{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b2209e0-bc73-4102-8d57-e0748ba55883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.2540902464637327\n",
      "=== epoch:1, train acc:0.107, test acc:0.112 ===\n",
      "train loss:2.251428322320407\n",
      "train loss:2.3070809090562934\n",
      "train loss:2.3012053773624386\n",
      "train loss:2.291659229612513\n",
      "train loss:2.281482153839448\n",
      "train loss:2.286839030009389\n",
      "train loss:2.2835117901791193\n",
      "train loss:2.280885343105764\n",
      "train loss:2.278649300675743\n",
      "train loss:2.27826423999992\n",
      "train loss:2.2769565590562806\n",
      "train loss:2.2714674981770706\n",
      "train loss:2.258797445495268\n",
      "train loss:2.2812261500268116\n",
      "train loss:2.2611291422194317\n",
      "train loss:2.2303147907176886\n",
      "train loss:2.2793805367949598\n",
      "train loss:2.246239014048766\n",
      "train loss:2.229922332439689\n",
      "train loss:2.2330692263328755\n",
      "train loss:2.229886496692957\n",
      "train loss:2.2277046092347677\n",
      "train loss:2.1045423647252415\n",
      "train loss:2.265706170271988\n",
      "train loss:2.179444506354871\n",
      "train loss:2.1534693480416127\n",
      "train loss:2.1247216344717303\n",
      "train loss:2.1365622364120123\n",
      "train loss:2.173875608419122\n",
      "train loss:2.232304883037054\n",
      "train loss:2.156923849237877\n",
      "train loss:2.1220814265101433\n",
      "train loss:2.1559909208618304\n",
      "train loss:2.050759276781324\n",
      "train loss:2.1029185194242657\n",
      "train loss:1.9303240724537043\n",
      "train loss:2.0521698964192847\n",
      "train loss:1.9328994454790933\n",
      "train loss:2.015364672307091\n",
      "train loss:2.1656912542595608\n",
      "train loss:2.0414271302376004\n",
      "train loss:2.008246416363733\n",
      "train loss:1.9696503302727806\n",
      "train loss:1.9410217008248467\n",
      "train loss:2.1633701658363798\n",
      "train loss:1.9911600530018623\n",
      "train loss:2.0862707380990653\n",
      "train loss:1.8895021275076136\n",
      "train loss:1.942570702658032\n",
      "train loss:2.0522528943358664\n",
      "train loss:1.996817093636194\n",
      "train loss:1.9641960440705482\n",
      "train loss:1.8612892250255646\n",
      "train loss:1.906680533522157\n",
      "train loss:1.957401725533189\n",
      "train loss:2.0544494303226553\n",
      "train loss:1.847967271489258\n",
      "train loss:1.8260998460989952\n",
      "train loss:1.9584251121733962\n",
      "train loss:1.9554449845488375\n",
      "train loss:1.8169681596633098\n",
      "train loss:1.8721191592483108\n",
      "train loss:1.85309090383899\n",
      "train loss:1.866131643497873\n",
      "train loss:2.0869187763246004\n",
      "train loss:1.8824826052820132\n",
      "train loss:1.900862276221622\n",
      "train loss:1.921806761192465\n",
      "train loss:1.9729189618014706\n",
      "train loss:1.8521753168251\n",
      "train loss:1.8230373037973888\n",
      "train loss:1.8767570317446862\n",
      "train loss:1.6971045918509085\n",
      "train loss:1.8911798980323404\n",
      "train loss:1.881819909218238\n",
      "train loss:2.000893043726586\n",
      "train loss:1.8020521228334143\n",
      "train loss:1.8557585305224702\n",
      "train loss:1.7835508092944712\n",
      "train loss:1.731699548198238\n",
      "train loss:1.8653537072994586\n",
      "train loss:1.803182196138195\n",
      "train loss:1.6592430633081627\n",
      "train loss:1.747028498483163\n",
      "train loss:1.8525422699024128\n",
      "train loss:1.8644663092097913\n",
      "train loss:1.7376140846137693\n",
      "train loss:1.6532729028695332\n",
      "train loss:1.7905564433746575\n",
      "train loss:1.750761602665215\n",
      "train loss:1.7652619493900819\n",
      "train loss:1.9286027515465138\n",
      "train loss:1.8077928681260733\n",
      "train loss:1.8319488144822824\n",
      "train loss:1.603207914889201\n",
      "train loss:1.733491807515764\n",
      "train loss:1.71788923323973\n",
      "train loss:1.820233128955871\n",
      "train loss:1.7409778024882454\n",
      "train loss:1.6208995958583292\n",
      "train loss:1.7908052946722066\n",
      "train loss:1.740931684263981\n",
      "train loss:1.6469330427733733\n",
      "train loss:1.6542575059045168\n",
      "train loss:1.6601261717057472\n",
      "train loss:1.5265018491702886\n",
      "train loss:1.8100711981557693\n",
      "train loss:1.674303804165763\n",
      "train loss:1.437929077404482\n",
      "train loss:1.5913548946529692\n",
      "train loss:1.761032217827411\n",
      "train loss:1.6300759745320577\n",
      "train loss:1.7361693118186372\n",
      "train loss:1.5350746977523693\n",
      "train loss:1.6812565734934568\n",
      "train loss:1.4770326566793832\n",
      "train loss:1.5853063985049494\n",
      "train loss:1.5271364373784488\n",
      "train loss:1.6803979110741603\n",
      "train loss:1.7552776940795576\n",
      "train loss:1.5212870112553574\n",
      "train loss:1.636263763368276\n",
      "train loss:1.5917237270731217\n",
      "train loss:1.5776112997069203\n",
      "train loss:1.7087415455929638\n",
      "train loss:1.631186201245017\n",
      "train loss:1.5475465955225796\n",
      "train loss:1.6448061148339266\n",
      "train loss:1.6751555926201769\n",
      "train loss:1.5564702807668067\n",
      "train loss:1.6405516143345023\n",
      "train loss:1.6322392510998371\n",
      "train loss:1.4432114510840734\n",
      "train loss:1.3695702585058351\n",
      "train loss:1.4974263470483142\n",
      "train loss:1.455257172045633\n",
      "train loss:1.6255054335139625\n",
      "train loss:1.5652433118546285\n",
      "train loss:1.2344406400838448\n",
      "train loss:1.3548544649811396\n",
      "train loss:1.63236807991817\n",
      "train loss:1.5117984436507335\n",
      "train loss:1.6180010088491852\n",
      "train loss:1.6006854800009855\n",
      "train loss:1.3788827092823115\n",
      "train loss:1.3383207429856723\n",
      "train loss:1.351481524850571\n",
      "train loss:1.3347866386758451\n",
      "train loss:1.3051893847736116\n",
      "train loss:1.77531132040496\n",
      "train loss:1.4269222960372892\n",
      "train loss:1.5087120425363643\n",
      "train loss:1.5192473291614237\n",
      "train loss:1.3316526209776458\n",
      "train loss:1.5475859211785536\n",
      "train loss:1.6825369798918586\n",
      "train loss:1.4977473992442638\n",
      "train loss:1.3878205761338562\n",
      "train loss:1.4200168897108896\n",
      "train loss:1.608869054952171\n",
      "train loss:1.3881619678638923\n",
      "train loss:1.536299612778148\n",
      "train loss:1.54306512810646\n",
      "train loss:1.557187645539378\n",
      "train loss:1.4997074928536054\n",
      "train loss:1.5480941607103973\n",
      "train loss:1.4802038700385498\n",
      "train loss:1.4157089701440628\n",
      "train loss:1.4456076748203528\n",
      "train loss:1.617729146087965\n",
      "train loss:1.5246265271407977\n",
      "train loss:1.4747886891028557\n",
      "train loss:1.531270023850231\n",
      "train loss:1.3857851593778252\n",
      "train loss:1.4515701274892336\n",
      "train loss:1.469107558927734\n",
      "train loss:1.4070363483569366\n",
      "train loss:1.444430944476075\n",
      "train loss:1.6307841010111954\n",
      "train loss:1.3621585114407069\n",
      "train loss:1.5329345170949187\n",
      "train loss:1.5508057935839779\n",
      "train loss:1.5547715743676291\n",
      "train loss:1.5461855153911523\n",
      "train loss:1.4410284150737802\n",
      "train loss:1.390968827210979\n",
      "train loss:1.2606162457249581\n",
      "train loss:1.4441017244915206\n",
      "train loss:1.4815533995231007\n",
      "train loss:1.3407745936910596\n",
      "train loss:1.510784178829185\n",
      "train loss:1.4877958243884006\n",
      "train loss:1.3622678422946137\n",
      "train loss:1.5498332270943447\n",
      "train loss:1.3098616979221536\n",
      "train loss:1.3734954503951058\n",
      "train loss:1.34766701182764\n",
      "train loss:1.5717269160221496\n",
      "train loss:1.5745320157373544\n",
      "train loss:1.4847951873380503\n",
      "train loss:1.3968626284667014\n",
      "train loss:1.5067710098575084\n",
      "train loss:1.252436722259187\n",
      "train loss:1.4583724061376784\n",
      "train loss:1.4184894386326858\n",
      "train loss:1.4225832875138382\n",
      "train loss:1.4864820642447443\n",
      "train loss:1.4881667703475117\n",
      "train loss:1.2596632273341022\n",
      "train loss:1.2838133613686145\n",
      "train loss:1.4142425374041705\n",
      "train loss:1.329094955203446\n",
      "train loss:1.4416895158355845\n",
      "train loss:1.4833848022745857\n",
      "train loss:1.4118186436309392\n",
      "train loss:1.4277451985129925\n",
      "train loss:1.4050921472581823\n",
      "train loss:1.400830350259743\n",
      "train loss:1.452366198288741\n",
      "train loss:1.3617635229697271\n",
      "train loss:1.483585556503347\n",
      "train loss:1.2732069427326342\n",
      "train loss:1.5197587448589105\n",
      "train loss:1.4083935740946019\n",
      "train loss:1.2890649389885822\n",
      "train loss:1.3423720021804626\n",
      "train loss:1.4608794443069268\n",
      "train loss:1.4582239306790192\n",
      "train loss:1.2967795432768607\n",
      "train loss:1.2657650959242959\n",
      "train loss:1.3790855030644982\n",
      "train loss:1.4773988610722235\n",
      "train loss:1.3845359557944994\n",
      "train loss:1.3624171304985293\n",
      "train loss:1.3488579876956432\n",
      "train loss:1.4155165532992122\n",
      "train loss:1.3300590062235893\n",
      "train loss:1.467828790886967\n",
      "train loss:1.4050658758976642\n",
      "train loss:1.2541070157720542\n",
      "train loss:1.412932855950165\n",
      "train loss:1.3300847207098425\n",
      "train loss:1.249461984233358\n",
      "train loss:1.4019308612158727\n",
      "train loss:1.448894090004988\n",
      "train loss:1.4820327218082046\n",
      "train loss:1.1685839376178908\n",
      "train loss:1.3972469717003488\n",
      "train loss:1.4889152682951627\n",
      "train loss:1.375753387929914\n",
      "train loss:1.4790995549185582\n",
      "train loss:1.1620286953197472\n",
      "train loss:1.3525369352937044\n",
      "train loss:1.4900707979491912\n",
      "train loss:1.3292543437662483\n",
      "train loss:1.2666681476224297\n",
      "train loss:1.260458909925298\n",
      "train loss:1.0966103864021046\n",
      "train loss:1.250971079205483\n",
      "train loss:1.2420757683968684\n",
      "train loss:1.4648686249086609\n",
      "train loss:1.3191989896797045\n",
      "train loss:1.2409978900422893\n",
      "train loss:1.3516291784360348\n",
      "train loss:1.321192081153677\n",
      "train loss:1.3512074438327804\n",
      "train loss:1.2884606516876733\n",
      "train loss:1.3931281472669883\n",
      "train loss:1.3572207093047453\n",
      "train loss:1.3592289291265371\n",
      "train loss:1.4893418493763166\n",
      "train loss:1.3892265714141585\n",
      "train loss:1.2745397695510876\n",
      "train loss:1.5679070766581498\n",
      "train loss:1.1826387074163989\n",
      "train loss:1.314571823760467\n",
      "train loss:1.3164383891049156\n",
      "train loss:1.361894862171663\n",
      "train loss:1.5663796415030056\n",
      "train loss:1.36961919543623\n",
      "train loss:1.391159156470408\n",
      "train loss:1.411424905962333\n",
      "train loss:1.1596681495964878\n",
      "train loss:1.4315204790562146\n",
      "train loss:1.370935174526483\n",
      "train loss:1.4675864974988881\n",
      "train loss:1.3290375910421173\n",
      "train loss:1.4246148293863314\n",
      "train loss:1.3906851770096793\n",
      "train loss:1.3523575856229306\n",
      "train loss:1.266447565480863\n",
      "train loss:1.4709324565773039\n",
      "train loss:1.4127503324950945\n",
      "train loss:1.2803633476010605\n",
      "train loss:1.3643035780352764\n",
      "train loss:1.4562994511336302\n",
      "train loss:1.4507367053619817\n",
      "train loss:1.276982044828316\n",
      "train loss:1.323367313204204\n",
      "train loss:1.1082176764939071\n",
      "train loss:1.5000503864500823\n",
      "train loss:1.4881409423087848\n",
      "train loss:1.3489427452422922\n",
      "train loss:1.478501939929373\n",
      "train loss:1.1505547134389809\n",
      "train loss:1.2360391327716105\n",
      "train loss:1.3870858935046904\n",
      "train loss:1.3739131245815832\n",
      "train loss:1.3507492321308816\n",
      "train loss:1.2581873513111719\n",
      "train loss:1.4625320623540723\n",
      "train loss:1.4593310381194695\n",
      "train loss:1.2883653385385367\n",
      "train loss:1.302010276970825\n",
      "train loss:1.295289472356121\n",
      "train loss:1.2117557422705154\n",
      "train loss:1.2837883101773442\n",
      "train loss:1.5269659359793948\n",
      "train loss:1.336785737514875\n",
      "train loss:1.1557997788490573\n",
      "train loss:1.3981626805661265\n",
      "train loss:1.3550578881253386\n",
      "train loss:1.374905644328828\n",
      "train loss:1.40264924912223\n",
      "train loss:1.326093642582799\n",
      "train loss:1.3057256600276463\n",
      "train loss:1.2150316044594285\n",
      "train loss:1.3310246770499652\n",
      "train loss:1.2348218881129407\n",
      "train loss:1.3173690882390365\n",
      "train loss:1.38020312928922\n",
      "train loss:1.1363515259247898\n",
      "train loss:1.2921673570876855\n",
      "train loss:1.2825606217932297\n",
      "train loss:1.332507249242715\n",
      "train loss:1.3997267789858452\n",
      "train loss:1.3961221571611764\n",
      "train loss:1.4115100650753971\n",
      "train loss:1.2242465277326713\n",
      "train loss:1.3935389789268313\n",
      "train loss:1.3001301118004742\n",
      "train loss:1.360393466444595\n",
      "train loss:1.1973830889533439\n",
      "train loss:1.1757058111497753\n",
      "train loss:1.2975950430094825\n",
      "train loss:1.3350061492843919\n",
      "train loss:1.155911667149505\n",
      "train loss:1.4400168056817273\n",
      "train loss:1.2657619241053588\n",
      "train loss:1.2070618227382273\n",
      "train loss:1.3009893959431114\n",
      "train loss:1.2893122032076676\n",
      "train loss:1.2513637299391724\n",
      "train loss:1.199989995670432\n",
      "train loss:1.0864162664067751\n",
      "train loss:1.317137689159303\n",
      "train loss:1.0833318248543378\n",
      "train loss:1.4888720380392206\n",
      "train loss:1.2542702854703733\n",
      "train loss:1.083072939324291\n",
      "train loss:1.4400361209210644\n",
      "train loss:1.2748600177555343\n",
      "train loss:1.2035091261556112\n",
      "train loss:1.4756321430305563\n",
      "train loss:1.3020843761501475\n",
      "train loss:1.3192807251453575\n",
      "train loss:1.2685008615630986\n",
      "train loss:1.4361127240373712\n",
      "train loss:1.266739907358795\n",
      "train loss:1.3209864790145418\n",
      "train loss:1.3579029698392124\n",
      "train loss:1.2023426685580183\n",
      "train loss:1.2217477867886557\n",
      "train loss:1.2960289568819723\n",
      "train loss:1.2684726770520738\n",
      "train loss:1.415118445784235\n",
      "train loss:1.0784107119946147\n",
      "train loss:1.1976178727853217\n",
      "train loss:1.2467044081133616\n",
      "train loss:1.3311254576383604\n",
      "train loss:1.2855652864435865\n",
      "train loss:1.1891945982912444\n",
      "train loss:1.168841021152274\n",
      "train loss:1.1506608076333682\n",
      "train loss:1.2638872346999244\n",
      "train loss:1.2118272652859536\n",
      "train loss:1.0701861744115995\n",
      "train loss:1.3320411790194426\n",
      "train loss:1.1990430127583191\n",
      "train loss:1.3736961344643976\n",
      "train loss:1.38681342326274\n",
      "train loss:1.2777346887452798\n",
      "train loss:1.4835756434285547\n",
      "train loss:1.2500006215909432\n",
      "train loss:1.2570750162156576\n",
      "train loss:1.246494514677302\n",
      "train loss:1.3337878235616256\n",
      "train loss:1.3110318150198916\n",
      "train loss:1.109642844947857\n",
      "train loss:1.4122459710676138\n",
      "train loss:1.2649814546978575\n",
      "train loss:1.2547680389145703\n",
      "train loss:1.3060958367066362\n",
      "train loss:1.2742265018171866\n",
      "train loss:1.2088658834745771\n",
      "train loss:1.186339644028872\n",
      "train loss:1.4366278166356954\n",
      "train loss:1.2343587308473005\n",
      "train loss:1.2224377040868217\n",
      "train loss:1.0862046373752365\n",
      "train loss:1.1664000569992172\n",
      "train loss:1.2471667274873959\n",
      "train loss:1.1926334191960606\n",
      "train loss:1.2683720431675556\n",
      "train loss:1.0371998854018678\n",
      "train loss:1.1307097014812595\n",
      "train loss:1.213100434241795\n",
      "train loss:1.229317501332608\n",
      "train loss:1.2478337551456307\n",
      "train loss:1.2742809266665043\n",
      "train loss:1.1549904838355878\n",
      "train loss:1.326332622736212\n",
      "train loss:1.1241871689635201\n",
      "train loss:1.1809052036420338\n",
      "train loss:1.26229488651627\n",
      "train loss:1.194856454929066\n",
      "train loss:1.342217074997339\n",
      "train loss:1.2142148269531416\n",
      "train loss:1.356197008448239\n",
      "train loss:1.2680021035689752\n",
      "train loss:1.2311973628759525\n",
      "train loss:1.2467072522075575\n",
      "train loss:1.3138795874420388\n",
      "train loss:1.1990095783713277\n",
      "train loss:1.101621054170866\n",
      "train loss:1.3801969605115474\n",
      "train loss:1.272001908656795\n",
      "train loss:1.2701428105152217\n",
      "train loss:1.2984531466370415\n",
      "train loss:1.2056368398019115\n",
      "train loss:1.2106488211475914\n",
      "train loss:1.2178143842036686\n",
      "train loss:1.2908736239986993\n",
      "train loss:1.082481057596484\n",
      "train loss:1.2624900588172157\n",
      "train loss:1.3349624746748707\n",
      "train loss:1.1729766338617926\n",
      "train loss:1.2701121768101102\n",
      "train loss:1.1851012872797901\n",
      "train loss:1.275661835438247\n",
      "train loss:1.2649289933240557\n",
      "train loss:1.3289981955054657\n",
      "train loss:1.1925503191199098\n",
      "train loss:1.140366558225752\n",
      "train loss:1.1011468653534449\n",
      "train loss:1.2045545156372266\n",
      "train loss:1.2439910246941062\n",
      "train loss:1.110733194145493\n",
      "train loss:1.1776609908525129\n",
      "train loss:1.1637227460672293\n",
      "train loss:1.1449100070624207\n",
      "train loss:1.159943643497087\n",
      "train loss:1.554038743318463\n",
      "train loss:1.3801197407199428\n",
      "train loss:1.2992100405664724\n",
      "train loss:1.2066699709785846\n",
      "train loss:1.25865335205952\n",
      "train loss:1.3103134503203215\n",
      "train loss:1.4269036965567876\n",
      "train loss:1.2887704549958203\n",
      "train loss:1.2508530650222307\n",
      "train loss:1.145936586320285\n",
      "train loss:1.0956840750041374\n",
      "train loss:1.3771060573288658\n",
      "train loss:1.2505045787207485\n",
      "train loss:1.1948026552829554\n",
      "train loss:1.1450559246007372\n",
      "train loss:1.3407001134129561\n",
      "train loss:1.1963182053422572\n",
      "train loss:1.1145355151539107\n",
      "train loss:1.1621220988508654\n",
      "train loss:1.2165716794336001\n",
      "train loss:1.198293080082692\n",
      "train loss:1.0666976761268996\n",
      "train loss:1.2415815335871252\n",
      "train loss:1.269037653805089\n",
      "train loss:1.1771384346019615\n",
      "train loss:1.2107150973025327\n",
      "train loss:1.270136538063538\n",
      "train loss:1.2037900934250538\n",
      "train loss:1.243252618991574\n",
      "train loss:1.1170381529388937\n",
      "train loss:1.1800020773211046\n",
      "train loss:1.094601730702251\n",
      "train loss:1.45919602066298\n",
      "train loss:1.0866843308899632\n",
      "train loss:1.2496996900235018\n",
      "train loss:1.3545583939811217\n",
      "train loss:1.2272903949268232\n",
      "train loss:0.9765927428347865\n",
      "train loss:1.1912347162695491\n",
      "train loss:1.128624227217201\n",
      "train loss:1.1193168819768526\n",
      "train loss:1.2371901766054965\n",
      "train loss:1.1642521210268288\n",
      "train loss:1.1648764095414672\n",
      "train loss:1.1320419905007737\n",
      "train loss:1.3433611162404038\n",
      "train loss:1.257707845578009\n",
      "train loss:1.2694405266578168\n",
      "train loss:1.1690084716999456\n",
      "train loss:1.2216512390583374\n",
      "train loss:0.9494334410532198\n",
      "train loss:1.3654284560509\n",
      "train loss:1.2130029789977836\n",
      "train loss:1.2545263991304587\n",
      "train loss:1.0099658016697963\n",
      "train loss:1.262564167752659\n",
      "train loss:1.240030823357201\n",
      "train loss:1.3568708851934561\n",
      "train loss:1.3380687476547002\n",
      "train loss:1.2016383470406202\n",
      "train loss:1.2189741975006279\n",
      "train loss:1.1954230103333874\n",
      "train loss:1.3157463647723457\n",
      "train loss:1.0758726975383168\n",
      "train loss:1.206229186993734\n",
      "train loss:1.1020064420997873\n",
      "train loss:1.3264716203951543\n",
      "train loss:1.0482214249963278\n",
      "train loss:1.1054519774922922\n",
      "train loss:1.0302674028319796\n",
      "train loss:1.3858193077154077\n",
      "train loss:1.056064485993583\n",
      "train loss:1.1985299655714017\n",
      "train loss:1.1096901570514743\n",
      "train loss:1.0041043151255296\n",
      "train loss:1.201110636895357\n",
      "train loss:1.309075311747148\n",
      "train loss:1.0200475100117434\n",
      "train loss:1.055864934874621\n",
      "train loss:1.1594140918395734\n",
      "train loss:1.2344464315837966\n",
      "train loss:1.2857139753645468\n",
      "train loss:1.1826757252771845\n",
      "train loss:1.1995354722297387\n",
      "train loss:0.9639164366209596\n",
      "train loss:1.0472084874557153\n",
      "train loss:1.2453742699904289\n",
      "train loss:1.051547475694677\n",
      "train loss:1.083871885493569\n",
      "train loss:1.0346918249815829\n",
      "train loss:1.0524056491522622\n",
      "train loss:1.1781020641359095\n",
      "train loss:0.9929036925646428\n",
      "train loss:1.2608100639669986\n",
      "train loss:1.0634283632606663\n",
      "train loss:1.3788599499915042\n",
      "train loss:1.1941455936991927\n",
      "train loss:1.3005096852424958\n",
      "train loss:1.259360333633212\n",
      "train loss:1.1448877978526744\n",
      "train loss:1.1635106431469062\n",
      "train loss:1.0546250765398386\n",
      "train loss:1.2245713849554387\n",
      "train loss:1.1494870851618944\n",
      "train loss:1.1623226059371978\n",
      "train loss:1.1497094810405537\n",
      "train loss:1.182630362921051\n",
      "train loss:1.229517459762052\n",
      "train loss:1.1689085553347371\n",
      "train loss:0.9657405807806161\n",
      "train loss:1.1523146589516424\n",
      "train loss:1.057025665803637\n",
      "train loss:1.215699216677497\n",
      "train loss:1.238403784150771\n",
      "train loss:1.2122662623862552\n",
      "train loss:1.2775327971945634\n",
      "train loss:1.281648557755843\n",
      "train loss:1.2242124845720608\n",
      "train loss:1.155568377095575\n",
      "train loss:1.2078796443353683\n",
      "train loss:1.161570196976366\n",
      "train loss:1.1300736147565997\n",
      "train loss:1.1859231207654977\n",
      "train loss:1.0368923180776095\n",
      "train loss:1.0874724192800107\n",
      "train loss:1.1018876469374712\n",
      "train loss:1.204774600383644\n",
      "train loss:1.0514250255421775\n",
      "train loss:1.0071527521983061\n",
      "train loss:1.091418854226273\n",
      "train loss:1.1676051584199367\n",
      "train loss:1.1915876184505698\n",
      "train loss:1.2185042089658271\n",
      "train loss:1.1490598845125743\n",
      "train loss:1.2334202217670753\n",
      "train loss:1.2524551712401986\n",
      "train loss:1.0100397308728128\n",
      "train loss:1.4670022038352348\n",
      "=== epoch:2, train acc:0.977, test acc:0.979 ===\n",
      "train loss:1.1154726066176703\n",
      "train loss:1.1728813302109513\n",
      "train loss:1.2412274012546165\n",
      "train loss:1.0329653423057403\n",
      "train loss:1.071154472223031\n",
      "train loss:1.104766772078247\n",
      "train loss:1.2582694992571164\n",
      "train loss:1.0776634929300188\n",
      "train loss:1.1193540139947056\n",
      "train loss:0.9804912174274031\n",
      "train loss:1.2761913568642052\n",
      "train loss:1.1526821758027732\n",
      "train loss:1.2780236637784461\n",
      "train loss:1.2709449463503781\n",
      "train loss:0.9800354434098874\n",
      "train loss:1.2282494220734974\n",
      "train loss:1.215519641257368\n",
      "train loss:1.2647943080669974\n",
      "train loss:1.1234858208131662\n",
      "train loss:1.3739766849848432\n",
      "train loss:1.1404712761930498\n",
      "train loss:1.0960164513492214\n",
      "train loss:1.0257660299960305\n",
      "train loss:1.2385477128923494\n",
      "train loss:1.0644127370791896\n",
      "train loss:1.0846858693848145\n",
      "train loss:1.2244290551000376\n",
      "train loss:1.0113365629940945\n",
      "train loss:1.1302338346691112\n",
      "train loss:1.4059306403765566\n",
      "train loss:1.2376209934132991\n",
      "train loss:1.1772048615721276\n",
      "train loss:1.1277256682610628\n",
      "train loss:1.0829014219255866\n",
      "train loss:1.2606338962636128\n",
      "train loss:1.1996609622214023\n",
      "train loss:0.9990365993119726\n",
      "train loss:1.1321144554473803\n",
      "train loss:1.2301891445277817\n",
      "train loss:1.2675340896970553\n",
      "train loss:1.0465788663142213\n",
      "train loss:1.116835089839085\n",
      "train loss:1.2505907595017383\n",
      "train loss:1.073954335139086\n",
      "train loss:1.1259052806460297\n",
      "train loss:1.1844428331846582\n",
      "train loss:1.2417017452022832\n",
      "train loss:1.0709557400770504\n",
      "train loss:1.0774741429873615\n",
      "train loss:1.137480831979249\n",
      "train loss:1.0925069895439987\n",
      "train loss:1.1397734424209507\n",
      "train loss:1.2094166337479235\n",
      "train loss:1.1113812377594368\n",
      "train loss:0.9314917977401861\n",
      "train loss:1.1791140946010659\n",
      "train loss:1.0254002919052632\n",
      "train loss:1.3119181107546458\n",
      "train loss:1.0244178840833187\n",
      "train loss:0.9653575316731061\n",
      "train loss:1.3705235707873769\n",
      "train loss:1.1967223713827528\n",
      "train loss:1.148269444401521\n",
      "train loss:0.9460477218081362\n",
      "train loss:1.2611948910750426\n",
      "train loss:1.3509494166887968\n",
      "train loss:0.9209410652038792\n",
      "train loss:1.2657941132125916\n",
      "train loss:1.285578725905572\n",
      "train loss:0.9839563884971351\n",
      "train loss:1.1957448137770517\n",
      "train loss:1.140490251011676\n",
      "train loss:1.1691079597541636\n",
      "train loss:1.0627413969123938\n",
      "train loss:1.0561217164287395\n",
      "train loss:1.182091965250256\n",
      "train loss:1.0910809311886407\n",
      "train loss:1.2537067545970877\n",
      "train loss:1.0584455563492359\n",
      "train loss:1.0448483576018068\n",
      "train loss:1.0804036174119063\n",
      "train loss:1.2003027626809186\n",
      "train loss:1.1029189148340985\n",
      "train loss:1.24986128967639\n",
      "train loss:1.044526068597978\n",
      "train loss:1.1350357491024303\n",
      "train loss:1.1416159355920825\n",
      "train loss:0.9673573420045021\n",
      "train loss:1.1282851020373936\n",
      "train loss:1.0684303091339122\n",
      "train loss:1.1669987625646783\n",
      "train loss:1.2462896522939702\n",
      "train loss:1.0132723652819562\n",
      "train loss:1.1806731254024156\n",
      "train loss:1.2085751418948718\n",
      "train loss:0.9748427020479756\n",
      "train loss:0.9044141868741293\n",
      "train loss:1.1159771317058047\n",
      "train loss:1.1460545208609354\n",
      "train loss:1.1823230661585256\n",
      "train loss:0.9496482685687582\n",
      "train loss:1.1906013286706756\n",
      "train loss:1.152889870211904\n",
      "train loss:1.031048697016656\n",
      "train loss:1.0056715176186477\n",
      "train loss:0.9876312794009646\n",
      "train loss:1.0883488778785777\n",
      "train loss:1.117479424777408\n",
      "train loss:1.1032226688140816\n",
      "train loss:0.9774403734837381\n",
      "train loss:1.2344837750783955\n",
      "train loss:1.2490335335841227\n",
      "train loss:0.9994601001378917\n",
      "train loss:1.0034111474092369\n",
      "train loss:1.2512442699778048\n",
      "train loss:1.101352154201969\n",
      "train loss:1.253303383934305\n",
      "train loss:1.2044141708232328\n",
      "train loss:1.0726605103537523\n",
      "train loss:1.1170784618548875\n",
      "train loss:1.163145612005275\n",
      "train loss:1.1426075799224054\n",
      "train loss:1.1950967052372947\n",
      "train loss:1.0787814932507804\n",
      "train loss:1.0223783014243581\n",
      "train loss:0.9027610472646788\n",
      "train loss:1.073675395729954\n",
      "train loss:1.1410371031670647\n",
      "train loss:1.0493175583762238\n",
      "train loss:1.157907784516908\n",
      "train loss:1.1652915295093875\n",
      "train loss:1.140352777521946\n",
      "train loss:1.0692937799131643\n",
      "train loss:1.3306228715755717\n",
      "train loss:1.235937906090748\n",
      "train loss:1.1387858126812274\n",
      "train loss:1.1043113918253162\n",
      "train loss:0.9577469966156219\n",
      "train loss:1.2182232008188436\n",
      "train loss:1.2921417912514213\n",
      "train loss:0.9021493761509382\n",
      "train loss:0.9597302842029637\n",
      "train loss:1.0920519655182401\n",
      "train loss:1.304035105439085\n",
      "train loss:1.138496957286856\n",
      "train loss:1.2540954652324328\n",
      "train loss:1.1472890717040536\n",
      "train loss:1.1951613311329794\n",
      "train loss:1.203511062781652\n",
      "train loss:0.9708125345706212\n",
      "train loss:1.0675512663749394\n",
      "train loss:1.0093925537724706\n",
      "train loss:1.1984004626809068\n",
      "train loss:1.0580915805832698\n",
      "train loss:1.041917877855341\n",
      "train loss:1.2263236721037685\n",
      "train loss:1.2374143901607337\n",
      "train loss:1.1002978184766656\n",
      "train loss:1.2501664730973807\n",
      "train loss:1.2372462939843203\n",
      "train loss:1.3163711962129983\n",
      "train loss:0.9936900969002083\n",
      "train loss:1.2901199318271908\n",
      "train loss:1.1200226450798079\n",
      "train loss:1.164025189487734\n",
      "train loss:1.1405463452936213\n",
      "train loss:1.2761434174388937\n",
      "train loss:1.2603608225106842\n",
      "train loss:1.0463904579192516\n",
      "train loss:1.1466740176116725\n",
      "train loss:0.9649422122377004\n",
      "train loss:1.1906670941542923\n",
      "train loss:1.0521797883602435\n",
      "train loss:0.9977129056148405\n",
      "train loss:0.9245434732114275\n",
      "train loss:1.083447122443458\n",
      "train loss:1.1542372161986842\n",
      "train loss:1.1236971056910747\n",
      "train loss:1.1906556022660895\n",
      "train loss:1.0832337566475316\n",
      "train loss:1.1372275894588417\n",
      "train loss:1.039886753498564\n",
      "train loss:1.2726974046504893\n",
      "train loss:1.0053370862768314\n",
      "train loss:1.1324427131441213\n",
      "train loss:1.1676644797748352\n",
      "train loss:1.0902431974943954\n",
      "train loss:1.1433648636342395\n",
      "train loss:1.1072593681806482\n",
      "train loss:1.0918787761098683\n",
      "train loss:1.0374267533842403\n",
      "train loss:1.0912973826563097\n",
      "train loss:1.033374004823698\n",
      "train loss:1.1478234551572313\n",
      "train loss:1.1310473621206996\n",
      "train loss:1.0294975460969145\n",
      "train loss:1.036703861810971\n",
      "train loss:1.2363569702927004\n",
      "train loss:1.2013012063617974\n",
      "train loss:1.0773941082618104\n",
      "train loss:1.125488240980519\n",
      "train loss:1.1222394781226566\n",
      "train loss:0.9679224299368957\n",
      "train loss:1.0666475326636786\n",
      "train loss:1.0349402202380242\n",
      "train loss:1.149807812040345\n",
      "train loss:1.2628239846515519\n",
      "train loss:1.1593934072672338\n",
      "train loss:1.1595512865497013\n",
      "train loss:1.1898618679744928\n",
      "train loss:1.1762031672338609\n",
      "train loss:1.1082340249080882\n",
      "train loss:1.0337140561607412\n",
      "train loss:0.8918199924914073\n",
      "train loss:1.1527401769527463\n",
      "train loss:1.1825091201700844\n",
      "train loss:1.2815967126433137\n",
      "train loss:1.0777923397307136\n",
      "train loss:1.12583787769885\n",
      "train loss:1.2287765746466\n",
      "train loss:0.9858083728115677\n",
      "train loss:1.123770952867752\n",
      "train loss:1.234946755858428\n",
      "train loss:1.1367656820198213\n",
      "train loss:1.1867765494141884\n",
      "train loss:1.0161872792718711\n",
      "train loss:1.0318427481657146\n",
      "train loss:1.0504441827348208\n",
      "train loss:1.126038816930329\n",
      "train loss:1.027305585602181\n",
      "train loss:1.055327133358965\n",
      "train loss:0.910595677729202\n",
      "train loss:1.114167571799092\n",
      "train loss:1.1662439775496996\n",
      "train loss:1.142958352433251\n",
      "train loss:1.0451159086175492\n",
      "train loss:1.0147186338381164\n",
      "train loss:1.2430513320535095\n",
      "train loss:0.9811807292198894\n",
      "train loss:1.1794032729453103\n",
      "train loss:1.0598477270292403\n",
      "train loss:1.1829199158148453\n",
      "train loss:1.2540790695907909\n",
      "train loss:1.0171076263309633\n",
      "train loss:1.1422198834221817\n",
      "train loss:1.1792076913923824\n",
      "train loss:1.361152927779212\n",
      "train loss:1.2259779621231655\n",
      "train loss:1.1078604509070968\n",
      "train loss:1.0901420022024657\n",
      "train loss:1.2299643252065138\n",
      "train loss:1.2681094256426853\n",
      "train loss:1.2122458416996984\n",
      "train loss:1.1149928053922131\n",
      "train loss:1.080647169601336\n",
      "train loss:0.9336289990976232\n",
      "train loss:1.106412941268489\n",
      "train loss:1.2145446812810277\n",
      "train loss:1.0493232698498833\n",
      "train loss:1.1592856548882244\n",
      "train loss:1.0956061340621934\n",
      "train loss:1.0240149814276553\n",
      "train loss:1.2169672843899426\n",
      "train loss:1.1889786064250296\n",
      "train loss:1.1259057257431193\n",
      "train loss:1.093779589934332\n",
      "train loss:1.0290689903279169\n",
      "train loss:1.2734602540613436\n",
      "train loss:1.1837889758950872\n",
      "train loss:1.0367749650664286\n",
      "train loss:1.0920620718176643\n",
      "train loss:0.9112123480359401\n",
      "train loss:1.155246181491654\n",
      "train loss:1.087508138388548\n",
      "train loss:1.0277963294892123\n",
      "train loss:1.1346338947437744\n",
      "train loss:1.0567288440641238\n",
      "train loss:1.020813544693256\n",
      "train loss:1.159527066935505\n",
      "train loss:0.9340508141270807\n",
      "train loss:1.0875909717106629\n",
      "train loss:1.0782187265999097\n",
      "train loss:1.305821165076069\n",
      "train loss:1.0375338165989718\n",
      "train loss:1.150857654023252\n",
      "train loss:1.0501684807918865\n",
      "train loss:1.1297995581703484\n",
      "train loss:1.264126308757252\n",
      "train loss:1.1361313443722316\n",
      "train loss:1.062914028335387\n",
      "train loss:1.1391321899116138\n",
      "train loss:1.229333871777204\n",
      "train loss:1.0152026243367134\n",
      "train loss:1.0517025524592718\n",
      "train loss:1.2029980930602602\n",
      "train loss:1.1234680442173295\n",
      "train loss:1.0423421566499287\n",
      "train loss:1.029732121290566\n",
      "train loss:1.0262573510352972\n",
      "train loss:1.0588017215946515\n",
      "train loss:1.0275604606806048\n",
      "train loss:1.1308327298273393\n",
      "train loss:0.8608381602970963\n",
      "train loss:1.1512391971336617\n",
      "train loss:0.908373108061526\n",
      "train loss:1.1231562127381105\n",
      "train loss:1.1547796270055382\n",
      "train loss:0.9282124890185163\n",
      "train loss:1.2613572969156994\n",
      "train loss:1.1274052324601007\n",
      "train loss:1.1678042062511855\n",
      "train loss:1.1274205271974251\n",
      "train loss:1.2069029016850865\n",
      "train loss:0.9969010627257832\n",
      "train loss:0.9196513105844363\n",
      "train loss:0.9183962926430808\n",
      "train loss:1.126695286152605\n",
      "train loss:1.1478704181310921\n",
      "train loss:0.9452831212082493\n",
      "train loss:1.0190426560129844\n",
      "train loss:1.2922260017906626\n",
      "train loss:1.1215275320349747\n",
      "train loss:1.0810668576716589\n",
      "train loss:1.272615403512872\n",
      "train loss:1.110215308871975\n",
      "train loss:1.024499218366275\n",
      "train loss:1.0686889343761026\n",
      "train loss:1.1239375238861924\n",
      "train loss:1.2450585148874271\n",
      "train loss:1.0143790050812609\n",
      "train loss:0.9994333131850098\n",
      "train loss:1.0050239238889715\n",
      "train loss:1.0382226472007152\n",
      "train loss:1.1094563637428314\n",
      "train loss:1.0408459351462256\n",
      "train loss:1.0490410983739582\n",
      "train loss:1.1270013714154208\n",
      "train loss:1.1556700210767452\n",
      "train loss:0.9684152204856187\n",
      "train loss:1.0388595020932216\n",
      "train loss:1.0807681355546277\n",
      "train loss:1.0073143659692583\n",
      "train loss:1.063629530228598\n",
      "train loss:0.8758242220650706\n",
      "train loss:1.1875120997183126\n",
      "train loss:1.0025318569448514\n",
      "train loss:0.8709020177963535\n",
      "train loss:1.0658270623162003\n",
      "train loss:1.0488614467533512\n",
      "train loss:1.0306747283002553\n",
      "train loss:1.1543951337928073\n",
      "train loss:0.9351393040249699\n",
      "train loss:0.8725216064765897\n",
      "train loss:1.148611042670554\n",
      "train loss:1.1270185815576423\n",
      "train loss:0.9947926147080263\n",
      "train loss:1.2150642455421448\n",
      "train loss:0.9458844166288103\n",
      "train loss:1.1498605094146384\n",
      "train loss:0.9404815790314331\n",
      "train loss:1.047936979475226\n",
      "train loss:1.0416537915646673\n",
      "train loss:1.0570944221131737\n",
      "train loss:1.2296695386743879\n",
      "train loss:1.1731825185003013\n",
      "train loss:1.1837719572711904\n",
      "train loss:1.0272386051980424\n",
      "train loss:1.086206925934996\n",
      "train loss:0.995060023726321\n",
      "train loss:1.1974007639625617\n",
      "train loss:1.2088244196684463\n",
      "train loss:1.0993683539479542\n",
      "train loss:0.9878235558708791\n",
      "train loss:0.9623278405940577\n",
      "train loss:1.0535903681194736\n",
      "train loss:0.9249136053840503\n",
      "train loss:1.0701438936463592\n",
      "train loss:1.028369185624681\n",
      "train loss:1.0803477889582624\n",
      "train loss:0.9014135386610621\n",
      "train loss:0.8911891189049507\n",
      "train loss:1.059988721456371\n",
      "train loss:1.155906056694497\n",
      "train loss:1.0369423222115064\n",
      "train loss:0.973431989028776\n",
      "train loss:1.0258964737716263\n",
      "train loss:1.003724846945778\n",
      "train loss:1.2326794555489358\n",
      "train loss:1.0040556160052354\n",
      "train loss:1.1822303671864995\n",
      "train loss:0.9898958147468372\n",
      "train loss:1.0141362069881392\n",
      "train loss:1.1285955567221628\n",
      "train loss:0.915801570583755\n",
      "train loss:1.0088365683766092\n",
      "train loss:1.240857924935501\n",
      "train loss:1.1507918404763675\n",
      "train loss:1.103832676114355\n",
      "train loss:1.0441918500359741\n",
      "train loss:1.0010738085492104\n",
      "train loss:0.9846952170718062\n",
      "train loss:0.9933809541975747\n",
      "train loss:1.1134869362704567\n",
      "train loss:0.8864420161412319\n",
      "train loss:0.9973571991562328\n",
      "train loss:0.7443153701599688\n",
      "train loss:1.108608252012389\n",
      "train loss:0.8929784230866495\n",
      "train loss:1.1450124965330915\n",
      "train loss:1.2303390210182068\n",
      "train loss:1.2725578896916117\n",
      "train loss:0.9487554963830589\n",
      "train loss:1.0481616586387692\n",
      "train loss:1.264140732000941\n",
      "train loss:1.175416023708123\n",
      "train loss:1.11061632791901\n",
      "train loss:1.0680682468414804\n",
      "train loss:1.2397071153224493\n",
      "train loss:1.2641051337296039\n",
      "train loss:1.062240929124786\n",
      "train loss:0.9699945091189144\n",
      "train loss:1.1997529924371317\n",
      "train loss:1.1710970948004262\n",
      "train loss:1.0038269745952093\n",
      "train loss:1.123948799020874\n",
      "train loss:1.0355372259625681\n",
      "train loss:1.0212468128236365\n",
      "train loss:0.9722215916017106\n",
      "train loss:0.9860717303752558\n",
      "train loss:1.1372901545969365\n",
      "train loss:1.0839661691873548\n",
      "train loss:1.057891869948452\n",
      "train loss:1.1961848436478393\n",
      "train loss:1.0025382372279728\n",
      "train loss:0.9085830897245672\n",
      "train loss:1.048499271555076\n",
      "train loss:1.017924161156018\n",
      "train loss:0.9589878569926406\n",
      "train loss:0.910656786568414\n",
      "train loss:1.0035102402124365\n",
      "train loss:0.9542871974298568\n",
      "train loss:0.975253289162808\n",
      "train loss:1.0738912039839466\n",
      "train loss:0.9919281244549691\n",
      "train loss:1.0653739548752497\n",
      "train loss:0.939322717297386\n",
      "train loss:1.1043923849056387\n",
      "train loss:0.8918122540964533\n",
      "train loss:0.8860896110065348\n",
      "train loss:1.1645911561090285\n",
      "train loss:0.9211409048316774\n",
      "train loss:1.065504283554115\n",
      "train loss:1.0557535228452337\n",
      "train loss:1.1713966356842624\n",
      "train loss:1.1563663184641952\n",
      "train loss:0.9827041556587733\n",
      "train loss:1.1413327668474427\n",
      "train loss:1.04647110762946\n",
      "train loss:1.1568877926500354\n",
      "train loss:1.1763394155513898\n",
      "train loss:1.0282914310938605\n",
      "train loss:1.0503500922828293\n",
      "train loss:1.240358495052443\n",
      "train loss:0.9418533669721549\n",
      "train loss:0.9629359628656473\n",
      "train loss:0.8966674287418277\n",
      "train loss:0.8691872957570205\n",
      "train loss:1.0571177129094143\n",
      "train loss:0.8732713691806356\n",
      "train loss:0.9661784551446668\n",
      "train loss:1.074082375322968\n",
      "train loss:0.8898799770562039\n",
      "train loss:1.1245078997799867\n",
      "train loss:0.8578730190780819\n",
      "train loss:0.8731623023485524\n",
      "train loss:1.1809520561735696\n",
      "train loss:1.0025264585220903\n",
      "train loss:1.004414748329661\n",
      "train loss:1.0324191062170545\n",
      "train loss:1.0802482079934885\n",
      "train loss:1.0217196843999259\n",
      "train loss:1.0809905898351717\n",
      "train loss:1.01156748819556\n",
      "train loss:1.0022436400894437\n",
      "train loss:1.0521972256746008\n",
      "train loss:1.0356212587180018\n",
      "train loss:1.0886746566150467\n",
      "train loss:0.9189087684788778\n",
      "train loss:0.8765125896213363\n",
      "train loss:0.9551140720950088\n",
      "train loss:1.0068544048935568\n",
      "train loss:1.170906822699196\n",
      "train loss:1.1204359667140007\n",
      "train loss:1.0325302043025288\n",
      "train loss:0.9962995648974641\n",
      "train loss:1.1513173484071517\n",
      "train loss:0.8774638161968192\n",
      "train loss:0.8994860009043397\n",
      "train loss:1.0166686297168173\n",
      "train loss:0.9504738691586495\n",
      "train loss:1.2317061668831342\n",
      "train loss:1.0008721696996772\n",
      "train loss:1.0143805442790372\n",
      "train loss:0.9487099905891345\n",
      "train loss:0.9484048907048438\n",
      "train loss:1.1348689696551153\n",
      "train loss:1.1009337086849849\n",
      "train loss:1.0484085332549833\n",
      "train loss:0.9978747477938483\n",
      "train loss:1.0883068383703285\n",
      "train loss:0.9945837046262999\n",
      "train loss:0.9041390955056411\n",
      "train loss:0.9378477736406657\n",
      "train loss:1.072074964549085\n",
      "train loss:1.027716270513217\n",
      "train loss:0.9844828206850559\n",
      "train loss:1.0812676084235924\n",
      "train loss:1.1172168449326056\n",
      "train loss:1.079768790423203\n",
      "train loss:0.9622334353339365\n",
      "train loss:1.021005684198794\n",
      "train loss:1.1133525858615418\n",
      "train loss:0.98409402044614\n",
      "train loss:0.8133690955375928\n",
      "train loss:1.0767875377868643\n",
      "train loss:1.0414201939715984\n",
      "train loss:0.9912286144355652\n",
      "train loss:1.0939761759032975\n",
      "train loss:1.1186569020882529\n",
      "train loss:1.0779570126682534\n",
      "train loss:0.9895784568512171\n",
      "train loss:0.9387022335306601\n",
      "train loss:1.0808307757734312\n",
      "train loss:1.1466478212605054\n",
      "train loss:0.9761028360179717\n",
      "train loss:1.0098557600224563\n",
      "train loss:1.031427444546572\n",
      "train loss:0.9251962441416545\n",
      "train loss:1.2733036338789048\n",
      "train loss:0.905025642390301\n",
      "train loss:1.1084465584815204\n",
      "train loss:0.8989176846909696\n",
      "train loss:1.0962565546911966\n",
      "train loss:0.9166617394329301\n",
      "train loss:1.179380044768636\n",
      "train loss:0.8930270343506129\n",
      "train loss:1.000305171321643\n",
      "train loss:1.0614444031503711\n",
      "train loss:0.9886273739316006\n",
      "train loss:1.0513522654023129\n",
      "train loss:1.0142004079868783\n",
      "train loss:0.9094498267298811\n",
      "train loss:1.030573839400641\n",
      "train loss:0.875354493805923\n",
      "train loss:0.9825461787174742\n",
      "train loss:0.992275901452641\n",
      "train loss:1.0691857056627698\n",
      "train loss:1.088147689156992\n",
      "train loss:1.087181222997391\n",
      "train loss:0.992799879611884\n",
      "train loss:0.947605263538059\n",
      "train loss:0.9712067597705386\n",
      "train loss:1.0746899670939294\n",
      "train loss:1.1393091597135203\n",
      "train loss:0.9739354888357316\n",
      "train loss:1.1780693568365859\n",
      "train loss:0.9283809864319703\n",
      "train loss:0.9200843974933447\n",
      "train loss:1.0081694581803011\n",
      "train loss:1.0710084959759074\n",
      "train loss:1.1508478452305702\n",
      "train loss:1.083776859663777\n",
      "train loss:0.9967849156487852\n",
      "train loss:0.9197910647066777\n",
      "train loss:0.9008146649647897\n",
      "train loss:1.0295442566773323\n",
      "train loss:0.9342468294855115\n",
      "train loss:0.9463558389440331\n",
      "train loss:0.9009326986142672\n",
      "train loss:1.0551805260121918\n",
      "train loss:0.9543329898867948\n",
      "train loss:0.971455296239082\n",
      "train loss:1.0584285770065103\n",
      "train loss:0.8655758840205027\n",
      "train loss:1.0921283007221678\n",
      "train loss:0.8837244516734986\n",
      "train loss:1.0467740151626623\n",
      "train loss:0.8601125357256494\n",
      "train loss:0.8934796967880768\n",
      "train loss:1.1829077333190618\n",
      "train loss:0.9554727373571754\n",
      "train loss:1.1481007489068575\n",
      "train loss:0.888596762347949\n",
      "train loss:1.0021578196356422\n",
      "train loss:1.0036005508143233\n",
      "train loss:0.9355155580925825\n",
      "train loss:0.9645910685239827\n",
      "train loss:1.0217619104672224\n",
      "train loss:0.9302043510318028\n",
      "train loss:0.9238348204708297\n",
      "=== epoch:3, train acc:0.987, test acc:0.981 ===\n",
      "train loss:1.034035391577359\n",
      "train loss:0.9971636658012387\n",
      "train loss:1.139680176415053\n",
      "train loss:1.0408148026674457\n",
      "train loss:0.8908676411014038\n",
      "train loss:1.0953603940157353\n",
      "train loss:1.0321409731495315\n",
      "train loss:1.0555989170630717\n",
      "train loss:0.8388280745573082\n",
      "train loss:0.9109153376745698\n",
      "train loss:1.0636973177268474\n",
      "train loss:1.104783399263993\n",
      "train loss:1.0712234170510384\n",
      "train loss:0.822947730871331\n",
      "train loss:0.9962430386134585\n",
      "train loss:0.9778807895860432\n",
      "train loss:0.9034497390084101\n",
      "train loss:1.0820162646595823\n",
      "train loss:1.14307329630409\n",
      "train loss:1.0103453486211673\n",
      "train loss:1.0364378402577956\n",
      "train loss:0.9759361238314347\n",
      "train loss:1.1181265172678096\n",
      "train loss:1.0171088389091283\n",
      "train loss:1.0468692021667168\n",
      "train loss:1.0842421861767897\n",
      "train loss:0.9740262420757658\n",
      "train loss:0.8100989335945404\n",
      "train loss:0.9975967483937453\n",
      "train loss:1.0699447013998442\n",
      "train loss:0.8399534693408058\n",
      "train loss:0.9736830296224841\n",
      "train loss:1.047391216574914\n",
      "train loss:1.0073014514643162\n",
      "train loss:0.8881260668533443\n",
      "train loss:0.9231134992699329\n",
      "train loss:0.9966116355612755\n",
      "train loss:1.0139288382005711\n",
      "train loss:0.9835900286592602\n",
      "train loss:1.0760856883627758\n",
      "train loss:0.8831912957283091\n",
      "train loss:1.1095732192473227\n",
      "train loss:0.9909079633400139\n",
      "train loss:1.0305723962531186\n",
      "train loss:1.2109573827392517\n",
      "train loss:1.0284910592002252\n",
      "train loss:0.895025883631047\n",
      "train loss:1.0361408576887385\n",
      "train loss:1.0046377151778811\n",
      "train loss:0.9730763847521436\n",
      "train loss:1.1572289984154909\n",
      "train loss:1.1696781404097338\n",
      "train loss:0.9473074126533281\n",
      "train loss:1.1179092699113455\n",
      "train loss:0.9166039043481411\n",
      "train loss:0.9751260220583626\n",
      "train loss:0.9351336525219868\n",
      "train loss:0.9641182919843573\n",
      "train loss:0.9707640036556487\n",
      "train loss:0.9164833501815168\n",
      "train loss:1.1585113076758893\n",
      "train loss:1.086947631454139\n",
      "train loss:1.0546462033019515\n",
      "train loss:0.9320005447809536\n",
      "train loss:0.9295733635336374\n",
      "train loss:1.0375437498381908\n",
      "train loss:0.9528741181516911\n",
      "train loss:0.8245727095277401\n",
      "train loss:0.9167336116389221\n",
      "train loss:1.2214961800315551\n",
      "train loss:0.9994859734456558\n",
      "train loss:1.1341003688380367\n",
      "train loss:0.8448378061847821\n",
      "train loss:0.9034667382139496\n",
      "train loss:0.9124741342857776\n",
      "train loss:1.2022911287708522\n",
      "train loss:0.9691614513697185\n",
      "train loss:0.9525669606127455\n",
      "train loss:0.9600008552159482\n",
      "train loss:0.9599487177119039\n",
      "train loss:0.8696496826299465\n",
      "train loss:1.1329943134658516\n",
      "train loss:0.9925519520392616\n",
      "train loss:1.0186562690738459\n",
      "train loss:1.078227238616475\n",
      "train loss:1.0141243691450688\n",
      "train loss:1.1193006950694575\n",
      "train loss:1.2138007235126573\n",
      "train loss:1.0165096181406816\n",
      "train loss:0.9529159555859132\n",
      "train loss:1.0091213178297875\n",
      "train loss:0.8039577588043783\n",
      "train loss:1.0636209072670193\n",
      "train loss:1.021421745200022\n",
      "train loss:0.87719485777914\n",
      "train loss:0.7189022525702207\n",
      "train loss:0.9258573206856174\n",
      "train loss:0.9140446326166111\n",
      "train loss:1.0124413383879132\n",
      "train loss:1.0892977958378873\n",
      "train loss:0.7975428222569216\n",
      "train loss:0.9217510246047415\n",
      "train loss:0.9553047599817387\n",
      "train loss:0.9078344422759986\n",
      "train loss:0.8466376622649548\n",
      "train loss:0.840302970396047\n",
      "train loss:0.9386556666004782\n",
      "train loss:0.9781305385668536\n",
      "train loss:0.859269328396034\n",
      "train loss:0.9552674262185589\n",
      "train loss:1.0773560414057899\n",
      "train loss:1.105867671167865\n",
      "train loss:1.0827317720339331\n",
      "train loss:0.8726585441003907\n",
      "train loss:1.0141761781795893\n",
      "train loss:1.0106024197108672\n",
      "train loss:0.9334572509373875\n",
      "train loss:1.050557773330589\n",
      "train loss:1.0943562367518735\n",
      "train loss:1.1265041084465524\n",
      "train loss:0.8440923584461776\n",
      "train loss:0.9814138596680732\n",
      "train loss:1.1152446321789775\n",
      "train loss:0.9977068962202239\n",
      "train loss:0.9080268698129228\n",
      "train loss:1.0112671841506773\n",
      "train loss:1.0093019360340123\n",
      "train loss:0.935066780378597\n",
      "train loss:0.9374067929780923\n",
      "train loss:0.852761590901232\n",
      "train loss:1.016111997250051\n",
      "train loss:0.7756429936523019\n",
      "train loss:1.0365401881760044\n",
      "train loss:1.0529287431266048\n",
      "train loss:1.0620364913078262\n",
      "train loss:0.9003852203576389\n",
      "train loss:0.9799389022092733\n",
      "train loss:0.9421056050488673\n",
      "train loss:1.06983822431632\n",
      "train loss:0.977780029984332\n",
      "train loss:0.7995252669264176\n",
      "train loss:1.0865535705994143\n",
      "train loss:1.0368777741233999\n",
      "train loss:0.9696964210398247\n",
      "train loss:0.975852481242657\n",
      "train loss:1.0392787851089675\n",
      "train loss:0.9398449565913617\n",
      "train loss:1.0279920651263028\n",
      "train loss:1.0425138092280812\n",
      "train loss:0.9772427648018385\n",
      "train loss:1.0008800224050025\n",
      "train loss:1.058044038890045\n",
      "train loss:0.8027228267173839\n",
      "train loss:1.0762777326646442\n",
      "train loss:1.247354454672876\n",
      "train loss:0.9840763796495299\n",
      "train loss:1.0000682904138178\n",
      "train loss:0.9806566092095451\n",
      "train loss:1.0522264863635538\n",
      "train loss:0.9806955669016477\n",
      "train loss:0.9848759025619032\n",
      "train loss:0.9983656060690056\n",
      "train loss:1.0680931677054604\n",
      "train loss:0.8795413923660931\n",
      "train loss:0.8661948438653426\n",
      "train loss:1.0406122008086252\n",
      "train loss:1.0140703322734475\n",
      "train loss:1.046207562700547\n",
      "train loss:0.9654670433716218\n",
      "train loss:1.055139422473309\n",
      "train loss:0.890780631160228\n",
      "train loss:1.3290881534151353\n",
      "train loss:0.7464490859395648\n",
      "train loss:1.0854465602353605\n",
      "train loss:0.9662203426236939\n",
      "train loss:0.8643293262463468\n",
      "train loss:1.1295823212586458\n",
      "train loss:0.9047850946627751\n",
      "train loss:1.1065791101734355\n",
      "train loss:1.0132331480679426\n",
      "train loss:1.0480677157563267\n",
      "train loss:1.032526066263092\n",
      "train loss:1.10598935019442\n",
      "train loss:0.9255414043291813\n",
      "train loss:1.0271797903971818\n",
      "train loss:1.0030680172604431\n",
      "train loss:1.0086293882596986\n",
      "train loss:1.1541817379232449\n",
      "train loss:1.0039404885921064\n",
      "train loss:0.9166478436925977\n",
      "train loss:0.8795725901932796\n",
      "train loss:1.0644672192638682\n",
      "train loss:1.0883680149033204\n",
      "train loss:0.9894756239818827\n",
      "train loss:1.0706764382436815\n",
      "train loss:0.9852905661317137\n",
      "train loss:0.9712427780272086\n",
      "train loss:0.9992154332792598\n",
      "train loss:0.9657894291620478\n",
      "train loss:1.22800481146505\n",
      "train loss:0.9228876090454708\n",
      "train loss:0.7556585111051739\n",
      "train loss:0.86243256387415\n",
      "train loss:1.1868040128059787\n",
      "train loss:0.9810551792580031\n",
      "train loss:0.8685912188956011\n",
      "train loss:0.9727757970791803\n",
      "train loss:0.9635929294952361\n",
      "train loss:1.1091438870607653\n",
      "train loss:0.8746159567771731\n",
      "train loss:1.3057678036511917\n",
      "train loss:0.8959039576121761\n",
      "train loss:0.8367356042766997\n",
      "train loss:1.1579805682337059\n",
      "train loss:0.9911251365460804\n",
      "train loss:1.2305917182859583\n",
      "train loss:0.9727449727356646\n",
      "train loss:0.9368292255660795\n",
      "train loss:0.9880587809450563\n",
      "train loss:1.0965843963583313\n",
      "train loss:1.0216845851860072\n",
      "train loss:0.9306058505155096\n",
      "train loss:0.7826185921985398\n",
      "train loss:1.120762991678165\n",
      "train loss:1.0200782965964514\n",
      "train loss:1.0598732443282521\n",
      "train loss:1.0236384114290542\n",
      "train loss:0.902165769928812\n",
      "train loss:1.1206121592341969\n",
      "train loss:1.0603341674000388\n",
      "train loss:1.1547873592084392\n",
      "train loss:0.8812563916711159\n",
      "train loss:0.9874678888806899\n",
      "train loss:0.9543311552003766\n",
      "train loss:0.8614764528633478\n",
      "train loss:0.974370868642973\n",
      "train loss:0.8887453853106496\n",
      "train loss:0.9716569328849376\n",
      "train loss:1.1138087547282252\n",
      "train loss:1.0252300158282388\n",
      "train loss:1.159102190333527\n",
      "train loss:0.8376013304342697\n",
      "train loss:0.8737823341052875\n",
      "train loss:1.0222802115428893\n",
      "train loss:1.0797566899220465\n",
      "train loss:0.9227361400711933\n",
      "train loss:0.9552437397612669\n",
      "train loss:0.7881547906118769\n",
      "train loss:1.078587904478855\n",
      "train loss:0.9331868686100075\n",
      "train loss:0.9767274610558689\n",
      "train loss:0.820509086498152\n",
      "train loss:0.9599973678702217\n",
      "train loss:0.9818529945535264\n",
      "train loss:0.9331582208538045\n",
      "train loss:0.8902284634468919\n",
      "train loss:1.106457385220928\n",
      "train loss:1.0914002251447996\n",
      "train loss:0.9130904514872178\n",
      "train loss:0.9182208507879649\n",
      "train loss:1.0412521090848426\n",
      "train loss:1.0067939118656006\n",
      "train loss:1.0189686323519849\n",
      "train loss:0.97017515375369\n",
      "train loss:1.065372678169544\n",
      "train loss:0.771017648312051\n",
      "train loss:0.8624006701979596\n",
      "train loss:0.7938502569938233\n",
      "train loss:1.0657383466510673\n",
      "train loss:0.8606596569869666\n",
      "train loss:0.920426970372899\n",
      "train loss:0.8466669999132965\n",
      "train loss:0.9931963640275943\n",
      "train loss:0.9536155464813377\n",
      "train loss:1.0053853180467722\n",
      "train loss:0.7995218437127605\n",
      "train loss:0.9857718595825632\n",
      "train loss:1.0226163805305042\n",
      "train loss:1.0132858828211384\n",
      "train loss:1.0434732001994305\n",
      "train loss:1.0822757494916266\n",
      "train loss:1.0899365470919242\n",
      "train loss:0.9411080285454058\n",
      "train loss:0.8679826711223813\n",
      "train loss:0.8965535942550953\n",
      "train loss:1.1117271467727547\n",
      "train loss:0.9560733703195149\n",
      "train loss:1.0899532007439843\n",
      "train loss:1.1599382743335467\n",
      "train loss:1.0515385340793941\n",
      "train loss:0.9361104900506309\n",
      "train loss:0.9632980032362904\n",
      "train loss:1.0199670313947824\n",
      "train loss:0.8118405767675619\n",
      "train loss:1.113190525792909\n",
      "train loss:1.0284139870986342\n",
      "train loss:1.0998191158730044\n",
      "train loss:1.0290604475134357\n",
      "train loss:1.019803000616957\n",
      "train loss:1.0333147981684663\n",
      "train loss:1.1268240155763272\n",
      "train loss:1.0025215487870782\n",
      "train loss:1.0489917719517297\n",
      "train loss:1.0065492449287126\n",
      "train loss:1.017875916286286\n",
      "train loss:1.0045314113895532\n",
      "train loss:1.0790943192123768\n",
      "train loss:0.963240682039073\n",
      "train loss:0.9392982893736089\n",
      "train loss:0.949827017867856\n",
      "train loss:0.930389587435108\n",
      "train loss:0.9007481689576403\n",
      "train loss:0.9795820342521268\n",
      "train loss:0.819422514990694\n",
      "train loss:1.216106984743602\n",
      "train loss:0.7828216581729555\n",
      "train loss:0.9908453178011328\n",
      "train loss:1.0822490881943774\n",
      "train loss:1.0321663592790262\n",
      "train loss:0.9551868977866724\n",
      "train loss:1.0447901219111424\n",
      "train loss:0.9430300740362623\n",
      "train loss:1.0717364719666638\n",
      "train loss:1.2350999796773086\n",
      "train loss:0.9938212553065651\n",
      "train loss:1.0987772558715536\n",
      "train loss:1.0247449378002855\n",
      "train loss:1.049758377298283\n",
      "train loss:0.9558299759629157\n",
      "train loss:0.988769472495585\n",
      "train loss:1.1402390587087838\n",
      "train loss:1.0192247910504044\n",
      "train loss:0.8782162798087759\n",
      "train loss:1.0637624530638872\n",
      "train loss:1.0600753961400893\n",
      "train loss:0.947406806913634\n",
      "train loss:0.8613763512688142\n",
      "train loss:0.9280169060483603\n",
      "train loss:0.7670505398279462\n",
      "train loss:1.1069442712886284\n",
      "train loss:1.0325142601675716\n",
      "train loss:1.1497525040809993\n",
      "train loss:0.8643574414683504\n",
      "train loss:1.0345331356295469\n",
      "train loss:0.8252271224483932\n",
      "train loss:1.0233796137775304\n",
      "train loss:0.9626730177604352\n",
      "train loss:1.0057666545772868\n",
      "train loss:0.9593125685696096\n",
      "train loss:0.9574241799157162\n",
      "train loss:1.0341278814549728\n",
      "train loss:1.0725875530839013\n",
      "train loss:0.9306783243474541\n",
      "train loss:0.8884253342665431\n",
      "train loss:0.9427451609656157\n",
      "train loss:0.9072421275602549\n",
      "train loss:0.9516491885251004\n",
      "train loss:0.9436990556048407\n",
      "train loss:1.0727098073157328\n",
      "train loss:0.9512391343010761\n",
      "train loss:0.8887738897654777\n",
      "train loss:1.0157470975311238\n",
      "train loss:1.0292989296029702\n",
      "train loss:1.0138388290641251\n",
      "train loss:0.9288266481815118\n",
      "train loss:1.0295043669481798\n",
      "train loss:1.1329443924385596\n",
      "train loss:0.9597756948219792\n",
      "train loss:1.0991841691947204\n",
      "train loss:1.0116618138427613\n",
      "train loss:0.9677928361916217\n",
      "train loss:1.1505898882508512\n",
      "train loss:1.0655941890844458\n",
      "train loss:1.0609401697474923\n",
      "train loss:0.8818862659591343\n",
      "train loss:0.9675189097670596\n",
      "train loss:0.8734779272336394\n",
      "train loss:1.062282205254804\n",
      "train loss:0.9748883473778391\n",
      "train loss:0.818962310784532\n",
      "train loss:0.9083781004079777\n",
      "train loss:0.9911242055557632\n",
      "train loss:1.0548192096022175\n",
      "train loss:0.9166760727183159\n",
      "train loss:0.9991643209729392\n",
      "train loss:0.8679048986789176\n",
      "train loss:1.0349328869292047\n",
      "train loss:0.9296305847354414\n",
      "train loss:1.0625326883372102\n",
      "train loss:0.8801885991770019\n",
      "train loss:0.8090535656344012\n",
      "train loss:0.9102221743901688\n",
      "train loss:1.1580883413201617\n",
      "train loss:0.9860733467301063\n",
      "train loss:0.8163094390011529\n",
      "train loss:0.9442690855454593\n",
      "train loss:1.0822835470226957\n",
      "train loss:1.0639454440577167\n",
      "train loss:0.894782010314731\n",
      "train loss:0.8434104790729547\n",
      "train loss:0.9495428543800473\n",
      "train loss:1.0901227882457034\n",
      "train loss:0.8730487311274798\n",
      "train loss:0.9863678672100943\n",
      "train loss:0.916076783062238\n",
      "train loss:0.958199766199462\n",
      "train loss:0.9440610334342067\n",
      "train loss:1.048110844201381\n",
      "train loss:1.0203419351965506\n",
      "train loss:0.8595416537969465\n",
      "train loss:1.0588088502487936\n",
      "train loss:1.0777786215658467\n",
      "train loss:0.8617184887055082\n",
      "train loss:0.9403453586187266\n",
      "train loss:1.0689565058120256\n",
      "train loss:0.8446820440351236\n",
      "train loss:1.009382515549898\n",
      "train loss:0.9799481439379585\n",
      "train loss:0.9922425940834003\n",
      "train loss:0.9414538890273437\n",
      "train loss:1.0085674809742156\n",
      "train loss:0.9907984472788529\n",
      "train loss:0.950064250831867\n",
      "train loss:1.023380186817916\n",
      "train loss:0.9823727331961595\n",
      "train loss:0.896748382871242\n",
      "train loss:1.0543285258049842\n",
      "train loss:1.060566125954324\n",
      "train loss:0.9840176380860863\n",
      "train loss:0.9156291021427687\n",
      "train loss:0.9490621623700037\n",
      "train loss:0.9277668383950664\n",
      "train loss:0.8998499892584576\n",
      "train loss:0.9574025222538631\n",
      "train loss:0.9384282270586016\n",
      "train loss:1.0933537714696222\n",
      "train loss:0.9504747311044853\n",
      "train loss:0.9390727752997506\n",
      "train loss:1.052170881628679\n",
      "train loss:1.05737233224926\n",
      "train loss:0.820632485860316\n",
      "train loss:0.8019214095518495\n",
      "train loss:0.9406564020056948\n",
      "train loss:0.9617205362827614\n",
      "train loss:1.036256315339972\n",
      "train loss:0.9215332695584638\n",
      "train loss:0.8853098537220232\n",
      "train loss:0.952750284884621\n",
      "train loss:0.8526015831665051\n",
      "train loss:1.0452408258694277\n",
      "train loss:1.0269606786375216\n",
      "train loss:0.9097321629988332\n",
      "train loss:0.9679480805671836\n",
      "train loss:1.2649795843057194\n",
      "train loss:1.0448153329574845\n",
      "train loss:0.8933868498742596\n",
      "train loss:0.997891634842626\n",
      "train loss:1.0375510150701603\n",
      "train loss:0.9951818638068844\n",
      "train loss:1.1793640821391198\n",
      "train loss:1.0906228705553813\n",
      "train loss:0.9171378602743768\n",
      "train loss:1.0599774563553217\n",
      "train loss:0.9932138977176018\n",
      "train loss:0.9299080446444159\n",
      "train loss:1.000083415648698\n",
      "train loss:0.9833795901204696\n",
      "train loss:1.1530357258257293\n",
      "train loss:0.7865157705538114\n",
      "train loss:1.0739311306817951\n",
      "train loss:0.9242900702423613\n",
      "train loss:0.9798239229478481\n",
      "train loss:0.9912311327119689\n",
      "train loss:0.9361504854124045\n",
      "train loss:0.9997747470397096\n",
      "train loss:1.011979203913785\n",
      "train loss:1.126469935089692\n",
      "train loss:0.8839008894303636\n",
      "train loss:1.1176546985323301\n",
      "train loss:0.9264825618345595\n",
      "train loss:1.1096672051923628\n",
      "train loss:0.8687564333474236\n",
      "train loss:1.0208713208730376\n",
      "train loss:0.9908035242582305\n",
      "train loss:1.037971548721977\n",
      "train loss:0.8388386025023437\n",
      "train loss:1.0825509031941245\n",
      "train loss:1.0242762201106617\n",
      "train loss:0.892504684651941\n",
      "train loss:0.9890991342089308\n",
      "train loss:1.0301169611819763\n",
      "train loss:1.0429986687960258\n",
      "train loss:1.10740885163298\n",
      "train loss:0.9848498421374435\n",
      "train loss:0.9461814955283288\n",
      "train loss:1.0310644119836867\n",
      "train loss:0.9774779746369733\n",
      "train loss:0.867804006392002\n",
      "train loss:0.9718411943008654\n",
      "train loss:0.8374737502807477\n",
      "train loss:0.9486049925756772\n",
      "train loss:1.1176461303813234\n",
      "train loss:0.8921433199715559\n",
      "train loss:1.0555194193099273\n",
      "train loss:0.9315884286444637\n",
      "train loss:0.8550910626206868\n",
      "train loss:0.9325279562510788\n",
      "train loss:0.9473425964303362\n",
      "train loss:1.0134928652461561\n",
      "train loss:1.1040317223689775\n",
      "train loss:1.0945717773335555\n",
      "train loss:1.0923353061564107\n",
      "train loss:0.8795841996265688\n",
      "train loss:1.006679848025206\n",
      "train loss:0.9390567638748122\n",
      "train loss:0.9400119665601226\n",
      "train loss:0.8345843384849236\n",
      "train loss:1.0119513556225115\n",
      "train loss:0.9019881097672717\n",
      "train loss:1.0756296665040455\n",
      "train loss:1.0929197837946036\n",
      "train loss:1.0813233236575377\n",
      "train loss:0.890843186493545\n",
      "train loss:1.007974604054706\n",
      "train loss:0.9527371691072476\n",
      "train loss:1.0507715235829096\n",
      "train loss:1.0356056351940317\n",
      "train loss:1.0230246025618324\n",
      "train loss:1.0343736330713706\n",
      "train loss:0.8828424251967523\n",
      "train loss:0.7980536230272081\n",
      "train loss:1.0057157914715704\n",
      "train loss:1.067105999095616\n",
      "train loss:0.9270807120410757\n",
      "train loss:0.8356101209108011\n",
      "train loss:1.0322417626598626\n",
      "train loss:1.0060593820204842\n",
      "train loss:1.0847921261096294\n",
      "train loss:1.0640661099211384\n",
      "train loss:0.9518707462985461\n",
      "train loss:0.9348131364976378\n",
      "train loss:0.9100538281294361\n",
      "train loss:1.0711137254195129\n",
      "train loss:0.8962371275883046\n",
      "train loss:1.174975787075627\n",
      "train loss:0.9633109477192157\n",
      "train loss:1.0448474977934328\n",
      "train loss:0.9436611787351201\n",
      "train loss:1.137375349464925\n",
      "train loss:1.0061369658353976\n",
      "train loss:0.9861338880027256\n",
      "train loss:1.0102793696424728\n",
      "train loss:0.9478889888400119\n",
      "train loss:0.9242855345314767\n",
      "train loss:1.0687544737377015\n",
      "train loss:1.0657150634962422\n",
      "train loss:0.7848473808759857\n",
      "train loss:0.9901712495222212\n",
      "train loss:1.0090242317660718\n",
      "train loss:0.8803231054334714\n",
      "train loss:1.0968411730383876\n",
      "train loss:0.9916646445928576\n",
      "train loss:0.9627443855271736\n",
      "train loss:0.9572139366165079\n",
      "train loss:0.8717688379070343\n",
      "train loss:1.1798414205795318\n",
      "train loss:0.9343381391908422\n",
      "train loss:1.0255398775120197\n",
      "train loss:0.8669776003758501\n",
      "train loss:1.0148483427332526\n",
      "train loss:1.0553892956318853\n",
      "train loss:1.092295022091121\n",
      "train loss:0.9436805162532792\n",
      "train loss:0.92600637018193\n",
      "train loss:0.9570259940802193\n",
      "train loss:0.9844063379465464\n",
      "train loss:1.0773007789527274\n",
      "train loss:0.9675817175483759\n",
      "train loss:1.0332085781083042\n",
      "train loss:1.0345058165347103\n",
      "train loss:0.9793237123047622\n",
      "train loss:1.0134841802872425\n",
      "train loss:1.0187299628133382\n",
      "train loss:0.9765113075286869\n",
      "train loss:1.0790803387553571\n",
      "train loss:1.0241108067654294\n",
      "train loss:0.924668797307849\n",
      "train loss:0.8615466044964067\n",
      "train loss:1.0757497488376142\n",
      "train loss:1.0926766490008928\n",
      "train loss:1.0097371954277818\n",
      "train loss:0.8583344378163144\n",
      "train loss:0.8214081111592059\n",
      "train loss:0.8607448630983744\n",
      "train loss:0.916471899124078\n",
      "train loss:1.046768991678838\n",
      "train loss:0.8287480175937528\n",
      "train loss:1.2176708217278722\n",
      "train loss:1.0131033137737595\n",
      "train loss:0.9472490347090818\n",
      "=== epoch:4, train acc:0.987, test acc:0.989 ===\n",
      "train loss:0.7958884467130509\n",
      "train loss:0.879713331531124\n",
      "train loss:1.0407930149046265\n",
      "train loss:1.042233034944704\n",
      "train loss:0.9687550098734568\n",
      "train loss:1.0601259621843635\n",
      "train loss:1.0235110685807742\n",
      "train loss:1.1152319434392233\n",
      "train loss:0.9468037507578733\n",
      "train loss:1.012239386820665\n",
      "train loss:1.0234562670136336\n",
      "train loss:1.0435632014648877\n",
      "train loss:0.8102980469736205\n",
      "train loss:1.0192896344531388\n",
      "train loss:0.8208025184796996\n",
      "train loss:0.936373719954716\n",
      "train loss:0.9595099225036754\n",
      "train loss:1.042518337453292\n",
      "train loss:0.888306880978568\n",
      "train loss:0.9227657539549518\n",
      "train loss:0.7781858021530187\n",
      "train loss:0.8720289439629668\n",
      "train loss:0.8535338795126356\n",
      "train loss:0.9405090372988648\n",
      "train loss:0.9152744421321296\n",
      "train loss:0.785572456345391\n",
      "train loss:0.8241194016178994\n",
      "train loss:1.0447729680740978\n",
      "train loss:1.2191825971318724\n",
      "train loss:1.0940539276400236\n",
      "train loss:0.9874870356575416\n",
      "train loss:0.9580675133710369\n",
      "train loss:0.8977596619763446\n",
      "train loss:1.0018076808704681\n",
      "train loss:1.1096134926792385\n",
      "train loss:0.7528933536364874\n",
      "train loss:0.7818791555622426\n",
      "train loss:0.8715970116711875\n",
      "train loss:0.9526837661296019\n",
      "train loss:1.1296215053256646\n",
      "train loss:0.8040698778490296\n",
      "train loss:0.8621423470804239\n",
      "train loss:0.958642791146575\n",
      "train loss:1.240713740334369\n",
      "train loss:0.9433134375983846\n",
      "train loss:1.0289125483544814\n",
      "train loss:0.9972850980249527\n",
      "train loss:0.9425915780882188\n",
      "train loss:1.1350304308603398\n",
      "train loss:1.2003883225476646\n",
      "train loss:1.0847791905840658\n",
      "train loss:0.8638373288635836\n",
      "train loss:1.0675168941253372\n",
      "train loss:0.9948378619460243\n",
      "train loss:1.023171448236082\n",
      "train loss:0.9380657649929389\n",
      "train loss:0.9456988890242031\n",
      "train loss:0.8935315535577958\n",
      "train loss:0.8831003314453639\n",
      "train loss:1.1132687743985388\n",
      "train loss:0.956986677411547\n",
      "train loss:0.9175355755441934\n",
      "train loss:1.1343509134316974\n",
      "train loss:1.0181611253660214\n",
      "train loss:0.8846321016261481\n",
      "train loss:0.9824228253840026\n",
      "train loss:0.9039939264738469\n",
      "train loss:0.8795582673749229\n",
      "train loss:1.0744309399330974\n",
      "train loss:0.780512894174398\n",
      "train loss:0.9803222052472198\n",
      "train loss:0.9881487752807709\n",
      "train loss:1.0110095695289574\n",
      "train loss:0.9442294142144035\n",
      "train loss:1.0558693395960443\n",
      "train loss:1.0077328125803076\n",
      "train loss:0.7999874628896367\n",
      "train loss:1.0210626310872954\n",
      "train loss:1.057632584101733\n",
      "train loss:0.9231614247824973\n",
      "train loss:1.1849595083630995\n",
      "train loss:0.8736340737246658\n",
      "train loss:0.925814697386037\n",
      "train loss:1.063331807060926\n",
      "train loss:0.8748552162007011\n",
      "train loss:0.9415638021680646\n",
      "train loss:1.046663388695422\n",
      "train loss:0.8672086532475148\n",
      "train loss:0.9328331090705665\n",
      "train loss:0.9496521941091598\n",
      "train loss:1.0063501204734888\n",
      "train loss:0.9998157072658863\n",
      "train loss:0.9225164096418638\n",
      "train loss:1.071288280635826\n",
      "train loss:0.904560831469945\n",
      "train loss:1.236343611686898\n",
      "train loss:1.0261513889854559\n",
      "train loss:0.9840945168016745\n",
      "train loss:0.9311576442766836\n",
      "train loss:1.0779329358293597\n",
      "train loss:0.9638006868630865\n",
      "train loss:0.8299754657722178\n",
      "train loss:0.885893294519868\n",
      "train loss:0.9010318872821181\n",
      "train loss:0.9753567155271047\n",
      "train loss:0.9110787092587017\n",
      "train loss:1.123392369079664\n",
      "train loss:0.8674322827660319\n",
      "train loss:1.0160961566393147\n",
      "train loss:0.9223233914175593\n",
      "train loss:0.7250449104009112\n",
      "train loss:1.0441827632133964\n",
      "train loss:1.0202344521529794\n",
      "train loss:1.0979486571346138\n",
      "train loss:0.8482888970324908\n",
      "train loss:1.2759022447458492\n",
      "train loss:1.0940829891575867\n",
      "train loss:1.071546203428077\n",
      "train loss:1.0664533154087443\n",
      "train loss:1.1327358700512398\n",
      "train loss:0.9070528377208951\n",
      "train loss:0.8594020696505181\n",
      "train loss:1.0079577110022386\n",
      "train loss:1.0520780205225997\n",
      "train loss:0.9598199984039675\n",
      "train loss:0.98318571670263\n",
      "train loss:1.1274301875522104\n",
      "train loss:0.9068444124543056\n",
      "train loss:0.9898675030273004\n",
      "train loss:0.9491984945566578\n",
      "train loss:0.9081918098647486\n",
      "train loss:0.8893030007730538\n",
      "train loss:0.8868580678769892\n",
      "train loss:1.1257190208377823\n",
      "train loss:1.114472071663019\n",
      "train loss:0.8795005619750413\n",
      "train loss:0.9668482651505532\n",
      "train loss:0.9061172137692306\n",
      "train loss:0.9305748713178471\n",
      "train loss:0.8120173911133977\n",
      "train loss:0.9326348830024616\n",
      "train loss:1.1816973122082493\n",
      "train loss:1.0301186557154638\n",
      "train loss:1.0624756466762064\n",
      "train loss:0.9782513420386054\n",
      "train loss:0.9501542098831507\n",
      "train loss:1.0506391226379004\n",
      "train loss:0.8473113208779283\n",
      "train loss:0.7742175219399542\n",
      "train loss:0.883514672690009\n",
      "train loss:0.953947845823301\n",
      "train loss:0.8926191927337327\n",
      "train loss:0.988204143395172\n",
      "train loss:1.0868588185752692\n",
      "train loss:0.9094788759612953\n",
      "train loss:0.9713017916027712\n",
      "train loss:1.0697699401530982\n",
      "train loss:0.8858043546815259\n",
      "train loss:0.9532606346156279\n",
      "train loss:0.983574565292125\n",
      "train loss:0.9199911408847623\n",
      "train loss:1.0308189152298441\n",
      "train loss:0.9506833256641599\n",
      "train loss:0.9572989187831239\n",
      "train loss:0.9293452633061139\n",
      "train loss:0.9465647788910619\n",
      "train loss:0.9879288653476608\n",
      "train loss:0.9100539706073598\n",
      "train loss:0.8676798145728587\n",
      "train loss:0.9768626453908407\n",
      "train loss:1.0995854164893601\n",
      "train loss:0.9563568042925283\n",
      "train loss:0.974681240064737\n",
      "train loss:1.0089581303135282\n",
      "train loss:0.9237786447706737\n",
      "train loss:0.9324284603156489\n",
      "train loss:0.9436081332267976\n",
      "train loss:1.0611124104943976\n",
      "train loss:1.0099836942386593\n",
      "train loss:0.9166220033215796\n",
      "train loss:0.8776615726768398\n",
      "train loss:0.7923789836801634\n",
      "train loss:1.2031524380976517\n",
      "train loss:1.1307258642374485\n",
      "train loss:1.0443383593527091\n",
      "train loss:1.0359441587424938\n",
      "train loss:1.0217213579103184\n",
      "train loss:0.7201112239709702\n",
      "train loss:0.9613728536206281\n",
      "train loss:0.9958242470703567\n",
      "train loss:1.0309708883635171\n",
      "train loss:1.1194198041542793\n",
      "train loss:0.8483873744996688\n",
      "train loss:0.8469756070475029\n",
      "train loss:0.8616589751223158\n",
      "train loss:0.8823177789501567\n",
      "train loss:0.9769578717650649\n",
      "train loss:0.8723449739137326\n",
      "train loss:0.822076577893387\n",
      "train loss:0.8717014859823097\n",
      "train loss:0.967360170844201\n",
      "train loss:1.0507610280900594\n",
      "train loss:0.7401903974856577\n",
      "train loss:0.805038415412621\n",
      "train loss:1.0674607054560468\n",
      "train loss:1.0147707026818467\n",
      "train loss:0.9739154996921188\n",
      "train loss:0.8189373781563952\n",
      "train loss:0.9371638791128184\n",
      "train loss:0.8849421444541288\n",
      "train loss:0.9472723058898883\n",
      "train loss:0.876433276386329\n",
      "train loss:0.9889676359961083\n",
      "train loss:1.190644213620011\n",
      "train loss:1.0135452497340376\n",
      "train loss:0.9916883002804455\n",
      "train loss:0.9876743430196178\n",
      "train loss:0.886688211015723\n",
      "train loss:0.987615440630963\n",
      "train loss:0.9231519410479847\n",
      "train loss:0.9998370671883124\n",
      "train loss:0.9369910729007853\n",
      "train loss:0.9274140830176567\n",
      "train loss:1.0688310908406975\n",
      "train loss:0.8331453924131956\n",
      "train loss:0.9387612229616338\n",
      "train loss:0.9539700335011874\n",
      "train loss:0.8541081152945336\n",
      "train loss:1.1067246630017156\n",
      "train loss:0.9106427316563861\n",
      "train loss:1.1116691570418449\n",
      "train loss:0.94968311528043\n",
      "train loss:1.0218875696461163\n",
      "train loss:1.02878061001306\n",
      "train loss:0.7510641951994743\n",
      "train loss:0.8629176737721069\n",
      "train loss:0.8574967601600798\n",
      "train loss:1.0652203340212911\n",
      "train loss:1.0349138302590204\n",
      "train loss:0.8333159442018274\n",
      "train loss:1.0418944362629494\n",
      "train loss:0.9335262183471501\n",
      "train loss:0.9608097655260854\n",
      "train loss:0.9315303199322895\n",
      "train loss:1.1413827899668778\n",
      "train loss:1.100436748862256\n",
      "train loss:0.987987093616985\n",
      "train loss:0.9690512070038376\n",
      "train loss:1.073969234858673\n",
      "train loss:1.0137583414139923\n",
      "train loss:0.7797064285146716\n",
      "train loss:1.042852537140238\n",
      "train loss:0.9055915966439104\n",
      "train loss:1.018926477180355\n",
      "train loss:0.9946457029237528\n",
      "train loss:0.7665396504574205\n",
      "train loss:0.9391385467731311\n",
      "train loss:0.8502002930369957\n",
      "train loss:0.8575032813980531\n",
      "train loss:0.9742451242655821\n",
      "train loss:0.8823036291191032\n",
      "train loss:1.1314703830569173\n",
      "train loss:1.026421384573809\n",
      "train loss:1.0389332080723732\n",
      "train loss:1.0193721132102038\n",
      "train loss:0.8912405552339608\n",
      "train loss:1.0770545455690372\n",
      "train loss:0.9295561462702889\n",
      "train loss:1.0188872978167958\n",
      "train loss:0.9838827053555871\n",
      "train loss:0.8723241809618522\n",
      "train loss:1.1316087523141667\n",
      "train loss:0.8519675087530849\n",
      "train loss:0.889782617340575\n",
      "train loss:0.970057471508515\n",
      "train loss:0.9560571879280744\n",
      "train loss:1.0508034784878502\n",
      "train loss:0.9047853915255198\n",
      "train loss:0.9015173761558383\n",
      "train loss:1.0075352876178993\n",
      "train loss:1.0315423436620952\n",
      "train loss:0.8104389915611998\n",
      "train loss:0.8445903401489961\n",
      "train loss:1.0842437022394082\n",
      "train loss:0.9675268968106269\n",
      "train loss:1.0936739549416705\n",
      "train loss:0.9373066485413414\n",
      "train loss:0.9479700478889177\n",
      "train loss:1.1423376232684672\n",
      "train loss:0.9963360926130918\n",
      "train loss:0.8498639500655064\n",
      "train loss:0.9618967977683697\n",
      "train loss:1.1769269595973055\n",
      "train loss:0.9416587726916178\n",
      "train loss:0.9123533663436347\n",
      "train loss:0.9245472871725977\n",
      "train loss:1.050295471722113\n",
      "train loss:0.9816236941145964\n",
      "train loss:0.9659792003999412\n",
      "train loss:1.154549250988463\n",
      "train loss:0.9245092310089698\n",
      "train loss:0.9286260349948146\n",
      "train loss:0.8966820048013956\n",
      "train loss:0.81929688690352\n",
      "train loss:1.173031767592567\n",
      "train loss:0.9135076639146259\n",
      "train loss:1.1568558298661444\n",
      "train loss:0.8259884199245733\n",
      "train loss:0.8111586924442712\n",
      "train loss:0.9905487392705798\n",
      "train loss:0.9911537338287535\n",
      "train loss:0.9017451082739305\n",
      "train loss:1.0163843247779727\n",
      "train loss:1.0255015940709722\n",
      "train loss:0.9021844644325738\n",
      "train loss:1.0210465033953133\n",
      "train loss:0.9177608218927272\n",
      "train loss:0.9988615022539222\n",
      "train loss:0.777462394623181\n",
      "train loss:0.9867874302349261\n",
      "train loss:0.875544171536932\n",
      "train loss:0.8976743768181186\n",
      "train loss:0.9107314533923733\n",
      "train loss:0.8926387142650303\n",
      "train loss:1.0584799275430499\n",
      "train loss:0.912902481121467\n",
      "train loss:0.835673866027696\n",
      "train loss:0.9475723427806569\n",
      "train loss:0.9258010318426902\n",
      "train loss:0.9001956188497552\n",
      "train loss:1.121951316665301\n",
      "train loss:0.9098232402779978\n",
      "train loss:1.1595122476542663\n",
      "train loss:1.0464603024084083\n",
      "train loss:0.9879704605338188\n",
      "train loss:0.8544260135767118\n",
      "train loss:1.0198512989698223\n",
      "train loss:0.8826815319983461\n",
      "train loss:0.816822761429847\n",
      "train loss:0.9270290681903656\n",
      "train loss:1.026483549964371\n",
      "train loss:0.8071288135085815\n",
      "train loss:1.1845335122912586\n",
      "train loss:0.798505196678204\n",
      "train loss:0.8472273092417\n",
      "train loss:1.0107558865132766\n",
      "train loss:0.8505316877901923\n",
      "train loss:0.9489260734908355\n",
      "train loss:0.9858594903271173\n",
      "train loss:1.2590543570574981\n",
      "train loss:1.0814337942506698\n",
      "train loss:0.9939918865958053\n",
      "train loss:0.9261883697314087\n",
      "train loss:0.8893427020655597\n",
      "train loss:1.0951589006945688\n",
      "train loss:0.9765464506198198\n",
      "train loss:1.0249683610883302\n",
      "train loss:0.9855282245972802\n",
      "train loss:0.9534154879667427\n",
      "train loss:1.1112224202666852\n",
      "train loss:1.1555478300656505\n",
      "train loss:0.9610690171410461\n",
      "train loss:1.0349606437043202\n",
      "train loss:1.103111780838637\n",
      "train loss:0.8971298435381724\n",
      "train loss:1.2615489140278677\n",
      "train loss:0.9263175102376766\n",
      "train loss:0.885435413021786\n",
      "train loss:0.9815311086143552\n",
      "train loss:0.956127359946115\n",
      "train loss:1.0010494415792137\n",
      "train loss:0.9337921656870494\n",
      "train loss:1.0176704625935329\n",
      "train loss:1.2438013323799182\n",
      "train loss:0.8982392043138681\n",
      "train loss:0.8204206876239952\n",
      "train loss:0.8015992826000086\n",
      "train loss:0.9741871759544353\n",
      "train loss:0.8869831812678303\n",
      "train loss:0.9617205940808372\n",
      "train loss:0.9761776179519337\n",
      "train loss:0.9186602493122301\n",
      "train loss:0.8714548542662809\n",
      "train loss:1.0402299795795003\n",
      "train loss:0.8324922661301808\n",
      "train loss:0.9892376844297757\n",
      "train loss:0.9253112482537742\n",
      "train loss:0.9914196555637672\n",
      "train loss:0.8354661428593563\n",
      "train loss:0.8919925219825403\n",
      "train loss:0.8176990775749092\n",
      "train loss:0.9224147975662311\n",
      "train loss:0.951831309360613\n",
      "train loss:0.9382636664664972\n",
      "train loss:0.7789949212428563\n",
      "train loss:0.9184398685145294\n",
      "train loss:0.9051932971327661\n",
      "train loss:1.0258170247405554\n",
      "train loss:0.9571538174503244\n",
      "train loss:0.886093374512529\n",
      "train loss:0.971913811861651\n",
      "train loss:1.0061597264798368\n",
      "train loss:0.933828815394049\n",
      "train loss:0.901643976128957\n",
      "train loss:1.0941475770641338\n",
      "train loss:0.8810184782876196\n",
      "train loss:0.8415305758714058\n",
      "train loss:0.7770180778234274\n",
      "train loss:1.0541094192121634\n",
      "train loss:0.8798578833601023\n",
      "train loss:1.0088674891637577\n",
      "train loss:0.7495629395319806\n",
      "train loss:0.8742362658115046\n",
      "train loss:0.8626139503772587\n",
      "train loss:0.8768463485232886\n",
      "train loss:0.9354759381956399\n",
      "train loss:0.9401035505437172\n",
      "train loss:1.028993272197891\n",
      "train loss:0.9632362200154111\n",
      "train loss:1.058357021957958\n",
      "train loss:0.9885732735806657\n",
      "train loss:0.9408835696567004\n",
      "train loss:0.9396017360987936\n",
      "train loss:1.085481155627648\n",
      "train loss:0.9365270201430569\n",
      "train loss:0.8822376087288233\n",
      "train loss:0.9120808759662841\n",
      "train loss:0.7739068019365994\n",
      "train loss:1.0114701657379788\n",
      "train loss:1.1362400848644116\n",
      "train loss:0.8205844368904158\n",
      "train loss:0.9057352591340275\n",
      "train loss:1.094653843239528\n",
      "train loss:1.0610180920040004\n",
      "train loss:1.0841590284978047\n",
      "train loss:0.9265069712214207\n",
      "train loss:0.8456543010573214\n",
      "train loss:0.8741592348468697\n",
      "train loss:0.9614284198929921\n",
      "train loss:0.948625789001634\n",
      "train loss:1.0086231978185258\n",
      "train loss:0.9958972229522242\n",
      "train loss:1.0004283713087556\n",
      "train loss:0.7524026225443761\n",
      "train loss:0.9622038658647923\n",
      "train loss:0.8480105237451929\n",
      "train loss:0.8856907820054835\n",
      "train loss:0.7641137094948671\n",
      "train loss:0.7654900067254657\n",
      "train loss:0.9311471097039474\n",
      "train loss:0.7556809181598757\n",
      "train loss:0.8569648011489994\n",
      "train loss:0.8632058960193956\n",
      "train loss:0.8986394516014236\n",
      "train loss:0.9436830388710811\n",
      "train loss:0.8993970754031051\n",
      "train loss:0.9124372060198119\n",
      "train loss:0.8897821821909794\n",
      "train loss:0.9596764245756129\n",
      "train loss:1.0704314328607976\n",
      "train loss:0.9507083800779316\n",
      "train loss:1.116555503613648\n",
      "train loss:0.9370723974431692\n",
      "train loss:0.9027258598863596\n",
      "train loss:1.0417236422879477\n",
      "train loss:0.948492876768759\n",
      "train loss:0.928097649697115\n",
      "train loss:0.9158088697681771\n",
      "train loss:0.9319851718003354\n",
      "train loss:0.9906296902698043\n",
      "train loss:0.9584923440028709\n",
      "train loss:0.8101677707269065\n",
      "train loss:0.850232405894658\n",
      "train loss:1.0133764451756975\n",
      "train loss:0.9131363016654201\n",
      "train loss:0.8847802871984581\n",
      "train loss:0.7649330283331808\n",
      "train loss:0.9598378099637881\n",
      "train loss:0.8773883493855188\n",
      "train loss:0.86749751836607\n",
      "train loss:1.0078394337246876\n",
      "train loss:0.7467167483875934\n",
      "train loss:1.0187316369021877\n",
      "train loss:0.9233752471121693\n",
      "train loss:0.9372262963452888\n",
      "train loss:0.8886056450644844\n",
      "train loss:0.8759758580227861\n",
      "train loss:1.025835138660416\n",
      "train loss:1.0089798271960344\n",
      "train loss:1.0714581555343308\n",
      "train loss:1.1047195237326235\n",
      "train loss:0.8180177020217285\n",
      "train loss:0.9049496856234238\n",
      "train loss:0.9648416085373003\n",
      "train loss:0.9102566615154767\n",
      "train loss:0.8860224160158241\n",
      "train loss:0.8113091660915734\n",
      "train loss:0.9389586992583893\n",
      "train loss:0.9623134562706716\n",
      "train loss:1.1101741811046317\n",
      "train loss:1.0542303967110747\n",
      "train loss:1.0267731286656465\n",
      "train loss:0.897478795721865\n",
      "train loss:0.6704361805929906\n",
      "train loss:1.0084182593417634\n",
      "train loss:0.9145463906506072\n",
      "train loss:0.8784377362240114\n",
      "train loss:0.8379229012929652\n",
      "train loss:0.9158919791454754\n",
      "train loss:1.0101901573112575\n",
      "train loss:1.0693734568945978\n",
      "train loss:0.9179790245183902\n",
      "train loss:0.9504203787866378\n",
      "train loss:0.9044344176754735\n",
      "train loss:0.9105848509365978\n",
      "train loss:0.8789399049950144\n",
      "train loss:0.8358192240075129\n",
      "train loss:0.8136842227845926\n",
      "train loss:0.7700312513393416\n",
      "train loss:1.0362210855098224\n",
      "train loss:0.7404671788686693\n",
      "train loss:0.8761542120540358\n",
      "train loss:1.0117377382129003\n",
      "train loss:0.8743720247629264\n",
      "train loss:1.070271956035602\n",
      "train loss:0.8559098448266431\n",
      "train loss:1.0009564005835443\n",
      "train loss:0.908025011509867\n",
      "train loss:0.751121253652485\n",
      "train loss:0.8689994798682231\n",
      "train loss:0.976161116576161\n",
      "train loss:0.8270710716453931\n",
      "train loss:0.9648068562686873\n",
      "train loss:1.0126384825981587\n",
      "train loss:0.9933553988893054\n",
      "train loss:0.8203719411508064\n",
      "train loss:0.9666637031703053\n",
      "train loss:0.8177918736326507\n",
      "train loss:0.904403455822615\n",
      "train loss:0.8548405560069129\n",
      "train loss:1.0047349375179515\n",
      "train loss:0.9572870262481795\n",
      "train loss:1.0105488405834424\n",
      "train loss:0.9446900146517208\n",
      "train loss:1.061699515162385\n",
      "train loss:0.8540611790162668\n",
      "train loss:0.8318998815068299\n",
      "train loss:0.9118115573877449\n",
      "train loss:1.0951103083154343\n",
      "train loss:0.994353232333963\n",
      "train loss:0.779045298135016\n",
      "train loss:0.9627867757012935\n",
      "train loss:0.8501703834828881\n",
      "train loss:0.9310740962479196\n",
      "train loss:0.9254834865915109\n",
      "train loss:0.8844041543106894\n",
      "train loss:0.8623311506321838\n",
      "train loss:1.011298211357702\n",
      "train loss:0.8884249798270983\n",
      "train loss:1.0872355226328387\n",
      "train loss:0.9457410833946654\n",
      "train loss:0.957014450887077\n",
      "train loss:0.8206485227750022\n",
      "train loss:0.8757620053500471\n",
      "train loss:1.0150563989956298\n",
      "train loss:0.9363552514975972\n",
      "train loss:0.8709295618408193\n",
      "train loss:1.1179640037139624\n",
      "train loss:0.9244562015631094\n",
      "train loss:1.0898908009421557\n",
      "train loss:0.8684631942248048\n",
      "train loss:0.9413728737504847\n",
      "train loss:1.001468118690304\n",
      "train loss:0.8136735610865728\n",
      "train loss:0.9959717136215979\n",
      "train loss:1.0088116600733597\n",
      "train loss:1.0445796336047501\n",
      "train loss:1.058538847843024\n",
      "train loss:0.9847402379641744\n",
      "train loss:1.0724262117230605\n",
      "train loss:0.8001827597634648\n",
      "train loss:1.0103177897880995\n",
      "train loss:0.9221255180818579\n",
      "train loss:0.9732488536298601\n",
      "train loss:1.0214239799379141\n",
      "train loss:0.9497360153272583\n",
      "train loss:0.9406768704541361\n",
      "train loss:1.0181737105060509\n",
      "train loss:0.9085226978018969\n",
      "train loss:1.1030778898945501\n",
      "train loss:0.9657384709857141\n",
      "train loss:1.0005016868265417\n",
      "train loss:0.8824660240666562\n",
      "train loss:1.0193262668750198\n",
      "train loss:0.9345634290764003\n",
      "train loss:0.7865953794039257\n",
      "train loss:0.8155731993050547\n",
      "train loss:0.7827642541073296\n",
      "train loss:1.0741767226368575\n",
      "train loss:0.9368907114821071\n",
      "=== epoch:5, train acc:0.992, test acc:0.991 ===\n",
      "train loss:1.011597655828931\n",
      "train loss:0.9543581577650374\n",
      "train loss:1.0431675401692253\n",
      "train loss:1.0129710103468654\n",
      "train loss:0.8006564943414112\n",
      "train loss:0.8228904607325305\n",
      "train loss:0.8331012773042602\n",
      "train loss:0.8825367529056297\n",
      "train loss:0.9632301326701483\n",
      "train loss:0.9137808426309197\n",
      "train loss:0.9065973974453883\n",
      "train loss:0.9883899149047641\n",
      "train loss:1.0231946088393005\n",
      "train loss:0.8330748903102451\n",
      "train loss:0.982419306465665\n",
      "train loss:0.8933336235585749\n",
      "train loss:0.8977798944317854\n",
      "train loss:0.8720481307663219\n",
      "train loss:0.9343480998909109\n",
      "train loss:1.0197838738298615\n",
      "train loss:0.8432400865391003\n",
      "train loss:0.9580719221742511\n",
      "train loss:1.0310417735190363\n",
      "train loss:0.853070336189696\n",
      "train loss:0.9061013155385664\n",
      "train loss:0.9975986420663366\n",
      "train loss:1.1368182833631544\n",
      "train loss:1.0458366502524112\n",
      "train loss:0.8782286584789846\n",
      "train loss:0.772282702302364\n",
      "train loss:0.9360132846118467\n",
      "train loss:0.9668848614180221\n",
      "train loss:0.8868746544598263\n",
      "train loss:0.849890857443705\n",
      "train loss:1.004320338736943\n",
      "train loss:0.9803426863660506\n",
      "train loss:1.0258512767999732\n",
      "train loss:0.8733284229417068\n",
      "train loss:0.9296260111114225\n",
      "train loss:1.0390267217897569\n",
      "train loss:1.0788052928933\n",
      "train loss:1.0547448339607637\n",
      "train loss:1.0163737009218243\n",
      "train loss:1.0429145833504767\n",
      "train loss:1.1691205090159422\n",
      "train loss:0.9476329829064276\n",
      "train loss:1.0208657472576839\n",
      "train loss:1.0439265446281711\n",
      "train loss:0.9620867462554117\n",
      "train loss:0.9520217692507775\n",
      "train loss:0.9590905044262265\n",
      "train loss:0.9579679351748704\n",
      "train loss:1.04519046684116\n",
      "train loss:0.860836767467527\n",
      "train loss:0.9806143240442242\n",
      "train loss:0.9893899872991941\n",
      "train loss:0.8177179819549031\n",
      "train loss:0.8607653002949271\n",
      "train loss:0.832171955929608\n",
      "train loss:0.8633766760842155\n",
      "train loss:0.8631461508980897\n",
      "train loss:0.9693419832696649\n",
      "train loss:0.7984966472659148\n",
      "train loss:1.02449583418045\n",
      "train loss:0.8045203450118951\n",
      "train loss:0.6985241396412271\n",
      "train loss:0.98955269245202\n",
      "train loss:1.048032018225947\n",
      "train loss:0.8793021834387146\n",
      "train loss:1.0464599832156605\n",
      "train loss:0.8578443196826785\n",
      "train loss:1.019653966020951\n",
      "train loss:0.9817933167887775\n",
      "train loss:0.9190785843444041\n",
      "train loss:0.9082109427577693\n",
      "train loss:0.8580065964403178\n",
      "train loss:0.9019956673901196\n",
      "train loss:0.9704810400930386\n",
      "train loss:0.9104024859196674\n",
      "train loss:1.0505236549560304\n",
      "train loss:0.9762355671344565\n",
      "train loss:0.9452469210833755\n",
      "train loss:0.8727799221788185\n",
      "train loss:0.8307624382893078\n",
      "train loss:1.0651418516794804\n",
      "train loss:0.9760677611979722\n",
      "train loss:0.9873660615873263\n",
      "train loss:0.9611106905779749\n",
      "train loss:0.9891685738357325\n",
      "train loss:1.0890997108014158\n",
      "train loss:0.7999257304711465\n",
      "train loss:0.7975153343317607\n",
      "train loss:0.9295328563235532\n",
      "train loss:0.7782190462924388\n",
      "train loss:1.0649127379578802\n",
      "train loss:0.9363451645659695\n",
      "train loss:1.104272211906839\n",
      "train loss:0.8653385367087387\n",
      "train loss:0.8863358542496016\n",
      "train loss:0.8691446759071039\n",
      "train loss:1.0135469966409971\n",
      "train loss:0.8254490897136877\n",
      "train loss:0.8834346401879766\n",
      "train loss:1.0647747990850451\n",
      "train loss:0.9118170835260293\n",
      "train loss:1.163108076510532\n",
      "train loss:1.1111444075046897\n",
      "train loss:0.9194872254656701\n",
      "train loss:1.137603429945826\n",
      "train loss:0.9553006822593605\n",
      "train loss:1.032115797658653\n",
      "train loss:0.944577842263696\n",
      "train loss:1.1826850146446184\n",
      "train loss:1.018450512508149\n",
      "train loss:0.9254491394125339\n",
      "train loss:0.9276915655350141\n",
      "train loss:0.8597737661211393\n",
      "train loss:0.9152511405387728\n",
      "train loss:0.7158501938529078\n",
      "train loss:0.8772610437997629\n",
      "train loss:0.9155406677903316\n",
      "train loss:0.8399554536128909\n",
      "train loss:0.9315492804305405\n",
      "train loss:0.8996960542359292\n",
      "train loss:0.8655000537365628\n",
      "train loss:0.8637059433280537\n",
      "train loss:0.9263342735231785\n",
      "train loss:0.9004942429838277\n",
      "train loss:0.8961182334756532\n",
      "train loss:1.078109940758617\n",
      "train loss:0.9292416829484113\n",
      "train loss:0.9943547252525599\n",
      "train loss:0.804840391385536\n",
      "train loss:0.9475538571672348\n",
      "train loss:0.8781321660143697\n",
      "train loss:1.0314846660474641\n",
      "train loss:0.9549847613687911\n",
      "train loss:1.0245536608265553\n",
      "train loss:0.8847823080549405\n",
      "train loss:0.9490312160373087\n",
      "train loss:0.8820496297960554\n",
      "train loss:0.9886131621715833\n",
      "train loss:0.9377161429106632\n",
      "train loss:0.9905604388608898\n",
      "train loss:0.8890978140549337\n",
      "train loss:1.005631763010954\n",
      "train loss:0.784933004779638\n",
      "train loss:0.9396215678339669\n",
      "train loss:1.0090125862878252\n",
      "train loss:1.0719101982406636\n",
      "train loss:1.0064336239147857\n",
      "train loss:0.8435156313007213\n",
      "train loss:0.9849489145040744\n",
      "train loss:1.0494784788713196\n",
      "train loss:0.8224152986324771\n",
      "train loss:1.0329684732413122\n",
      "train loss:0.9684715723015421\n",
      "train loss:1.0026710400788603\n",
      "train loss:0.9138969464222271\n",
      "train loss:1.0977215389003436\n",
      "train loss:0.9948437810706242\n",
      "train loss:0.8677082950460182\n",
      "train loss:0.7976012252964764\n",
      "train loss:0.9703188351352051\n",
      "train loss:0.9981866219075148\n",
      "train loss:0.9031759324788383\n",
      "train loss:0.9004422637194938\n",
      "train loss:0.8652235929333573\n",
      "train loss:0.8882498089115363\n",
      "train loss:0.8466171067398959\n",
      "train loss:0.8838648045026198\n",
      "train loss:0.8943515731255629\n",
      "train loss:0.8909385768528024\n",
      "train loss:0.9236888044666965\n",
      "train loss:1.0055350328012942\n",
      "train loss:0.8201362282456257\n",
      "train loss:1.099836342203605\n",
      "train loss:0.9514327828392167\n",
      "train loss:1.0400764538486194\n",
      "train loss:0.8425576281724588\n",
      "train loss:0.928952591735622\n",
      "train loss:0.7965160734721981\n",
      "train loss:0.9800413046801993\n",
      "train loss:0.9965815155430081\n",
      "train loss:1.0256976430880782\n",
      "train loss:0.8975281389788005\n",
      "train loss:0.8762356926313456\n",
      "train loss:1.03438032403897\n",
      "train loss:0.8301940176316268\n",
      "train loss:0.9835719397609938\n",
      "train loss:0.9324264859207082\n",
      "train loss:0.9594041701387692\n",
      "train loss:0.8788548170263739\n",
      "train loss:0.8941118597045863\n",
      "train loss:0.9823853979219801\n",
      "train loss:0.9597417024894945\n",
      "train loss:0.8310996808856594\n",
      "train loss:1.0215327664430411\n",
      "train loss:1.0843628714986255\n",
      "train loss:0.9230633928134502\n",
      "train loss:0.9416291438105564\n",
      "train loss:1.012343169964185\n",
      "train loss:1.0580475086373158\n",
      "train loss:0.8555203153467678\n",
      "train loss:1.012631368997198\n",
      "train loss:1.0558479380407204\n",
      "train loss:1.137862730970794\n",
      "train loss:0.8712171724664336\n",
      "train loss:0.9511999254699839\n",
      "train loss:0.915220239618193\n",
      "train loss:1.0525139747685122\n",
      "train loss:0.857067694894534\n",
      "train loss:0.8753809043577867\n",
      "train loss:1.0165936224345777\n",
      "train loss:0.9422996326371073\n",
      "train loss:0.910500116856751\n",
      "train loss:0.9759952524142852\n",
      "train loss:1.0340246550749952\n",
      "train loss:0.9593374093393697\n",
      "train loss:0.8645842812825056\n",
      "train loss:0.9004591717323998\n",
      "train loss:0.9258721705243487\n",
      "train loss:0.9332959472004316\n",
      "train loss:0.9195977472511909\n",
      "train loss:1.0049841363494851\n",
      "train loss:0.9580125390785826\n",
      "train loss:0.9245184146290895\n",
      "train loss:0.6311996455745285\n",
      "train loss:0.7766009153233557\n",
      "train loss:0.9219914309719194\n",
      "train loss:0.9236112230927769\n",
      "train loss:0.8551039245166312\n",
      "train loss:0.9416881493069731\n",
      "train loss:0.8430518433399037\n",
      "train loss:0.7836712465825362\n",
      "train loss:1.029920408046323\n",
      "train loss:1.0779425191341936\n",
      "train loss:0.8772931797687368\n",
      "train loss:1.015720529482416\n",
      "train loss:0.8196113612096962\n",
      "train loss:0.7910123394802226\n",
      "train loss:0.752683453195704\n",
      "train loss:0.9546770050658\n",
      "train loss:0.7983272049364585\n",
      "train loss:1.0029591792590962\n",
      "train loss:1.0603844838904002\n",
      "train loss:0.9787634942110093\n",
      "train loss:0.7842834237147717\n",
      "train loss:0.921706907575682\n",
      "train loss:1.0294102321401244\n",
      "train loss:0.9123200798719509\n",
      "train loss:0.9624797032299709\n",
      "train loss:1.0818272947988254\n",
      "train loss:0.8676986144083707\n",
      "train loss:0.908802364452732\n",
      "train loss:0.9499487202911229\n",
      "train loss:0.9744179858079282\n",
      "train loss:0.8958098963286275\n",
      "train loss:1.0726139678253128\n",
      "train loss:1.2052142246917716\n",
      "train loss:0.8182698467498122\n",
      "train loss:0.9621450860449327\n",
      "train loss:1.102123301031588\n",
      "train loss:0.7370697457083151\n",
      "train loss:0.8778118930959635\n",
      "train loss:1.008685126992637\n",
      "train loss:0.9160852090598864\n",
      "train loss:1.0981952174455427\n",
      "train loss:0.9710007739026119\n",
      "train loss:0.9297218492877204\n",
      "train loss:0.9097662341514137\n",
      "train loss:1.073669711573344\n",
      "train loss:0.8167230349810525\n",
      "train loss:0.9615061360996279\n",
      "train loss:1.128879072537761\n",
      "train loss:0.8293993259679746\n",
      "train loss:0.9424949227115215\n",
      "train loss:0.9558701245694412\n",
      "train loss:0.9373613158894947\n",
      "train loss:1.0427222085107863\n",
      "train loss:1.0876222345532396\n",
      "train loss:1.112758241474559\n",
      "train loss:0.9717413388779179\n",
      "train loss:0.9599052549732464\n",
      "train loss:1.0973498353909183\n",
      "train loss:1.0144094619234558\n",
      "train loss:0.9816900107993621\n",
      "train loss:0.9529339574850607\n",
      "train loss:1.131785754199057\n",
      "train loss:0.9963126549030874\n",
      "train loss:1.0618533163873107\n",
      "train loss:1.0310592745207419\n",
      "train loss:1.0076435768199112\n",
      "train loss:0.9181350579683677\n",
      "train loss:0.9297927516486888\n",
      "train loss:1.122186011578964\n",
      "train loss:1.0512708211801511\n",
      "train loss:0.7890606018522353\n",
      "train loss:0.907826103137183\n",
      "train loss:1.0060348038582523\n",
      "train loss:0.8853207097491225\n",
      "train loss:0.9115625823969201\n",
      "train loss:1.0007906179751793\n",
      "train loss:0.92038733607478\n",
      "train loss:0.8843023372810592\n",
      "train loss:0.8282122126932968\n",
      "train loss:0.9283627648189436\n",
      "train loss:0.8921968661190073\n",
      "train loss:0.9849050183021218\n",
      "train loss:0.9019175875270082\n",
      "train loss:0.8468975131630815\n",
      "train loss:1.0453966214156958\n",
      "train loss:0.8209898167138101\n",
      "train loss:1.0728062796772104\n",
      "train loss:0.8096867816286389\n",
      "train loss:1.028955401151718\n",
      "train loss:0.9714548797016477\n",
      "train loss:0.9004383930220993\n",
      "train loss:0.840663113625983\n",
      "train loss:1.0308404027131757\n",
      "train loss:1.171428298660769\n",
      "train loss:0.9741695344822665\n",
      "train loss:0.952687721582498\n",
      "train loss:0.8309241016929642\n",
      "train loss:0.980478299966202\n",
      "train loss:0.9501760366209149\n",
      "train loss:0.9310558378442156\n",
      "train loss:1.0240801962943793\n",
      "train loss:0.9656704920143884\n",
      "train loss:0.9330510800997687\n",
      "train loss:0.9758728074523251\n",
      "train loss:0.836960877951962\n",
      "train loss:0.8775855204742032\n",
      "train loss:1.1191587164911923\n",
      "train loss:0.8855321944953154\n",
      "train loss:1.011103284746893\n",
      "train loss:0.9870386301635575\n",
      "train loss:1.0125635401322517\n",
      "train loss:0.91816594864931\n",
      "train loss:1.0390376896223785\n",
      "train loss:0.976001230262957\n",
      "train loss:0.9131793928713808\n",
      "train loss:0.8986015892719296\n",
      "train loss:0.8086068521145465\n",
      "train loss:0.9325324375135132\n",
      "train loss:0.8407293647592655\n",
      "train loss:0.9089115392018756\n",
      "train loss:0.9840267071961974\n",
      "train loss:0.6780489871938253\n",
      "train loss:0.9353859391296018\n",
      "train loss:0.9633015926678791\n",
      "train loss:0.9533955386751859\n",
      "train loss:1.049450831582732\n",
      "train loss:0.8925411522824934\n",
      "train loss:0.9257293073381024\n",
      "train loss:0.9214201299320288\n",
      "train loss:1.0379943224443655\n",
      "train loss:0.8926789050080582\n",
      "train loss:0.8190235962907378\n",
      "train loss:0.8062693139969652\n",
      "train loss:0.9792824294416503\n",
      "train loss:0.915066957622412\n",
      "train loss:0.9396531473115067\n",
      "train loss:0.8787973092000837\n",
      "train loss:1.0912642835141482\n",
      "train loss:0.867020894046449\n",
      "train loss:1.0605466075320251\n",
      "train loss:0.8348510124457482\n",
      "train loss:1.0191249211692661\n",
      "train loss:0.9479841268777308\n",
      "train loss:0.7399635125833152\n",
      "train loss:1.0031585758752097\n",
      "train loss:1.1569635736357118\n",
      "train loss:1.1762106204163283\n",
      "train loss:0.9567037060616786\n",
      "train loss:1.0362739160309276\n",
      "train loss:0.9290395852412202\n",
      "train loss:0.9600710035821288\n",
      "train loss:0.992186245104484\n",
      "train loss:0.9820671523643923\n",
      "train loss:0.9702096573648433\n",
      "train loss:1.200492841327183\n",
      "train loss:0.8330944168335178\n",
      "train loss:0.9739402647677976\n",
      "train loss:0.9282460236523336\n",
      "train loss:0.9614882240243245\n",
      "train loss:0.8792554725045659\n",
      "train loss:0.9664715226428465\n",
      "train loss:1.0435722745977685\n",
      "train loss:0.9608547037959104\n",
      "train loss:0.8218297437713504\n",
      "train loss:0.8987719532053737\n",
      "train loss:0.8759952558031275\n",
      "train loss:1.0308683719193545\n",
      "train loss:0.8649818879276542\n",
      "train loss:1.004125997184329\n",
      "train loss:0.9207289261636062\n",
      "train loss:0.9104380497106791\n",
      "train loss:0.8906656296718968\n",
      "train loss:0.8612883307943399\n",
      "train loss:0.914145814731754\n",
      "train loss:0.9072144899093693\n",
      "train loss:1.001990418473998\n",
      "train loss:1.006022518756557\n",
      "train loss:1.0592642368040592\n",
      "train loss:0.8891668172777726\n",
      "train loss:0.8362350947408045\n",
      "train loss:0.8307601070332337\n",
      "train loss:0.9733930882532489\n",
      "train loss:1.0021869247061617\n",
      "train loss:0.9760089378458894\n",
      "train loss:1.0392291423130318\n",
      "train loss:0.8910767640908213\n",
      "train loss:0.9484436028814328\n",
      "train loss:1.1497128159822934\n",
      "train loss:1.214491008824938\n",
      "train loss:0.8117006197426884\n",
      "train loss:0.8102022150262477\n",
      "train loss:0.9887218797376138\n",
      "train loss:0.9501300976531712\n",
      "train loss:0.8939737834751242\n",
      "train loss:0.9522455629084453\n",
      "train loss:1.0000637520320823\n",
      "train loss:0.9349731026770232\n",
      "train loss:0.8624770961275321\n",
      "train loss:1.063100270971036\n",
      "train loss:0.8640536064808818\n",
      "train loss:0.9503149611013952\n",
      "train loss:0.8577779768249829\n",
      "train loss:0.8313404322380685\n",
      "train loss:0.8227494455210188\n",
      "train loss:0.9456815931567292\n",
      "train loss:0.9654811780660867\n",
      "train loss:0.9526941868612318\n",
      "train loss:1.028000347088257\n",
      "train loss:0.9646662985808989\n",
      "train loss:0.9746892603527381\n",
      "train loss:1.0523623052282935\n",
      "train loss:1.1174854678609818\n",
      "train loss:0.8756247270104014\n",
      "train loss:0.908674134646564\n",
      "train loss:0.8975022479501006\n",
      "train loss:1.1955193302087423\n",
      "train loss:0.8610936158703449\n",
      "train loss:0.8798996198286763\n",
      "train loss:0.8143242742364208\n",
      "train loss:0.9729903235565093\n",
      "train loss:0.8719444003574662\n",
      "train loss:0.9826883603493765\n",
      "train loss:0.986020281280648\n",
      "train loss:1.0929459358737101\n",
      "train loss:0.8966908489037609\n",
      "train loss:0.9316320014871533\n",
      "train loss:0.9719471814512957\n",
      "train loss:1.0278776819171975\n",
      "train loss:0.8502587468984788\n",
      "train loss:0.9628655913814339\n",
      "train loss:0.9467886043402856\n",
      "train loss:0.8831020850443855\n",
      "train loss:1.1257571494596683\n",
      "train loss:0.9806392177583283\n",
      "train loss:0.9603196049844827\n",
      "train loss:0.7668410869820497\n",
      "train loss:0.9594937388752203\n",
      "train loss:1.0907551019612016\n",
      "train loss:1.0416862433884262\n",
      "train loss:0.7919789991854721\n",
      "train loss:0.923967043784192\n",
      "train loss:0.8966957735299443\n",
      "train loss:0.8234830812094722\n",
      "train loss:1.037623171879153\n",
      "train loss:0.9258582602555278\n",
      "train loss:0.9251180414028934\n",
      "train loss:0.8946223387926576\n",
      "train loss:0.9314512241768425\n",
      "train loss:1.0075594950329523\n",
      "train loss:0.9383749100058075\n",
      "train loss:1.034669898492263\n",
      "train loss:0.9089505356582861\n",
      "train loss:0.9834673147704298\n",
      "train loss:0.9491638072607584\n",
      "train loss:0.9364591030743099\n",
      "train loss:1.1241593469749396\n",
      "train loss:0.8061134776146622\n",
      "train loss:0.8139345660100504\n",
      "train loss:0.814833345307439\n",
      "train loss:0.9549438290339203\n",
      "train loss:0.885781102599877\n",
      "train loss:0.800392745045015\n",
      "train loss:0.8176688326812629\n",
      "train loss:1.0314905039932407\n",
      "train loss:0.8858471665199313\n",
      "train loss:0.9517339610213524\n",
      "train loss:0.9012302087391393\n",
      "train loss:1.0650199725913503\n",
      "train loss:0.8947857403649732\n",
      "train loss:0.8681198739595166\n",
      "train loss:0.7886626087094202\n",
      "train loss:0.9907407308530722\n",
      "train loss:1.0169519599051935\n",
      "train loss:0.9375631902042997\n",
      "train loss:0.7238594397179208\n",
      "train loss:0.9666810303858265\n",
      "train loss:0.8987305379244788\n",
      "train loss:0.9289982580587116\n",
      "train loss:0.7884070148998629\n",
      "train loss:0.9168855042276165\n",
      "train loss:0.9973644089837345\n",
      "train loss:0.8588783322704592\n",
      "train loss:0.7730311504993661\n",
      "train loss:0.7855440698246221\n",
      "train loss:0.9717309995042467\n",
      "train loss:0.8459813639663519\n",
      "train loss:1.0011519857285214\n",
      "train loss:0.940270210372215\n",
      "train loss:0.9329588156876929\n",
      "train loss:0.9750389164338688\n",
      "train loss:0.9383629802621303\n",
      "train loss:1.0079521910607\n",
      "train loss:0.9701123873901875\n",
      "train loss:0.8761504495589055\n",
      "train loss:1.0389422982248513\n",
      "train loss:0.8730653509500388\n",
      "train loss:0.8131412091669283\n",
      "train loss:0.7476882147872352\n",
      "train loss:0.9732903190790643\n",
      "train loss:1.0304300270737685\n",
      "train loss:1.0549361631349097\n",
      "train loss:0.9699055196088535\n",
      "train loss:0.7518407331474651\n",
      "train loss:0.8800635733854411\n",
      "train loss:0.9828682611356488\n",
      "train loss:0.9128815135888669\n",
      "train loss:0.9055869425300407\n",
      "train loss:0.8287081721709767\n",
      "train loss:0.9619140131566535\n",
      "train loss:0.8999835628113552\n",
      "train loss:0.852030465267118\n",
      "train loss:1.075175930407714\n",
      "train loss:0.8614030741897173\n",
      "train loss:1.0609455773469796\n",
      "train loss:0.8441690876507786\n",
      "train loss:0.904926995051415\n",
      "train loss:0.8359830565866792\n",
      "train loss:0.7839153791552765\n",
      "train loss:1.0083907398210292\n",
      "train loss:0.9591613050682928\n",
      "train loss:1.0085811748169395\n",
      "train loss:1.0312838182725053\n",
      "train loss:1.0209370038904255\n",
      "train loss:0.9733640530695036\n",
      "train loss:0.9269470061510309\n",
      "train loss:0.8418289987060479\n",
      "train loss:0.9365386015131588\n",
      "train loss:0.9734779769811602\n",
      "train loss:0.8645337333453555\n",
      "train loss:1.0797990281442602\n",
      "train loss:0.909707913100479\n",
      "train loss:0.9469838384489441\n",
      "train loss:0.7961377358627783\n",
      "train loss:0.9500324164142332\n",
      "train loss:0.9885662360401503\n",
      "train loss:1.070909514438428\n",
      "train loss:0.9138949682785058\n",
      "train loss:0.9366140225408357\n",
      "train loss:1.0336285345203544\n",
      "train loss:0.9406094368640118\n",
      "train loss:1.0068835063398136\n",
      "train loss:0.676658311856588\n",
      "train loss:0.9551974251805649\n",
      "train loss:0.9438508910931465\n",
      "train loss:1.0007007741263345\n",
      "train loss:0.9997473202916883\n",
      "train loss:1.0496410900498232\n",
      "train loss:1.0032289120266198\n",
      "train loss:1.023448094449178\n",
      "train loss:0.9075038874249894\n",
      "train loss:0.9128673863544309\n",
      "train loss:0.8161254937418544\n",
      "train loss:0.9435868880297243\n",
      "train loss:0.970758527190432\n",
      "train loss:0.9598090353050229\n",
      "train loss:0.8886174128901626\n",
      "train loss:1.0564335552679547\n",
      "train loss:0.8732220857195856\n",
      "train loss:0.7327297576354997\n",
      "train loss:0.8283663736958512\n",
      "train loss:1.0614229405556712\n",
      "train loss:1.0557904706217687\n",
      "train loss:0.9463077799564114\n",
      "train loss:0.9649563300405479\n",
      "train loss:0.9460966927821934\n",
      "train loss:0.878182991676171\n",
      "train loss:1.1222446884975097\n",
      "train loss:0.8781987514384898\n",
      "train loss:1.1395242417319533\n",
      "train loss:0.9745461317886539\n",
      "train loss:1.0136447477961699\n",
      "train loss:0.9414940836925331\n",
      "train loss:1.0916378812305674\n",
      "=== epoch:6, train acc:0.993, test acc:0.991 ===\n",
      "train loss:0.8757748234473469\n",
      "train loss:0.7219022317533819\n",
      "train loss:0.8224622164693309\n",
      "train loss:0.7865091228740693\n",
      "train loss:0.9679371350398077\n",
      "train loss:0.9419350043957431\n",
      "train loss:0.914830941652174\n",
      "train loss:1.0528686260683708\n",
      "train loss:0.8566189938010895\n",
      "train loss:0.8898945689332792\n",
      "train loss:1.003757994938065\n",
      "train loss:0.9675827009406116\n",
      "train loss:0.6744173647275755\n",
      "train loss:1.0156563798879845\n",
      "train loss:0.8292194185365034\n",
      "train loss:0.839948323512491\n",
      "train loss:0.7490473228575604\n",
      "train loss:0.917261705681888\n",
      "train loss:0.9522963284283392\n",
      "train loss:0.8623965676462072\n",
      "train loss:0.9192945230884763\n",
      "train loss:1.0001336404420846\n",
      "train loss:0.9384650523468633\n",
      "train loss:0.8401050217603888\n",
      "train loss:1.1131892836091906\n",
      "train loss:0.9732298465410613\n",
      "train loss:0.9358119282173465\n",
      "train loss:0.9518249533798864\n",
      "train loss:0.8375478534382853\n",
      "train loss:0.9755585808119855\n",
      "train loss:0.9887129972141817\n",
      "train loss:0.8912414256862391\n",
      "train loss:0.973537196358741\n",
      "train loss:1.0498444732221195\n",
      "train loss:1.0898578919500477\n",
      "train loss:0.8882841851666562\n",
      "train loss:0.8759249209563039\n",
      "train loss:1.0209689968394726\n",
      "train loss:1.0103814699122606\n",
      "train loss:0.920172269179802\n",
      "train loss:0.8642398891929842\n",
      "train loss:0.9629060338385109\n",
      "train loss:0.8396901287163914\n",
      "train loss:0.9474803103875954\n",
      "train loss:0.9930172352801289\n",
      "train loss:0.9487163661069811\n",
      "train loss:1.0045784565544162\n",
      "train loss:0.9839995326912166\n",
      "train loss:1.003634178830811\n",
      "train loss:0.8753577242314706\n",
      "train loss:1.0011433699292747\n",
      "train loss:1.0477126840122208\n",
      "train loss:0.8893642678808564\n",
      "train loss:1.0845222272479678\n",
      "train loss:1.0516714462039152\n",
      "train loss:0.889819984882972\n",
      "train loss:1.0856171383688988\n",
      "train loss:0.8241760082659847\n",
      "train loss:1.061152456529005\n",
      "train loss:0.7922156988773429\n",
      "train loss:0.7817883189656304\n",
      "train loss:0.7396151127941823\n",
      "train loss:0.8868883808830091\n",
      "train loss:1.032661354738514\n",
      "train loss:0.8328142014894314\n",
      "train loss:0.9529104247175908\n",
      "train loss:0.951934857980931\n",
      "train loss:0.8588591835558312\n",
      "train loss:0.924956078030673\n",
      "train loss:1.0603873023410706\n",
      "train loss:0.9134339758582438\n",
      "train loss:0.8737089511357558\n",
      "train loss:0.92175755563934\n",
      "train loss:0.9716841057125336\n",
      "train loss:0.9030117935523352\n",
      "train loss:0.9754629339719577\n",
      "train loss:0.9913871570799643\n",
      "train loss:0.8439469434713474\n",
      "train loss:0.9046401838018151\n",
      "train loss:0.9035552755210575\n",
      "train loss:1.0336554423150508\n",
      "train loss:0.9447067378875975\n",
      "train loss:0.8813041303863514\n",
      "train loss:0.8380214181285252\n",
      "train loss:0.9648295622052494\n",
      "train loss:0.9193271311280589\n",
      "train loss:0.9653476027787362\n",
      "train loss:1.001595010844825\n",
      "train loss:1.009525810715806\n",
      "train loss:0.8827861857100326\n",
      "train loss:1.1244498586419467\n",
      "train loss:0.9091054373188803\n",
      "train loss:0.9470985305889111\n",
      "train loss:0.8893437980508494\n",
      "train loss:0.8528663956709225\n",
      "train loss:1.0691576455522844\n",
      "train loss:0.9399192993002391\n",
      "train loss:0.8808544349662004\n",
      "train loss:0.9203718233410876\n",
      "train loss:0.9118115637173105\n",
      "train loss:0.9582673995354911\n",
      "train loss:1.0919038999919053\n",
      "train loss:0.8793538338942405\n",
      "train loss:0.8674701982453658\n",
      "train loss:0.7087268427246814\n",
      "train loss:0.8629069878074692\n",
      "train loss:1.028845881131336\n",
      "train loss:1.0718390465083731\n",
      "train loss:0.899068853215867\n",
      "train loss:0.7721038633286146\n",
      "train loss:0.9879451279392893\n",
      "train loss:0.8368701352588884\n",
      "train loss:0.7811687236640711\n",
      "train loss:1.0773099119390523\n",
      "train loss:0.9044438752973583\n",
      "train loss:0.8532934413531705\n",
      "train loss:1.079357266661257\n",
      "train loss:1.0362235889284148\n",
      "train loss:0.8775980948067658\n",
      "train loss:0.8562112969350784\n",
      "train loss:0.9394340613841483\n",
      "train loss:1.0077525690788836\n",
      "train loss:1.1208531976706944\n",
      "train loss:0.8884060007220036\n",
      "train loss:0.9586526493449409\n",
      "train loss:1.0320963770194111\n",
      "train loss:0.771809987217357\n",
      "train loss:0.8598645284570189\n",
      "train loss:0.9310568322599334\n",
      "train loss:0.8673080518607647\n",
      "train loss:0.9829947087173959\n",
      "train loss:0.8166227247139538\n",
      "train loss:1.0390902074482333\n",
      "train loss:0.7954222678521188\n",
      "train loss:0.8595973944244939\n",
      "train loss:0.9372363937892267\n",
      "train loss:0.9310570532205545\n",
      "train loss:0.9457015608002629\n",
      "train loss:0.9227442069296949\n",
      "train loss:0.8591155233729217\n",
      "train loss:0.8526316443257344\n",
      "train loss:0.9548767907246121\n",
      "train loss:0.9788444827631243\n",
      "train loss:1.111584209649887\n",
      "train loss:0.9086253608184243\n",
      "train loss:0.9841435706871163\n",
      "train loss:0.9137243856458755\n",
      "train loss:0.8590442381229246\n",
      "train loss:0.8569955209717369\n",
      "train loss:1.0674976552039492\n",
      "train loss:0.8704487509130413\n",
      "train loss:0.957705981977739\n",
      "train loss:0.9208781810596604\n",
      "train loss:0.9914523354444132\n",
      "train loss:0.9094275963165408\n",
      "train loss:0.8287161517143992\n",
      "train loss:0.8489320068472659\n",
      "train loss:0.9207810307226703\n",
      "train loss:0.791679101070595\n",
      "train loss:0.9099255370287139\n",
      "train loss:1.1167632796861435\n",
      "train loss:0.7551698891503691\n",
      "train loss:0.9512987184339563\n",
      "train loss:1.0298798350808511\n",
      "train loss:0.8855546688856525\n",
      "train loss:0.8414604017860339\n",
      "train loss:0.9208131970616036\n",
      "train loss:0.9829481159204319\n",
      "train loss:0.8996567584969938\n",
      "train loss:0.8462864753051507\n",
      "train loss:0.8781871943525001\n",
      "train loss:0.9969133738272801\n",
      "train loss:0.9402588730038015\n",
      "train loss:0.8701358397727204\n",
      "train loss:0.9133457360003231\n",
      "train loss:0.8921568417150867\n",
      "train loss:0.9799852141953531\n",
      "train loss:0.8484715466393135\n",
      "train loss:0.713987124343556\n",
      "train loss:0.8956608874526872\n",
      "train loss:0.8693569660164898\n",
      "train loss:1.0044597751840418\n",
      "train loss:0.7196778293922899\n",
      "train loss:0.9426631445675039\n",
      "train loss:0.7895343506280894\n",
      "train loss:0.9928013956473279\n",
      "train loss:0.7790539518840924\n",
      "train loss:0.7760368487886702\n",
      "train loss:1.0908533749856089\n",
      "train loss:1.003665192106164\n",
      "train loss:0.9554111755035533\n",
      "train loss:0.7505682599177165\n",
      "train loss:0.8691917572925288\n",
      "train loss:0.8611954094212331\n",
      "train loss:0.9299897084422665\n",
      "train loss:1.0034635671551804\n",
      "train loss:0.9574610624727338\n",
      "train loss:0.9460831395101625\n",
      "train loss:0.9853907669102887\n",
      "train loss:0.9998996657884617\n",
      "train loss:1.0221093637521508\n",
      "train loss:1.043082351186242\n",
      "train loss:0.8683863637451946\n",
      "train loss:1.0029201459745332\n",
      "train loss:0.7778160263013316\n",
      "train loss:0.8300234467025992\n",
      "train loss:1.0249760352105544\n",
      "train loss:1.06555914070479\n",
      "train loss:1.089473215047833\n",
      "train loss:1.0123506982941166\n",
      "train loss:0.979479676031972\n",
      "train loss:1.0861596497910089\n",
      "train loss:1.0094715186919867\n",
      "train loss:1.0188222205812527\n",
      "train loss:0.9851616446005522\n",
      "train loss:0.8175030038998337\n",
      "train loss:0.8260197100741551\n",
      "train loss:0.8589652021393732\n",
      "train loss:0.9372628238422434\n",
      "train loss:0.9307191727641725\n",
      "train loss:0.8458361081226633\n",
      "train loss:0.947297818304706\n",
      "train loss:0.9253378387142281\n",
      "train loss:0.965466110069665\n",
      "train loss:0.7543418145731546\n",
      "train loss:0.9010807659138333\n",
      "train loss:0.8652475188031936\n",
      "train loss:0.9048282978187626\n",
      "train loss:0.9244658159017832\n",
      "train loss:0.8594355134052489\n",
      "train loss:0.9525827772360391\n",
      "train loss:1.0480329437119318\n",
      "train loss:0.894526106492488\n",
      "train loss:0.9503712594329147\n",
      "train loss:0.8869305891584881\n",
      "train loss:0.9939960517399092\n",
      "train loss:0.94067936811946\n",
      "train loss:0.988385064392241\n",
      "train loss:0.8050184230591476\n",
      "train loss:0.8843520229958518\n",
      "train loss:1.0671420459399967\n",
      "train loss:0.912183773864235\n",
      "train loss:0.946718473166357\n",
      "train loss:0.8429395765968646\n",
      "train loss:0.8668694587058015\n",
      "train loss:1.0629881358221156\n",
      "train loss:1.007684359869237\n",
      "train loss:0.8308433936630354\n",
      "train loss:0.8064766753122973\n",
      "train loss:1.0631508518181112\n",
      "train loss:1.0050979971340859\n",
      "train loss:0.8465740464899889\n",
      "train loss:1.0113926044576258\n",
      "train loss:0.767051642258934\n",
      "train loss:0.9497330543842231\n",
      "train loss:0.8757174756641467\n",
      "train loss:0.9133329386278457\n",
      "train loss:0.8247953370430083\n",
      "train loss:0.7985697773091406\n",
      "train loss:0.934138095358729\n",
      "train loss:0.8566338644440321\n",
      "train loss:0.8952194826542785\n",
      "train loss:0.9226369970179863\n",
      "train loss:1.1077779645432804\n",
      "train loss:0.8330116662538505\n",
      "train loss:0.7375181019163599\n",
      "train loss:0.8844588413571515\n",
      "train loss:0.879709471439659\n",
      "train loss:0.8001757105933297\n",
      "train loss:0.9968507172184493\n",
      "train loss:0.9521958628070334\n",
      "train loss:0.909092445955852\n",
      "train loss:0.8632402082040581\n",
      "train loss:0.9057207649596832\n",
      "train loss:0.8257892827194206\n",
      "train loss:0.8660762984545615\n",
      "train loss:0.9178794217333376\n",
      "train loss:1.0507085852985056\n",
      "train loss:0.8547516180713072\n",
      "train loss:0.9521724525383513\n",
      "train loss:0.8575049761742265\n",
      "train loss:0.8915445707841227\n",
      "train loss:0.955330664664451\n",
      "train loss:0.8190829980886788\n",
      "train loss:0.8364111219109303\n",
      "train loss:1.02360220297858\n",
      "train loss:0.9576296206046269\n",
      "train loss:0.9796521242888494\n",
      "train loss:0.8436761877137819\n",
      "train loss:0.801724940764017\n",
      "train loss:0.8101956142217166\n",
      "train loss:0.9095750950024721\n",
      "train loss:0.9419355060884927\n",
      "train loss:0.75437982532112\n",
      "train loss:0.8354088350187512\n",
      "train loss:1.0598752620943086\n",
      "train loss:1.0503540835039955\n",
      "train loss:0.9617547572273402\n",
      "train loss:1.1264124074425954\n",
      "train loss:0.8251858714528898\n",
      "train loss:0.9309091839083569\n",
      "train loss:0.9696361227960136\n",
      "train loss:0.9679696409679296\n",
      "train loss:0.8785192866676255\n",
      "train loss:0.9563827557168729\n",
      "train loss:0.9432745004635439\n",
      "train loss:1.1090329237240268\n",
      "train loss:1.0767168394971158\n",
      "train loss:0.76042918838781\n",
      "train loss:0.9925701513753161\n",
      "train loss:0.9300969194072226\n",
      "train loss:1.0240370721171002\n",
      "train loss:1.037416924395545\n",
      "train loss:0.9171619123842919\n",
      "train loss:0.9259577450353242\n",
      "train loss:1.1934286714105773\n",
      "train loss:0.9643181820759165\n",
      "train loss:0.8028922175385418\n",
      "train loss:0.8179099918870735\n",
      "train loss:0.8711567494317317\n",
      "train loss:0.9224001967744845\n",
      "train loss:0.9911379732046744\n",
      "train loss:0.9297897004252758\n",
      "train loss:0.8292043725380264\n",
      "train loss:0.7324767762266602\n",
      "train loss:0.7827422175898562\n",
      "train loss:0.9808496616237359\n",
      "train loss:0.9235221780799605\n",
      "train loss:0.9459375685940813\n",
      "train loss:1.2077509908178519\n",
      "train loss:0.8843031896173912\n",
      "train loss:0.990372808971448\n",
      "train loss:0.9564542108182831\n",
      "train loss:0.9892574273358347\n",
      "train loss:1.1630993995556311\n",
      "train loss:1.1311872289625768\n",
      "train loss:0.9970693524708898\n",
      "train loss:1.0090063262226179\n",
      "train loss:0.9349420439569358\n",
      "train loss:0.9992761333589663\n",
      "train loss:0.878563592747636\n",
      "train loss:0.9488492732966916\n",
      "train loss:0.9762122501321787\n",
      "train loss:0.8792105870334023\n",
      "train loss:0.8214243553466836\n",
      "train loss:0.9228092708026339\n",
      "train loss:0.867308217601356\n",
      "train loss:0.9894723253324688\n",
      "train loss:1.0030461977036702\n",
      "train loss:0.9838642680308398\n",
      "train loss:0.8037714185752588\n",
      "train loss:0.9073493218431381\n",
      "train loss:0.8667092262964431\n",
      "train loss:1.0100737176326593\n",
      "train loss:0.8628970071814606\n",
      "train loss:1.0771689446487216\n",
      "train loss:1.0071113564116057\n",
      "train loss:0.8487048275498593\n",
      "train loss:0.9234939886360471\n",
      "train loss:1.0323876552752427\n",
      "train loss:0.8933811962229976\n",
      "train loss:0.9321637315647009\n",
      "train loss:0.9264997410860366\n",
      "train loss:0.8981507390610175\n",
      "train loss:0.8224286746747096\n",
      "train loss:0.7285095451430139\n",
      "train loss:1.0442695367819426\n",
      "train loss:1.1127263437926391\n",
      "train loss:1.0043808504645406\n",
      "train loss:0.9322686593380176\n",
      "train loss:0.8087210320198936\n",
      "train loss:1.0477909991692664\n",
      "train loss:1.0813777532001634\n",
      "train loss:1.0816434980708918\n",
      "train loss:0.932725390473089\n",
      "train loss:0.9283187214329115\n",
      "train loss:0.9364559255560456\n",
      "train loss:0.8115326036102397\n",
      "train loss:0.9043839404891478\n",
      "train loss:0.874464404665593\n",
      "train loss:0.8770549412182054\n",
      "train loss:0.867436146208057\n",
      "train loss:0.9935886567269292\n",
      "train loss:1.0987421559511157\n",
      "train loss:1.0235555487309111\n",
      "train loss:0.9601525648746784\n",
      "train loss:0.8499140460291129\n",
      "train loss:0.7846281009947608\n",
      "train loss:0.9461918484381556\n",
      "train loss:0.8109965402506368\n",
      "train loss:0.8163485298328187\n",
      "train loss:0.9627198515145355\n",
      "train loss:0.8993319534431373\n",
      "train loss:1.006003952731396\n",
      "train loss:0.9523919250256837\n",
      "train loss:0.918520305913844\n",
      "train loss:0.943692902507077\n",
      "train loss:1.0262417283858323\n",
      "train loss:0.935290676666983\n",
      "train loss:0.9813260490853171\n",
      "train loss:0.8995555429848653\n",
      "train loss:0.8529723153894687\n",
      "train loss:0.8701187758478103\n",
      "train loss:0.8390334436962257\n",
      "train loss:1.072726242454273\n",
      "train loss:0.9451818896279991\n",
      "train loss:0.9996205496770669\n",
      "train loss:0.8865196105810965\n",
      "train loss:0.8383378327731001\n",
      "train loss:0.7942842532281787\n",
      "train loss:0.9188615362586205\n",
      "train loss:0.7145245220290917\n",
      "train loss:0.9795724390549794\n",
      "train loss:1.1661864887655324\n",
      "train loss:0.9759903716951661\n",
      "train loss:1.021630677144636\n",
      "train loss:0.8485282216941629\n",
      "train loss:0.8644849383015739\n",
      "train loss:0.996328850967326\n",
      "train loss:1.0157820307231515\n",
      "train loss:0.7852788467889045\n",
      "train loss:0.9530979431673932\n",
      "train loss:0.8815767410276734\n",
      "train loss:0.9049300547342363\n",
      "train loss:0.8878238373477285\n",
      "train loss:0.8496962123088465\n",
      "train loss:1.1007451117431264\n",
      "train loss:0.9612251337051325\n",
      "train loss:0.894032106748009\n",
      "train loss:0.9649131213028668\n",
      "train loss:0.8872638641637808\n",
      "train loss:1.1121633880071213\n",
      "train loss:0.9044592405712153\n",
      "train loss:0.8982307916883543\n",
      "train loss:0.781545393493126\n",
      "train loss:0.9249612135925487\n",
      "train loss:0.9611360061869596\n",
      "train loss:0.9253618868021131\n",
      "train loss:0.8723888547649804\n",
      "train loss:0.926811520781229\n",
      "train loss:0.902151628533641\n",
      "train loss:0.8827283059327335\n",
      "train loss:1.0300147280098466\n",
      "train loss:0.8871167937476123\n",
      "train loss:0.8877484104178511\n",
      "train loss:0.8792701730672832\n",
      "train loss:0.8215475184458759\n",
      "train loss:1.0116700477111886\n",
      "train loss:0.8921835425290326\n",
      "train loss:0.9690934211309624\n",
      "train loss:0.8208656491192389\n",
      "train loss:0.9653812119447693\n",
      "train loss:0.8973672567432419\n",
      "train loss:0.9659760484078818\n",
      "train loss:0.8077170102168438\n",
      "train loss:0.9141381002295306\n",
      "train loss:0.8078466596117618\n",
      "train loss:0.7582677773955178\n",
      "train loss:0.9805344113521365\n",
      "train loss:0.7695506443860438\n",
      "train loss:0.8951149138657629\n",
      "train loss:0.8987847813699515\n",
      "train loss:1.0246952251690034\n",
      "train loss:1.2349074053340903\n",
      "train loss:0.90081722245799\n",
      "train loss:1.1085995709133731\n",
      "train loss:0.8389550249088475\n",
      "train loss:0.8906260683430157\n",
      "train loss:0.9103187050846379\n",
      "train loss:0.8164803390967761\n",
      "train loss:0.8966394549442012\n",
      "train loss:1.06034547775163\n",
      "train loss:0.8894061927054673\n",
      "train loss:0.9146987177934364\n",
      "train loss:0.959619449190517\n",
      "train loss:0.797929180400233\n",
      "train loss:1.0948992620022575\n",
      "train loss:0.8013137065719096\n",
      "train loss:0.7909043483500757\n",
      "train loss:0.925673437182915\n",
      "train loss:0.9100692028506979\n",
      "train loss:0.8093999480066671\n",
      "train loss:0.8724012915835054\n",
      "train loss:0.7380061399189854\n",
      "train loss:0.9739999524520302\n",
      "train loss:0.9259791349859166\n",
      "train loss:0.8683628783947012\n",
      "train loss:0.7763729005679991\n",
      "train loss:0.8866386505643291\n",
      "train loss:1.1471377959646767\n",
      "train loss:1.1577073131799982\n",
      "train loss:0.9072862597131518\n",
      "train loss:0.9709604751751774\n",
      "train loss:0.7925958906261396\n",
      "train loss:0.9091461128872115\n",
      "train loss:1.1188690095162408\n",
      "train loss:0.9970303132674538\n",
      "train loss:0.9276342318111662\n",
      "train loss:0.9199401234160586\n",
      "train loss:1.120939776565362\n",
      "train loss:0.9228498195633301\n",
      "train loss:1.0385124393399305\n",
      "train loss:0.804863918981487\n",
      "train loss:0.8480895841170549\n",
      "train loss:0.8889271621606109\n",
      "train loss:0.933010045736427\n",
      "train loss:0.8280599902872672\n",
      "train loss:0.840990400909838\n",
      "train loss:0.9016897757372847\n",
      "train loss:0.9337784737311384\n",
      "train loss:0.8683232530442521\n",
      "train loss:0.8586407555666428\n",
      "train loss:0.9228960824869306\n",
      "train loss:0.8746982950714688\n",
      "train loss:0.9683675190953761\n",
      "train loss:0.8315193578640799\n",
      "train loss:0.8106005880701963\n",
      "train loss:0.8783210793808657\n",
      "train loss:1.0184650448501746\n",
      "train loss:0.9272173254673345\n",
      "train loss:0.9904595833260177\n",
      "train loss:0.9719961739777164\n",
      "train loss:0.8958533276802187\n",
      "train loss:0.7815124133264711\n",
      "train loss:0.9393972117352579\n",
      "train loss:1.037091414157031\n",
      "train loss:0.7642378833288574\n",
      "train loss:0.905491100535294\n",
      "train loss:1.0482776347626277\n",
      "train loss:0.9359526018813272\n",
      "train loss:0.8381467800840379\n",
      "train loss:0.933823957148646\n",
      "train loss:0.9297930963577766\n",
      "train loss:0.8962565418328038\n",
      "train loss:0.8149661651551666\n",
      "train loss:0.9114045768519681\n",
      "train loss:0.829687267577442\n",
      "train loss:1.062299985947539\n",
      "train loss:1.1345829825213876\n",
      "train loss:0.866761105738087\n",
      "train loss:1.0092368408080137\n",
      "train loss:0.7540628404669305\n",
      "train loss:0.8979484101935832\n",
      "train loss:0.7882048761202922\n",
      "train loss:0.866322988864982\n",
      "train loss:0.9140547042113967\n",
      "train loss:0.8158723151615422\n",
      "train loss:1.0427520043930583\n",
      "train loss:0.9498611407257189\n",
      "train loss:0.8034159999537424\n",
      "train loss:0.7658068177415607\n",
      "train loss:0.9013253154863382\n",
      "train loss:0.732027544181991\n",
      "train loss:1.0963762918043092\n",
      "train loss:0.9574546935073767\n",
      "train loss:1.0380635260580882\n",
      "train loss:0.7588218096100523\n",
      "train loss:0.9724498833766142\n",
      "train loss:0.8821735147015138\n",
      "train loss:1.0897929023598942\n",
      "train loss:0.8649902324385824\n",
      "train loss:0.9175210792226018\n",
      "train loss:0.6971519998981117\n",
      "train loss:0.9007141270141248\n",
      "train loss:0.992896578227107\n",
      "train loss:0.833524028423053\n",
      "train loss:0.965835930348851\n",
      "train loss:0.8779828056549634\n",
      "train loss:0.9686075380317719\n",
      "train loss:1.0883579308765865\n",
      "train loss:0.9530181777418992\n",
      "train loss:0.8642813187571234\n",
      "train loss:0.8458216333667038\n",
      "train loss:0.8513185913764744\n",
      "train loss:0.9487648746585151\n",
      "train loss:0.8709694079574049\n",
      "train loss:0.9113339284818207\n",
      "train loss:0.8765002608484238\n",
      "train loss:0.9727697506046806\n",
      "train loss:0.8580923326191371\n",
      "train loss:1.1018801045483728\n",
      "train loss:0.8746081494873651\n",
      "train loss:1.1416798926896246\n",
      "train loss:0.9767748815349461\n",
      "train loss:1.074191066189513\n",
      "train loss:1.1249019868538377\n",
      "train loss:0.8925549398949236\n",
      "train loss:0.8813313832080059\n",
      "train loss:0.7311558305980195\n",
      "train loss:0.8490379495829433\n",
      "train loss:0.9898780244302734\n",
      "train loss:0.9407142944376184\n",
      "train loss:1.0543790375396254\n",
      "train loss:0.8537653257552777\n",
      "train loss:0.9296859438143482\n",
      "train loss:1.264505247798268\n",
      "train loss:1.0159181315562846\n",
      "train loss:1.0449263526617607\n",
      "train loss:0.9287277150948217\n",
      "train loss:0.918754844529092\n",
      "=== epoch:7, train acc:0.992, test acc:0.994 ===\n",
      "train loss:0.9552624593095038\n",
      "train loss:0.9219095032164492\n",
      "train loss:0.6310130866061794\n",
      "train loss:0.8258318379660406\n",
      "train loss:0.8441840359187549\n",
      "train loss:0.9730526870303606\n",
      "train loss:0.8912586178222984\n",
      "train loss:0.904764138740321\n",
      "train loss:0.8574422970223547\n",
      "train loss:0.9315858439234407\n",
      "train loss:0.886570332529176\n",
      "train loss:0.9981460567889237\n",
      "train loss:0.9128468866119094\n",
      "train loss:0.9621989441686267\n",
      "train loss:0.8059750193222858\n",
      "train loss:0.9952647544869098\n",
      "train loss:0.9813504752138381\n",
      "train loss:0.869391500424993\n",
      "train loss:0.8510640471811135\n",
      "train loss:0.9090160789649806\n",
      "train loss:0.7583456661348259\n",
      "train loss:0.9586304195740053\n",
      "train loss:0.9056354379770695\n",
      "train loss:1.1047368354189235\n",
      "train loss:0.9250751206237343\n",
      "train loss:1.0312277941572794\n",
      "train loss:0.9720866815020185\n",
      "train loss:1.0143803569243646\n",
      "train loss:0.8784467640592177\n",
      "train loss:0.8731148691823998\n",
      "train loss:0.9945844094934548\n",
      "train loss:0.9939618362454854\n",
      "train loss:0.859264797649162\n",
      "train loss:0.8773991853759759\n",
      "train loss:0.9255152857674236\n",
      "train loss:0.7961625783849603\n",
      "train loss:0.8508408144096006\n",
      "train loss:0.9516663982085912\n",
      "train loss:0.981678780685368\n",
      "train loss:0.8171389031258767\n",
      "train loss:0.884991066959066\n",
      "train loss:0.7842915351231998\n",
      "train loss:0.9565016464656527\n",
      "train loss:0.8551357774878022\n",
      "train loss:1.061738869353057\n",
      "train loss:0.9008339980239245\n",
      "train loss:1.1114453723082511\n",
      "train loss:0.9404324784182413\n",
      "train loss:0.8625866382361198\n",
      "train loss:0.844968541024994\n",
      "train loss:0.90173682252806\n",
      "train loss:0.9238611964932524\n",
      "train loss:0.949121285420232\n",
      "train loss:0.766242255357763\n",
      "train loss:0.9664603191092432\n",
      "train loss:1.0078498748629945\n",
      "train loss:0.7498719186933381\n",
      "train loss:0.9413259829664574\n",
      "train loss:0.7966886773877168\n",
      "train loss:1.0665738118522905\n",
      "train loss:0.8347653522633575\n",
      "train loss:0.89761272465026\n",
      "train loss:0.9431085844928144\n",
      "train loss:1.0242142196503161\n",
      "train loss:0.9165975095151925\n",
      "train loss:1.1913558944323634\n",
      "train loss:0.7632026202055243\n",
      "train loss:0.8262464419788391\n",
      "train loss:0.9504467087675024\n",
      "train loss:0.9437484879209935\n",
      "train loss:0.7159916805496649\n",
      "train loss:0.9592005219980884\n",
      "train loss:0.8867135265767446\n",
      "train loss:0.9224467972703094\n",
      "train loss:0.9069998949824477\n",
      "train loss:0.9813280302074159\n",
      "train loss:0.9525858496500337\n",
      "train loss:0.9391379320538137\n",
      "train loss:1.0202773837097046\n",
      "train loss:0.8499301631798051\n",
      "train loss:0.8143671399769837\n",
      "train loss:0.9529668134610861\n",
      "train loss:0.8642125264124004\n",
      "train loss:0.9962233862845613\n",
      "train loss:0.8503885332504771\n",
      "train loss:1.0222131244479564\n",
      "train loss:0.978038204058672\n",
      "train loss:0.9919068962280769\n",
      "train loss:0.9383761498625962\n",
      "train loss:1.0561724344653545\n",
      "train loss:0.7620410688886241\n",
      "train loss:0.8871700504683416\n",
      "train loss:0.982098219041882\n",
      "train loss:0.8214955693352635\n",
      "train loss:0.814815377167988\n",
      "train loss:0.8137198367869953\n",
      "train loss:1.0223082686831302\n",
      "train loss:0.9261456454092483\n",
      "train loss:0.8970192805253405\n",
      "train loss:0.919906403330355\n",
      "train loss:0.7877227817968755\n",
      "train loss:0.9292321730258017\n",
      "train loss:1.0310167665921648\n",
      "train loss:0.8763023082167813\n",
      "train loss:0.9441476592543947\n",
      "train loss:0.9910645981065155\n",
      "train loss:1.0465441417005363\n",
      "train loss:1.0003726263347892\n",
      "train loss:1.0243285270960212\n",
      "train loss:1.0808502506070012\n",
      "train loss:0.756950615097918\n",
      "train loss:1.1524880899724905\n",
      "train loss:0.9796690961143644\n",
      "train loss:0.8560304181378099\n",
      "train loss:0.9603893783362227\n",
      "train loss:0.8630414172833365\n",
      "train loss:0.8129574159092127\n",
      "train loss:1.0144673401285875\n",
      "train loss:0.8960790436412214\n",
      "train loss:0.8078850533841297\n",
      "train loss:0.8755767493273997\n",
      "train loss:0.7879319995315285\n",
      "train loss:0.75952994121033\n",
      "train loss:1.0712816013214828\n",
      "train loss:0.8123311738613984\n",
      "train loss:0.8648208155262261\n",
      "train loss:0.9065334029841209\n",
      "train loss:0.8969645675879012\n",
      "train loss:1.0021598265326186\n",
      "train loss:1.0227734889134197\n",
      "train loss:0.8344492864125586\n",
      "train loss:0.7824529633503435\n",
      "train loss:0.8462264208634849\n",
      "train loss:1.0516350489821944\n",
      "train loss:0.9232697631588569\n",
      "train loss:0.9624290330628326\n",
      "train loss:0.8283914588265329\n",
      "train loss:0.9087350990947753\n",
      "train loss:0.98876462696386\n",
      "train loss:1.1136769756281624\n",
      "train loss:0.9627969029995666\n",
      "train loss:0.9096979033292465\n",
      "train loss:0.9065283846787847\n",
      "train loss:1.0082507077286984\n",
      "train loss:0.8474944005878219\n",
      "train loss:0.7571955222109689\n",
      "train loss:0.8642222594021995\n",
      "train loss:0.7895455133952541\n",
      "train loss:0.9027059718231262\n",
      "train loss:0.9312686986639175\n",
      "train loss:0.8961629819269649\n",
      "train loss:0.8850617396032442\n",
      "train loss:0.8572316801353997\n",
      "train loss:0.8749538695626032\n",
      "train loss:0.9486505193835865\n",
      "train loss:0.8441989420922457\n",
      "train loss:0.8709671768732552\n",
      "train loss:0.8011731047030927\n",
      "train loss:0.7999294505915125\n",
      "train loss:1.2350312058516435\n",
      "train loss:0.9326598310298173\n",
      "train loss:0.7001756589937093\n",
      "train loss:0.8326492983765629\n",
      "train loss:0.8874446221751853\n",
      "train loss:0.8174268091762252\n",
      "train loss:0.8425786595259146\n",
      "train loss:0.9162031494253837\n",
      "train loss:0.7726533727263474\n",
      "train loss:1.0881801288190656\n",
      "train loss:0.8122905017602388\n",
      "train loss:0.9197319476415099\n",
      "train loss:0.8769456158809154\n",
      "train loss:0.8932511052695962\n",
      "train loss:0.8896513581307893\n",
      "train loss:0.9214493599991502\n",
      "train loss:0.9575273379624045\n",
      "train loss:0.7724286924991884\n",
      "train loss:0.8570501362765603\n",
      "train loss:0.9663568198590601\n",
      "train loss:0.9341229763094403\n",
      "train loss:0.8672814802993717\n",
      "train loss:0.7853218024508144\n",
      "train loss:1.0819793291005373\n",
      "train loss:0.9486203572123726\n",
      "train loss:0.8497414950578047\n",
      "train loss:0.8903442831282297\n",
      "train loss:1.0376815923140332\n",
      "train loss:0.7688904366122037\n",
      "train loss:0.8625353509102893\n",
      "train loss:0.8240975778577082\n",
      "train loss:0.8579028006024232\n",
      "train loss:1.035545550121299\n",
      "train loss:0.7982047053896753\n",
      "train loss:1.0698645311961152\n",
      "train loss:0.9531878338718451\n",
      "train loss:0.9483215752526323\n",
      "train loss:0.9178497217572956\n",
      "train loss:0.9721708202554642\n",
      "train loss:0.998897277580543\n",
      "train loss:0.8872448632564596\n",
      "train loss:0.7776293920786668\n",
      "train loss:1.0113459677835543\n",
      "train loss:0.9410491995753358\n",
      "train loss:1.1356280379216617\n",
      "train loss:0.8987204315204212\n",
      "train loss:0.8333139306537831\n",
      "train loss:0.999642170604431\n",
      "train loss:0.7419401906898335\n",
      "train loss:0.8211485546745159\n",
      "train loss:0.9319176900420435\n",
      "train loss:0.7114187661540184\n",
      "train loss:0.9368552500629374\n",
      "train loss:1.0075230443582341\n",
      "train loss:0.6665893592048591\n",
      "train loss:0.820600312169891\n",
      "train loss:0.7374293666046823\n",
      "train loss:1.1135765007675469\n",
      "train loss:0.9433881890480954\n",
      "train loss:0.8600004790530327\n",
      "train loss:1.0011561796454551\n",
      "train loss:0.9176010818701187\n",
      "train loss:0.9528652623448162\n",
      "train loss:1.0527591032787356\n",
      "train loss:0.8336720262467646\n",
      "train loss:0.873135711205566\n",
      "train loss:1.0233931340472457\n",
      "train loss:0.8483617820624981\n",
      "train loss:0.6798785578444305\n",
      "train loss:0.8053563358653583\n",
      "train loss:0.9784216929664126\n",
      "train loss:0.9096714027431537\n",
      "train loss:0.9754804574655558\n",
      "train loss:0.9226070350144936\n",
      "train loss:0.7570969106843443\n",
      "train loss:0.904508655017608\n",
      "train loss:0.9047447928204655\n",
      "train loss:0.9293360038304951\n",
      "train loss:0.9077646566591491\n",
      "train loss:0.9386316767370176\n",
      "train loss:0.925882679401795\n",
      "train loss:1.0387780486898854\n",
      "train loss:0.9558250999012988\n",
      "train loss:0.9054233062022286\n",
      "train loss:1.0005275299456684\n",
      "train loss:0.8295894634906726\n",
      "train loss:0.81112904030785\n",
      "train loss:0.8704138286838484\n",
      "train loss:0.9886284668191259\n",
      "train loss:0.9229486388907867\n",
      "train loss:0.8487659156946343\n",
      "train loss:0.8822465112866567\n",
      "train loss:0.9250128519541535\n",
      "train loss:0.8975874966552203\n",
      "train loss:0.9513454550464288\n",
      "train loss:1.0055079008283851\n",
      "train loss:0.9543422654499328\n",
      "train loss:1.039810907147263\n",
      "train loss:0.7585052973748357\n",
      "train loss:0.8447366260552839\n",
      "train loss:0.8608922517295099\n",
      "train loss:0.7604798218957823\n",
      "train loss:0.8803511918267947\n",
      "train loss:1.052133238634665\n",
      "train loss:0.8952569350706423\n",
      "train loss:0.9044687203680135\n",
      "train loss:1.0042425688003336\n",
      "train loss:0.8081473198335307\n",
      "train loss:0.8972329050545242\n",
      "train loss:0.9357433285019395\n",
      "train loss:0.9755686251835453\n",
      "train loss:0.903953984233851\n",
      "train loss:0.8359141987381727\n",
      "train loss:0.9346486214208788\n",
      "train loss:0.9798783966487297\n",
      "train loss:0.6739019648054507\n",
      "train loss:1.0271390432779681\n",
      "train loss:0.8782123928312818\n",
      "train loss:0.7909592467455215\n",
      "train loss:0.9220447837206531\n",
      "train loss:0.9870430892785808\n",
      "train loss:0.9648903460700722\n",
      "train loss:0.7303312382761693\n",
      "train loss:0.8898053237697704\n",
      "train loss:0.7366390872656866\n",
      "train loss:0.9495429153100956\n",
      "train loss:0.9014309524745359\n",
      "train loss:0.8137716111417496\n",
      "train loss:0.9781553662577547\n",
      "train loss:0.8227184275742602\n",
      "train loss:0.9719751196031055\n",
      "train loss:0.912516605472685\n",
      "train loss:0.8704093963287082\n",
      "train loss:0.9111094044790312\n",
      "train loss:0.8896242843088683\n",
      "train loss:0.9115757464789447\n",
      "train loss:1.0201857613593384\n",
      "train loss:1.1338302160618665\n",
      "train loss:1.053746921740228\n",
      "train loss:0.8605559568314731\n",
      "train loss:0.9557504900096864\n",
      "train loss:0.8611944853500465\n",
      "train loss:1.003681224879083\n",
      "train loss:1.0659657396942028\n",
      "train loss:0.880548078068205\n",
      "train loss:0.9005768002611014\n",
      "train loss:0.8875290254200408\n",
      "train loss:0.8149581625163907\n",
      "train loss:0.9880702432889996\n",
      "train loss:0.8739339063381282\n",
      "train loss:0.7152399253819217\n",
      "train loss:0.9454634511065012\n",
      "train loss:0.8756931100764725\n",
      "train loss:0.9661293150566109\n",
      "train loss:1.0015192824865158\n",
      "train loss:0.9069546875839269\n",
      "train loss:0.8555885355297542\n",
      "train loss:0.7688868044307944\n",
      "train loss:0.9328741514294435\n",
      "train loss:0.9363872501800237\n",
      "train loss:0.8745810562292574\n",
      "train loss:0.8960779955124883\n",
      "train loss:0.825072048681229\n",
      "train loss:0.9150379096146524\n",
      "train loss:0.8909307025275429\n",
      "train loss:0.8162967017709524\n",
      "train loss:1.1161247220258108\n",
      "train loss:0.8565731884944671\n",
      "train loss:0.9631830520484804\n",
      "train loss:0.8796616262250856\n",
      "train loss:0.8673803639577768\n",
      "train loss:0.8543649496421304\n",
      "train loss:0.9488832698696771\n",
      "train loss:0.8548108838112363\n",
      "train loss:0.9044099057516108\n",
      "train loss:0.9040517712720519\n",
      "train loss:0.8499859289133298\n",
      "train loss:0.909631311320686\n",
      "train loss:0.8642142688440562\n",
      "train loss:1.0079404174583155\n",
      "train loss:0.8846221579592272\n",
      "train loss:0.7915905009584175\n",
      "train loss:0.9827330483143147\n",
      "train loss:0.9008967827056098\n",
      "train loss:0.8870030811909468\n",
      "train loss:0.9257426474842595\n",
      "train loss:0.9423433956811378\n",
      "train loss:0.7481031811056919\n",
      "train loss:0.9660743097151696\n",
      "train loss:1.006344009786108\n",
      "train loss:0.8123815276594367\n",
      "train loss:0.8457810765464018\n",
      "train loss:0.93094637289128\n",
      "train loss:1.1212637465149813\n",
      "train loss:0.9343477944247977\n",
      "train loss:0.9079898143924316\n",
      "train loss:0.9364627568693797\n",
      "train loss:1.050220527746759\n",
      "train loss:0.9733156904076897\n",
      "train loss:0.8855434368478368\n",
      "train loss:0.8479535034278689\n",
      "train loss:0.9504727509430804\n",
      "train loss:0.8075712553463843\n",
      "train loss:1.0078174902864436\n",
      "train loss:0.8731408719051007\n",
      "train loss:1.002283800559597\n",
      "train loss:0.9401407382899566\n",
      "train loss:0.7658759063264949\n",
      "train loss:0.8812095009180783\n",
      "train loss:0.9213028604570167\n",
      "train loss:1.0775023224829001\n",
      "train loss:1.0486922107655932\n",
      "train loss:0.8105389749186556\n",
      "train loss:0.9274041124389949\n",
      "train loss:0.8925164131136409\n",
      "train loss:0.8733379449892708\n",
      "train loss:0.9270731641249155\n",
      "train loss:0.9638195426566999\n",
      "train loss:0.8175053801110156\n",
      "train loss:0.9214302541480519\n",
      "train loss:0.8830492692530955\n",
      "train loss:0.9370368926072342\n",
      "train loss:0.9284450249260562\n",
      "train loss:0.9588095671384269\n",
      "train loss:0.892619502385057\n",
      "train loss:0.8022850968018115\n",
      "train loss:1.057287760049944\n",
      "train loss:0.8223884421288008\n",
      "train loss:0.9274739562496415\n",
      "train loss:0.9240618075026574\n",
      "train loss:1.0188810005286488\n",
      "train loss:0.8943367976772181\n",
      "train loss:0.929493554892671\n",
      "train loss:1.0722224401086313\n",
      "train loss:1.0863285081126177\n",
      "train loss:0.892192166486342\n",
      "train loss:0.9847733650478758\n",
      "train loss:1.0511283183983278\n",
      "train loss:0.8441119984133111\n",
      "train loss:0.8088409360710048\n",
      "train loss:0.8674478283924966\n",
      "train loss:1.008109973920214\n",
      "train loss:1.0237203382103055\n",
      "train loss:0.9544159147049013\n",
      "train loss:0.9636569558553325\n",
      "train loss:0.9680178681869996\n",
      "train loss:0.8444404039570503\n",
      "train loss:0.9563906037166504\n",
      "train loss:0.8060329669053776\n",
      "train loss:0.8978129799521826\n",
      "train loss:0.8887430139274095\n",
      "train loss:0.8831641575958387\n",
      "train loss:0.944921153179596\n",
      "train loss:0.9605146330743307\n",
      "train loss:0.8686763131232064\n",
      "train loss:0.9084314308842261\n",
      "train loss:0.7917559478350457\n",
      "train loss:1.046336441960105\n",
      "train loss:0.9766998332271217\n",
      "train loss:0.9081998445299477\n",
      "train loss:0.9610266083557906\n",
      "train loss:0.9034127434961952\n",
      "train loss:0.8480996044995631\n",
      "train loss:1.0303659409292785\n",
      "train loss:0.9190833924299656\n",
      "train loss:0.8855382186484484\n",
      "train loss:0.7261367596613166\n",
      "train loss:0.8221873259965439\n",
      "train loss:0.9232350838617341\n",
      "train loss:0.7454743997023354\n",
      "train loss:0.8995211249884291\n",
      "train loss:1.0149628332684368\n",
      "train loss:0.8864255648363047\n",
      "train loss:0.8617220232105133\n",
      "train loss:0.914973634542645\n",
      "train loss:0.8080543200715763\n",
      "train loss:0.8668655926967783\n",
      "train loss:0.838529826797975\n",
      "train loss:1.0579639131093452\n",
      "train loss:0.8195091351591596\n",
      "train loss:0.9124087916645511\n",
      "train loss:1.076976133773306\n",
      "train loss:0.875847170761917\n",
      "train loss:0.9739523868619915\n",
      "train loss:0.9419750360067316\n",
      "train loss:0.8539137457056125\n",
      "train loss:1.107838391573014\n",
      "train loss:0.9398273148438581\n",
      "train loss:0.8994365787781127\n",
      "train loss:0.9691840643388041\n",
      "train loss:0.8932485598181843\n",
      "train loss:0.8219423654334312\n",
      "train loss:0.8867205996928658\n",
      "train loss:0.7484704155053845\n",
      "train loss:0.7542636920500277\n",
      "train loss:0.8858403202402267\n",
      "train loss:0.7897131227257391\n",
      "train loss:0.8754993263626034\n",
      "train loss:0.994238764355519\n",
      "train loss:0.9615973278129214\n",
      "train loss:0.871369540897932\n",
      "train loss:0.8641038757960763\n",
      "train loss:0.9708226798923205\n",
      "train loss:0.9905497207025864\n",
      "train loss:0.9152618198597622\n",
      "train loss:0.9562504565467959\n",
      "train loss:0.8298408793504032\n",
      "train loss:0.9648248005829998\n",
      "train loss:0.8303974089453624\n",
      "train loss:0.9026963671921009\n",
      "train loss:0.9302588481667294\n",
      "train loss:1.0529902028592877\n",
      "train loss:1.0297050514330415\n",
      "train loss:1.023773733669505\n",
      "train loss:1.0154957208698583\n",
      "train loss:0.8351031912535918\n",
      "train loss:0.965266773121961\n",
      "train loss:0.7887172054534851\n",
      "train loss:0.7350003966044547\n",
      "train loss:0.8213577917687709\n",
      "train loss:0.8664448983184571\n",
      "train loss:0.8077273131783173\n",
      "train loss:1.1333440537807347\n",
      "train loss:0.9238177717771363\n",
      "train loss:0.9685159285636483\n",
      "train loss:0.8295547556413899\n",
      "train loss:0.9906076275163042\n",
      "train loss:0.9197847365099528\n",
      "train loss:0.8795167265128145\n",
      "train loss:0.9412299403014828\n",
      "train loss:0.8446545769821582\n",
      "train loss:0.5649634097459193\n",
      "train loss:0.8219479825208224\n",
      "train loss:0.8724811729032289\n",
      "train loss:1.042504140172019\n",
      "train loss:0.8531192563146232\n",
      "train loss:0.8392527031477391\n",
      "train loss:0.9049414238795754\n",
      "train loss:0.9714320195565748\n",
      "train loss:1.1628973578950774\n",
      "train loss:0.8736647784045212\n",
      "train loss:1.0010373358471383\n",
      "train loss:1.15082880829247\n",
      "train loss:0.961370383912388\n",
      "train loss:1.0055362394101097\n",
      "train loss:0.7570835601083259\n",
      "train loss:0.9914666185529897\n",
      "train loss:0.8464768080338675\n",
      "train loss:0.737627566430579\n",
      "train loss:0.7957318986115332\n",
      "train loss:0.807813538948854\n",
      "train loss:0.8612997625606011\n",
      "train loss:0.9327854181514188\n",
      "train loss:0.9814764878940545\n",
      "train loss:0.851622542190674\n",
      "train loss:0.9204563573146491\n",
      "train loss:0.7871924489567145\n",
      "train loss:0.8562224293361986\n",
      "train loss:0.7341303578468816\n",
      "train loss:0.9563997507995997\n",
      "train loss:0.8843550420238728\n",
      "train loss:0.999397242545156\n",
      "train loss:0.7458078883132611\n",
      "train loss:0.8620241296200625\n",
      "train loss:0.773004183980236\n",
      "train loss:0.8757291190562946\n",
      "train loss:0.9473560163538584\n",
      "train loss:0.7349015810800459\n",
      "train loss:1.0286871184338344\n",
      "train loss:0.8845142298653955\n",
      "train loss:0.8574194357901045\n",
      "train loss:0.8943527860481068\n",
      "train loss:1.0146373884387574\n",
      "train loss:0.9002473458883185\n",
      "train loss:0.9145049529659761\n",
      "train loss:0.7264331810042508\n",
      "train loss:0.9366443118004762\n",
      "train loss:0.8366383296210563\n",
      "train loss:0.8874857894021665\n",
      "train loss:0.8202420595386652\n",
      "train loss:1.0229012762659526\n",
      "train loss:0.9684068429763693\n",
      "train loss:0.9895812557529942\n",
      "train loss:0.8104787021877358\n",
      "train loss:0.8549074549801737\n",
      "train loss:1.0040904356438523\n",
      "train loss:0.8846802063905332\n",
      "train loss:0.8764130725862617\n",
      "train loss:1.0085300499816945\n",
      "train loss:0.8634758358012209\n",
      "train loss:1.02456915744992\n",
      "train loss:0.7966571206545595\n",
      "train loss:0.8106116774060007\n",
      "train loss:0.9967558126271746\n",
      "train loss:0.7069067553943187\n",
      "train loss:0.9210816686057148\n",
      "train loss:0.8765110469583974\n",
      "train loss:0.9401622126076356\n",
      "train loss:0.9840167102305274\n",
      "train loss:0.8908540589645949\n",
      "train loss:1.1482803922797935\n",
      "train loss:0.9675728829682368\n",
      "train loss:0.7972009539286654\n",
      "train loss:0.8744209755019896\n",
      "train loss:0.7969878707134835\n",
      "train loss:1.011056131458631\n",
      "train loss:0.9187357853561771\n",
      "train loss:0.8555275117009512\n",
      "train loss:0.9308452568188937\n",
      "train loss:1.0235432634658475\n",
      "train loss:0.9063123542387135\n",
      "train loss:1.0685900019230212\n",
      "train loss:0.8057734959521754\n",
      "train loss:0.9655078816704254\n",
      "train loss:0.8321225487077609\n",
      "train loss:1.0612536894231013\n",
      "train loss:0.9869791884326068\n",
      "train loss:0.9420609951892611\n",
      "train loss:0.8094491611783675\n",
      "train loss:1.0432746776649242\n",
      "train loss:0.782824667792095\n",
      "train loss:0.9366584546966336\n",
      "train loss:0.7622085394057763\n",
      "train loss:0.9442448765533581\n",
      "train loss:0.8827804828683874\n",
      "train loss:0.8142853087665913\n",
      "train loss:0.8830743241654129\n",
      "train loss:0.8100525530087423\n",
      "train loss:0.8018738161317317\n",
      "train loss:0.8639198659959096\n",
      "train loss:1.0538066923360738\n",
      "train loss:0.9430962683143923\n",
      "train loss:0.9732059635632488\n",
      "train loss:0.8631565309611814\n",
      "train loss:0.815838572015504\n",
      "train loss:0.8596472601409856\n",
      "train loss:0.8365239084439287\n",
      "train loss:0.9351954544038789\n",
      "train loss:0.8581177184438377\n",
      "train loss:0.70233818024524\n",
      "train loss:0.8353416749134517\n",
      "=== epoch:8, train acc:0.994, test acc:0.994 ===\n",
      "train loss:0.8157443040595197\n",
      "train loss:0.9344210600385451\n",
      "train loss:0.9503677668190029\n",
      "train loss:0.8508580409807636\n",
      "train loss:0.8748228814597239\n",
      "train loss:0.9604454734232277\n",
      "train loss:0.9920397370021182\n",
      "train loss:0.9608565674460184\n",
      "train loss:1.0475436817263082\n",
      "train loss:0.8399125641866252\n",
      "train loss:0.8422360416086605\n",
      "train loss:0.9052528665834089\n",
      "train loss:0.8544322702791892\n",
      "train loss:0.8824435156131952\n",
      "train loss:1.0049232547809146\n",
      "train loss:0.7454123703623727\n",
      "train loss:0.9503094311547285\n",
      "train loss:0.8743291129102575\n",
      "train loss:0.9014890844581774\n",
      "train loss:0.990214204787663\n",
      "train loss:0.7092222527079548\n",
      "train loss:0.8685858699758469\n",
      "train loss:0.958170991381814\n",
      "train loss:0.9957533923486069\n",
      "train loss:0.7910185598842859\n",
      "train loss:0.8158799643724615\n",
      "train loss:0.8679122686552294\n",
      "train loss:0.8109959855906004\n",
      "train loss:0.919456957000558\n",
      "train loss:0.8641490990324221\n",
      "train loss:0.9258913646901051\n",
      "train loss:1.010034928032826\n",
      "train loss:0.9459073908859836\n",
      "train loss:0.945311199844231\n",
      "train loss:1.0086347762158159\n",
      "train loss:1.112497234689436\n",
      "train loss:0.7487643948174022\n",
      "train loss:0.7723724147272419\n",
      "train loss:0.8831084228019109\n",
      "train loss:0.7323244978462103\n",
      "train loss:0.8293086109491874\n",
      "train loss:0.9673905910424131\n",
      "train loss:0.8837341899293673\n",
      "train loss:0.7484901400982095\n",
      "train loss:1.025941860137766\n",
      "train loss:0.9028845159805055\n",
      "train loss:0.954647502571539\n",
      "train loss:0.8952382385534123\n",
      "train loss:0.8668112117780951\n",
      "train loss:0.9346213260798482\n",
      "train loss:1.0107460343188701\n",
      "train loss:0.9358363171926039\n",
      "train loss:0.8754641270267426\n",
      "train loss:0.8402407330414541\n",
      "train loss:1.005242102924946\n",
      "train loss:1.0366658937385367\n",
      "train loss:0.8032788476263859\n",
      "train loss:0.8388715034865655\n",
      "train loss:0.8743249619882092\n",
      "train loss:0.9261859575825251\n",
      "train loss:1.0577419211123136\n",
      "train loss:0.9181540274595771\n",
      "train loss:0.8554193200525781\n",
      "train loss:0.9171281765953555\n",
      "train loss:0.876318163723529\n",
      "train loss:0.9349341835269245\n",
      "train loss:0.7926317551481783\n",
      "train loss:0.8182968486101967\n",
      "train loss:0.9372620770980771\n",
      "train loss:1.0175632277213644\n",
      "train loss:0.9928159048750151\n",
      "train loss:0.7794575896266732\n",
      "train loss:0.9549459733681495\n",
      "train loss:0.8465874136460569\n",
      "train loss:0.8399277297850007\n",
      "train loss:0.8528286681579198\n",
      "train loss:0.9200778069873553\n",
      "train loss:0.7611550275621703\n",
      "train loss:0.9140113667267432\n",
      "train loss:1.0300185714469041\n",
      "train loss:0.7987204547302081\n",
      "train loss:0.8603774729200913\n",
      "train loss:1.181936553338555\n",
      "train loss:0.9814972526522212\n",
      "train loss:1.0281303865118303\n",
      "train loss:0.8774133908475078\n",
      "train loss:0.8852788081120799\n",
      "train loss:0.9033578467330133\n",
      "train loss:0.8410403313514293\n",
      "train loss:0.9252859771328883\n",
      "train loss:1.0210924143879583\n",
      "train loss:0.8806057477470514\n",
      "train loss:0.8158161677231509\n",
      "train loss:0.8237720378413556\n",
      "train loss:0.9353704864235877\n",
      "train loss:0.8589796987179154\n",
      "train loss:0.9268441933177302\n",
      "train loss:0.9598300847949263\n",
      "train loss:0.9819112472946339\n",
      "train loss:0.8800002795848796\n",
      "train loss:0.9106033864263349\n",
      "train loss:0.8810333439816432\n",
      "train loss:0.9522097256166204\n",
      "train loss:1.0255562898289954\n",
      "train loss:0.8995383233950527\n",
      "train loss:0.9968973036796034\n",
      "train loss:0.9393723151949487\n",
      "train loss:0.9123975226542173\n",
      "train loss:0.9226207222443682\n",
      "train loss:0.8634408336780025\n",
      "train loss:0.9097942086933442\n",
      "train loss:0.7648903592549288\n",
      "train loss:0.9101279147055941\n",
      "train loss:0.9922674332565827\n",
      "train loss:0.8846626862050513\n",
      "train loss:0.9127520206552552\n",
      "train loss:0.9054050617433309\n",
      "train loss:1.0194613904232206\n",
      "train loss:1.0065539512421797\n",
      "train loss:0.7973118300224701\n",
      "train loss:1.0630270505713824\n",
      "train loss:0.9717638670455089\n",
      "train loss:0.8827735221559396\n",
      "train loss:0.960331756310453\n",
      "train loss:1.0014992033830739\n",
      "train loss:0.8342077250595975\n",
      "train loss:0.732189655556689\n",
      "train loss:0.7739282992930586\n",
      "train loss:0.9008289459633991\n",
      "train loss:0.8601653051112961\n",
      "train loss:0.8868191017508364\n",
      "train loss:0.9222851031157283\n",
      "train loss:1.0375144891544696\n",
      "train loss:1.0842598130821999\n",
      "train loss:0.9100827648333327\n",
      "train loss:0.9539940270986758\n",
      "train loss:0.9958106613617025\n",
      "train loss:0.9647674847903077\n",
      "train loss:0.8918500960883192\n",
      "train loss:0.9693859829532022\n",
      "train loss:0.9665986385866572\n",
      "train loss:0.8642450431411836\n",
      "train loss:0.7915306195211165\n",
      "train loss:0.8872592726795687\n",
      "train loss:0.9176318099939976\n",
      "train loss:0.8278697263405959\n",
      "train loss:0.9396456568503011\n",
      "train loss:0.9072647882225131\n",
      "train loss:1.0686747843606565\n",
      "train loss:0.82400239851655\n",
      "train loss:0.9605324887750598\n",
      "train loss:0.983656616189449\n",
      "train loss:0.931510883158936\n",
      "train loss:0.9163930211659292\n",
      "train loss:1.0477467887188034\n",
      "train loss:0.9581188466651027\n",
      "train loss:0.8137969152519726\n",
      "train loss:0.8669303432437464\n",
      "train loss:0.7188162658836\n",
      "train loss:1.0082423977085673\n",
      "train loss:0.9934690303958134\n",
      "train loss:0.9114559217423018\n",
      "train loss:1.0585739704002994\n",
      "train loss:0.9221933282237166\n",
      "train loss:0.9677398504965731\n",
      "train loss:0.9461594277872584\n",
      "train loss:1.0129031323148532\n",
      "train loss:1.0621717829697344\n",
      "train loss:0.767455888786605\n",
      "train loss:0.9352827100225249\n",
      "train loss:0.9635912053209441\n",
      "train loss:0.83988324900229\n",
      "train loss:0.8022340986936172\n",
      "train loss:0.8915938260408207\n",
      "train loss:0.8593482473291131\n",
      "train loss:0.9854581569674962\n",
      "train loss:0.9745819554113193\n",
      "train loss:1.100981638405164\n",
      "train loss:0.8821768854006945\n",
      "train loss:0.9364573238335034\n",
      "train loss:0.9684736042192119\n",
      "train loss:0.9136851623717894\n",
      "train loss:0.9084475308177957\n",
      "train loss:0.8053773255798576\n",
      "train loss:0.8416416301417352\n",
      "train loss:0.8160412356736774\n",
      "train loss:0.7624794092028675\n",
      "train loss:1.0108389874794\n",
      "train loss:0.9276770473589676\n",
      "train loss:0.95502423474137\n",
      "train loss:0.9998308495071799\n",
      "train loss:0.9169405356835952\n",
      "train loss:0.8648455301095319\n",
      "train loss:0.9643958267225763\n",
      "train loss:0.8833505166320674\n",
      "train loss:0.7219705871730153\n",
      "train loss:0.8310544213870432\n",
      "train loss:0.9384156889193096\n",
      "train loss:0.9558015212804183\n",
      "train loss:0.9161446172583426\n",
      "train loss:0.8168979190179776\n",
      "train loss:0.8125478050726416\n",
      "train loss:0.8141268703781822\n",
      "train loss:0.7591501840634624\n",
      "train loss:0.883763005628525\n",
      "train loss:0.9784608553832065\n",
      "train loss:0.946037489525642\n",
      "train loss:1.0809831010745239\n",
      "train loss:0.9347793370305257\n",
      "train loss:1.0317215234647938\n",
      "train loss:0.7727618361174811\n",
      "train loss:0.9955265290203654\n",
      "train loss:0.8279659829093045\n",
      "train loss:0.9168141345112706\n",
      "train loss:0.8933092784852592\n",
      "train loss:0.9597267284666221\n",
      "train loss:0.987071217829153\n",
      "train loss:1.036815087671095\n",
      "train loss:0.8187614345533157\n",
      "train loss:0.9448350266754382\n",
      "train loss:0.9128562483155784\n",
      "train loss:0.8969715035957868\n",
      "train loss:0.8074859802932941\n",
      "train loss:0.7910821226385905\n",
      "train loss:0.8596891322673157\n",
      "train loss:1.035990025125806\n",
      "train loss:0.8163693306731613\n",
      "train loss:0.9678437578888641\n",
      "train loss:0.8242272967953136\n",
      "train loss:0.8013843945446173\n",
      "train loss:0.9865159602367994\n",
      "train loss:0.8709361981456972\n",
      "train loss:1.0062206952834556\n",
      "train loss:0.7571274574477412\n",
      "train loss:0.995314673077729\n",
      "train loss:0.8488011109644247\n",
      "train loss:0.7596604911506725\n",
      "train loss:0.890971134176495\n",
      "train loss:0.8211141129766015\n",
      "train loss:0.9007272846415791\n",
      "train loss:0.98354101741943\n",
      "train loss:1.061679563029629\n",
      "train loss:0.9879235629819669\n",
      "train loss:0.841818085167333\n",
      "train loss:0.9175775288741792\n",
      "train loss:0.7922622852955028\n",
      "train loss:1.1809245163050632\n",
      "train loss:0.7430852750228971\n",
      "train loss:0.8216298501884256\n",
      "train loss:1.0036188536074797\n",
      "train loss:0.880765967659886\n",
      "train loss:0.8907371496000601\n",
      "train loss:0.8969706544542574\n",
      "train loss:0.9590407220021067\n",
      "train loss:0.8273798192624716\n",
      "train loss:0.8019334989256095\n",
      "train loss:0.9634615545638234\n",
      "train loss:0.9066989597952577\n",
      "train loss:1.1409620804665286\n",
      "train loss:0.8577959378040936\n",
      "train loss:0.8682303004958214\n",
      "train loss:0.9625228756223736\n",
      "train loss:0.8391018406180176\n",
      "train loss:0.9845216566199873\n",
      "train loss:0.9204491095836473\n",
      "train loss:1.0141891592272432\n",
      "train loss:0.9050391010504722\n",
      "train loss:0.8689565758555454\n",
      "train loss:0.9076438216900559\n",
      "train loss:0.9486055189743813\n",
      "train loss:0.994929908130436\n",
      "train loss:0.8165593894409122\n",
      "train loss:0.9334195967430202\n",
      "train loss:1.1317262783379753\n",
      "train loss:0.9813129065215072\n",
      "train loss:0.999595886143974\n",
      "train loss:0.945889065284383\n",
      "train loss:1.0520630539028717\n",
      "train loss:0.8307058579942719\n",
      "train loss:0.8337540031319404\n",
      "train loss:0.8064030150986646\n",
      "train loss:0.8138616791456657\n",
      "train loss:0.9317704635873616\n",
      "train loss:0.9314234818572251\n",
      "train loss:0.8803930607455098\n",
      "train loss:0.8492328207960341\n",
      "train loss:1.0466247507102882\n",
      "train loss:0.8686200171891807\n",
      "train loss:0.8224630498038923\n",
      "train loss:0.969952574668594\n",
      "train loss:0.9381356695854266\n",
      "train loss:0.9721798338021891\n",
      "train loss:0.8049398672532441\n",
      "train loss:0.7475098271338659\n",
      "train loss:0.949384043063031\n",
      "train loss:0.9476886352954245\n",
      "train loss:0.9693605371187459\n",
      "train loss:0.9852037510592203\n",
      "train loss:0.8697604655301221\n",
      "train loss:1.0827083983299388\n",
      "train loss:0.9319949152580371\n",
      "train loss:0.9560315365763223\n",
      "train loss:0.8556223609353991\n",
      "train loss:0.9886658641027942\n",
      "train loss:0.9338094635421054\n",
      "train loss:0.8409116767797054\n",
      "train loss:0.9714497856033241\n",
      "train loss:0.8293827732242822\n",
      "train loss:0.9048518161687984\n",
      "train loss:0.881386921340831\n",
      "train loss:0.817105465509147\n",
      "train loss:0.8184866353499787\n",
      "train loss:0.9708862626909568\n",
      "train loss:0.8834526246756711\n",
      "train loss:0.9540392794486087\n",
      "train loss:0.7684329644508882\n",
      "train loss:0.986779252029161\n",
      "train loss:0.8332954356618852\n",
      "train loss:0.9794544663082257\n",
      "train loss:1.0104710603700753\n",
      "train loss:0.9128501531487941\n",
      "train loss:0.8011390890631716\n",
      "train loss:0.8553212803240321\n",
      "train loss:0.7951337202182788\n",
      "train loss:1.0423223414883425\n",
      "train loss:0.9764777879471974\n",
      "train loss:0.7031646471028847\n",
      "train loss:1.0474568106313804\n",
      "train loss:0.9268837544730133\n",
      "train loss:1.058857231822773\n",
      "train loss:0.967453779135361\n",
      "train loss:0.9433305219274994\n",
      "train loss:0.9210272287649519\n",
      "train loss:0.8724935588665035\n",
      "train loss:0.9623640895830864\n",
      "train loss:0.8562501814147885\n",
      "train loss:0.9590369782889926\n",
      "train loss:0.8437936425643187\n",
      "train loss:0.9313973638573217\n",
      "train loss:0.9433464465751272\n",
      "train loss:0.8245820585425961\n",
      "train loss:0.7798080247417083\n",
      "train loss:1.0179960874375953\n",
      "train loss:0.8180136351413796\n",
      "train loss:1.0248467313647929\n",
      "train loss:0.9682251607091452\n",
      "train loss:0.8667374028129121\n",
      "train loss:1.0075902256045284\n",
      "train loss:0.8364341596878265\n",
      "train loss:0.7467222794389613\n",
      "train loss:0.999158111187298\n",
      "train loss:0.988096720158046\n",
      "train loss:1.0091179605004457\n",
      "train loss:0.9743180310322876\n",
      "train loss:1.0739814548020736\n",
      "train loss:0.7953590300178177\n",
      "train loss:0.8905132090151249\n",
      "train loss:1.0775212197764847\n",
      "train loss:0.7883019599763275\n",
      "train loss:0.7409800851583068\n",
      "train loss:0.9785914080883406\n",
      "train loss:0.85219463759587\n",
      "train loss:0.8101539488345866\n",
      "train loss:0.795782798255265\n",
      "train loss:0.9240383879461439\n",
      "train loss:0.9078590401935142\n",
      "train loss:0.9959527849541532\n",
      "train loss:0.8141119247466161\n",
      "train loss:0.9391768696732111\n",
      "train loss:0.8470539353509754\n",
      "train loss:0.9670419813519211\n",
      "train loss:1.0564351451668879\n",
      "train loss:0.7859636487424454\n",
      "train loss:0.9104363157790775\n",
      "train loss:0.8918063480181176\n",
      "train loss:1.0154652841254121\n",
      "train loss:0.8511414384106198\n",
      "train loss:0.9285132032415491\n",
      "train loss:1.1170702468811327\n",
      "train loss:0.9440782625188687\n",
      "train loss:0.8664973513223321\n",
      "train loss:0.8716247489556926\n",
      "train loss:0.9982944550875023\n",
      "train loss:0.7198773110494886\n",
      "train loss:1.0376628790901499\n",
      "train loss:1.0167770588973424\n",
      "train loss:0.8798498501417796\n",
      "train loss:0.8813981312815122\n",
      "train loss:0.8924139819709255\n",
      "train loss:0.9154670529053004\n",
      "train loss:0.8981539575432894\n",
      "train loss:0.772774689021848\n",
      "train loss:0.9194106991565788\n",
      "train loss:0.8125762148816728\n",
      "train loss:0.8939466388437158\n",
      "train loss:0.9433893785407409\n",
      "train loss:0.848889786207688\n",
      "train loss:0.9220226980509678\n",
      "train loss:0.9029629796804732\n",
      "train loss:0.9133596112292459\n",
      "train loss:1.0766032139513901\n",
      "train loss:0.8344583816720273\n",
      "train loss:0.8163371699281218\n",
      "train loss:0.8587941443382031\n",
      "train loss:0.9328905325643181\n",
      "train loss:0.9323443364310041\n",
      "train loss:0.8688551814543558\n",
      "train loss:0.8073241709995638\n",
      "train loss:0.8267503627581939\n",
      "train loss:0.8201657494318123\n",
      "train loss:0.820267436347515\n",
      "train loss:0.7979774661661843\n",
      "train loss:0.9613333178883039\n",
      "train loss:0.7809393710740471\n",
      "train loss:0.989867262823978\n",
      "train loss:0.9131143527573963\n",
      "train loss:0.8964212605465355\n",
      "train loss:0.9326443556353073\n",
      "train loss:1.0993290235472841\n",
      "train loss:0.8225122716928587\n",
      "train loss:0.8509037124730078\n",
      "train loss:1.0188662137152145\n",
      "train loss:0.6391612397080901\n",
      "train loss:0.9635882256545735\n",
      "train loss:0.8960559132972774\n",
      "train loss:0.9205636192126175\n",
      "train loss:0.9020797567529132\n",
      "train loss:0.7859813669738446\n",
      "train loss:0.9641497312302573\n",
      "train loss:0.8886861911661222\n",
      "train loss:0.9495703182726604\n",
      "train loss:1.0317145093329023\n",
      "train loss:1.0280586588412672\n",
      "train loss:0.8461315154013801\n",
      "train loss:0.7599172930720086\n",
      "train loss:0.8395413760891138\n",
      "train loss:0.9252124780305852\n",
      "train loss:0.9936541170839936\n",
      "train loss:0.8528945796789046\n",
      "train loss:1.086595078565045\n",
      "train loss:0.9687142569844702\n",
      "train loss:0.9482700182191399\n",
      "train loss:1.0548869843229896\n",
      "train loss:0.8994546764038333\n",
      "train loss:0.9629761951172435\n",
      "train loss:0.8576040172376497\n",
      "train loss:0.8553549979425266\n",
      "train loss:0.9757879296928774\n",
      "train loss:1.108353594344142\n",
      "train loss:0.9116574227006881\n",
      "train loss:1.090706366738297\n",
      "train loss:1.052580609331957\n",
      "train loss:0.8996757116436762\n",
      "train loss:0.8331531747524038\n",
      "train loss:1.1457739703445644\n",
      "train loss:0.815424962347314\n",
      "train loss:0.9190102700480811\n",
      "train loss:0.9557604424779271\n",
      "train loss:0.9528333706110854\n",
      "train loss:1.0361257241653385\n",
      "train loss:1.0429580099719689\n",
      "train loss:1.0840151967488945\n",
      "train loss:1.0130413315360949\n",
      "train loss:0.9646281767615023\n",
      "train loss:0.977718552401622\n",
      "train loss:0.863939084101018\n",
      "train loss:0.8128138622562634\n",
      "train loss:0.9891243746152287\n",
      "train loss:0.9450036470526234\n",
      "train loss:0.9290458012418725\n",
      "train loss:0.9652953886728568\n",
      "train loss:0.9669399561526751\n",
      "train loss:1.011986965020109\n",
      "train loss:1.0541948576240414\n",
      "train loss:0.8499259979679116\n",
      "train loss:0.8119806119546139\n",
      "train loss:0.6887812692950209\n",
      "train loss:0.8656731982200475\n",
      "train loss:0.8438215837070402\n",
      "train loss:0.9501503949237637\n",
      "train loss:0.9171296138200316\n",
      "train loss:0.8067999360031989\n",
      "train loss:0.8134405748895409\n",
      "train loss:0.7798217736007486\n",
      "train loss:0.8974102718313194\n",
      "train loss:1.0062061109598859\n",
      "train loss:0.7930760302640281\n",
      "train loss:0.8441218741388306\n",
      "train loss:0.8688577439617627\n",
      "train loss:0.9184391484668524\n",
      "train loss:0.8155678443477921\n",
      "train loss:0.8690458350482411\n",
      "train loss:0.8591055915432056\n",
      "train loss:0.9487616771564404\n",
      "train loss:1.1098367363506259\n",
      "train loss:0.8612903111469632\n",
      "train loss:0.7694376400678854\n",
      "train loss:0.679922806372336\n",
      "train loss:0.7949434928030145\n",
      "train loss:0.7909644198448939\n",
      "train loss:1.0145824403935213\n",
      "train loss:0.8666147106084057\n",
      "train loss:0.9180341818464964\n",
      "train loss:0.8084519253698345\n",
      "train loss:1.0351944821255288\n",
      "train loss:0.9465486634173665\n",
      "train loss:0.7070532523245917\n",
      "train loss:0.914147638759244\n",
      "train loss:0.8373845549764232\n",
      "train loss:1.0041813556304475\n",
      "train loss:0.7384081385434917\n",
      "train loss:0.9154800260608655\n",
      "train loss:0.889490880021884\n",
      "train loss:0.8239371894521565\n",
      "train loss:0.8544129796932225\n",
      "train loss:0.9606654663983601\n",
      "train loss:0.9511506371827245\n",
      "train loss:0.9514248515781363\n",
      "train loss:0.9593661914061831\n",
      "train loss:0.7167514724121199\n",
      "train loss:0.9411184473489657\n",
      "train loss:0.7961279911578815\n",
      "train loss:0.931554128925149\n",
      "train loss:0.8048598136900709\n",
      "train loss:0.8990379602434428\n",
      "train loss:0.8519079806770324\n",
      "train loss:0.8640757109490319\n",
      "train loss:0.8992493282421079\n",
      "train loss:0.9400681744416213\n",
      "train loss:0.9171645001423364\n",
      "train loss:0.9536942654950425\n",
      "train loss:0.895782498002652\n",
      "train loss:0.9852665125846278\n",
      "train loss:1.0214630525334687\n",
      "train loss:0.8853370686899715\n",
      "train loss:0.9130021464922445\n",
      "train loss:0.9222890717317408\n",
      "train loss:1.0854798696928563\n",
      "train loss:0.8787497353322054\n",
      "train loss:0.921057100987986\n",
      "train loss:0.9419651190424239\n",
      "train loss:0.8629078314000622\n",
      "train loss:0.9173455741745229\n",
      "train loss:0.8692914296180178\n",
      "train loss:0.7560221032853609\n",
      "train loss:0.8497332166534922\n",
      "train loss:0.9188958942125328\n",
      "train loss:1.0538359385408465\n",
      "train loss:0.9901130800099337\n",
      "train loss:0.8837750004373441\n",
      "train loss:0.8413822677970616\n",
      "train loss:0.8116357409826405\n",
      "train loss:0.8112454899333259\n",
      "train loss:0.7045793967267008\n",
      "train loss:1.0401984380446405\n",
      "train loss:0.850026549892273\n",
      "train loss:0.8105174317493332\n",
      "train loss:0.9335184268836432\n",
      "train loss:0.883672653911852\n",
      "train loss:0.9288644212316889\n",
      "train loss:0.7873538924951266\n",
      "train loss:0.9191708254087014\n",
      "train loss:0.8473445982551664\n",
      "train loss:0.7735423341817744\n",
      "train loss:0.9238335372458808\n",
      "train loss:0.9761825867952806\n",
      "train loss:1.026423541696638\n",
      "train loss:0.7812882959924974\n",
      "train loss:0.9792052038294337\n",
      "train loss:0.8403033637223223\n",
      "train loss:0.8292401555552752\n",
      "train loss:0.8996040028127714\n",
      "train loss:1.0380778956603907\n",
      "train loss:0.9942970623461442\n",
      "train loss:0.927923856256914\n",
      "train loss:0.8093379584413714\n",
      "train loss:0.8312055174093079\n",
      "train loss:0.8115114084985869\n",
      "train loss:0.8921817995417104\n",
      "train loss:0.9188821896112838\n",
      "train loss:0.8637516934582576\n",
      "train loss:0.9148113199868368\n",
      "train loss:0.8575233539475318\n",
      "train loss:0.8352779385297266\n",
      "train loss:0.9576252762461617\n",
      "train loss:0.9653791616304662\n",
      "train loss:0.9432677626370795\n",
      "train loss:0.9844319431915582\n",
      "train loss:0.9589428439849895\n",
      "train loss:0.940036351453552\n",
      "train loss:0.8538894147308238\n",
      "train loss:0.9611490616537168\n",
      "train loss:0.9571038402120579\n",
      "train loss:0.8213160172023812\n",
      "train loss:0.8870730931607039\n",
      "train loss:0.8972131069360725\n",
      "train loss:0.9027237059950708\n",
      "train loss:0.7995475887760932\n",
      "train loss:0.8445678825801863\n",
      "train loss:1.1458073453874744\n",
      "=== epoch:9, train acc:0.991, test acc:0.991 ===\n",
      "train loss:0.7826449135880985\n",
      "train loss:0.7678694139546391\n",
      "train loss:0.7604345991611078\n",
      "train loss:0.7677865071956643\n",
      "train loss:0.924360874313298\n",
      "train loss:0.7854474869337434\n",
      "train loss:0.8809077596277745\n",
      "train loss:0.8551597756019593\n",
      "train loss:0.895535245892011\n",
      "train loss:0.7400474485927109\n",
      "train loss:1.021410652626473\n",
      "train loss:0.8992283929375644\n",
      "train loss:0.85628314926394\n",
      "train loss:0.7796433223963013\n",
      "train loss:0.8923078671265553\n",
      "train loss:0.9879729135696326\n",
      "train loss:0.9758045726083351\n",
      "train loss:1.0557371701283293\n",
      "train loss:0.8803342621213642\n",
      "train loss:1.0943367907246129\n",
      "train loss:0.9017853971100935\n",
      "train loss:0.944992860659331\n",
      "train loss:0.8365853133977008\n",
      "train loss:0.8979811920107603\n",
      "train loss:0.8528252330509405\n",
      "train loss:0.9207753630444659\n",
      "train loss:0.767783263633784\n",
      "train loss:0.7450597144467258\n",
      "train loss:0.9034623860549982\n",
      "train loss:1.0956160298394166\n",
      "train loss:0.85737844086058\n",
      "train loss:0.7033855786921719\n",
      "train loss:0.931168389556533\n",
      "train loss:0.7964020172966305\n",
      "train loss:1.0381317682222275\n",
      "train loss:0.8306979488278639\n",
      "train loss:0.8154280354198948\n",
      "train loss:0.8039813177653801\n",
      "train loss:0.9074225694029404\n",
      "train loss:0.7622301781710541\n",
      "train loss:0.7916161066976325\n",
      "train loss:1.1630336707554731\n",
      "train loss:1.0023421725923953\n",
      "train loss:0.8481499732174332\n",
      "train loss:0.8840230033852882\n",
      "train loss:0.7959421434488259\n",
      "train loss:0.8761818279339036\n",
      "train loss:0.914594994359954\n",
      "train loss:0.8590292314058207\n",
      "train loss:0.9821917540484314\n",
      "train loss:1.0577752651807353\n",
      "train loss:0.7237760968438374\n",
      "train loss:0.9019961952863408\n",
      "train loss:0.8885636526416747\n",
      "train loss:0.806137949519211\n",
      "train loss:0.8658327092123163\n",
      "train loss:0.8900196842564221\n",
      "train loss:0.898567602624981\n",
      "train loss:0.7919594441953202\n",
      "train loss:0.8356948832742277\n",
      "train loss:0.8002171379573891\n",
      "train loss:0.9839952121308077\n",
      "train loss:0.8662593162234673\n",
      "train loss:0.9250799889024108\n",
      "train loss:0.676962058460759\n",
      "train loss:0.7400805959706761\n",
      "train loss:0.8424445972183037\n",
      "train loss:0.9522105902978508\n",
      "train loss:0.9368189746200014\n",
      "train loss:0.8237800615611122\n",
      "train loss:0.9222078205813107\n",
      "train loss:0.8766488878591389\n",
      "train loss:1.0337633292328297\n",
      "train loss:0.863722146399589\n",
      "train loss:0.8760654483643848\n",
      "train loss:0.8282538511681687\n",
      "train loss:1.0001605853103315\n",
      "train loss:0.8581152632908726\n",
      "train loss:1.0158511617348587\n",
      "train loss:0.8752037375915203\n",
      "train loss:0.6137508016343709\n",
      "train loss:0.8557314697279721\n",
      "train loss:0.7964975158691567\n",
      "train loss:0.904984303125857\n",
      "train loss:0.9117616944103787\n",
      "train loss:0.9995555633230627\n",
      "train loss:0.9115479444052642\n",
      "train loss:1.0131052126191735\n",
      "train loss:0.9604461375483777\n",
      "train loss:0.8966585128951443\n",
      "train loss:0.8562551050100429\n",
      "train loss:0.8235943049400273\n",
      "train loss:0.849846217108286\n",
      "train loss:0.8422727994175502\n",
      "train loss:1.0814135988838502\n",
      "train loss:0.810895094350906\n",
      "train loss:0.8452130412914904\n",
      "train loss:0.7730476378914729\n",
      "train loss:0.819532754274947\n",
      "train loss:0.7860249451964954\n",
      "train loss:1.0374929478702573\n",
      "train loss:0.7972950391119437\n",
      "train loss:0.820925821930136\n",
      "train loss:0.9246387742244235\n",
      "train loss:0.8198426114466659\n",
      "train loss:0.8875476105097795\n",
      "train loss:0.9583310920284259\n",
      "train loss:0.8479888844002379\n",
      "train loss:0.7912873228729573\n",
      "train loss:0.780081850088726\n",
      "train loss:0.976243905615855\n",
      "train loss:0.8887176768606789\n",
      "train loss:0.9200974621205981\n",
      "train loss:0.953981381756694\n",
      "train loss:0.8593296912776198\n",
      "train loss:0.9095970285434879\n",
      "train loss:0.8793005340525895\n",
      "train loss:0.7652624212559376\n",
      "train loss:0.8074425257532616\n",
      "train loss:1.0007037640804932\n",
      "train loss:1.024195411914037\n",
      "train loss:0.8421288245134859\n",
      "train loss:1.1298770822459978\n",
      "train loss:0.8490378034661699\n",
      "train loss:1.0922546334635777\n",
      "train loss:0.8710720640989897\n",
      "train loss:1.0211576883116766\n",
      "train loss:0.7614682133713644\n",
      "train loss:0.9898225507799058\n",
      "train loss:0.8550102296500438\n",
      "train loss:0.9772978708894694\n",
      "train loss:0.7645984663143979\n",
      "train loss:0.9617267671925621\n",
      "train loss:0.8202713290320338\n",
      "train loss:0.8923747686157028\n",
      "train loss:0.780266979165567\n",
      "train loss:0.8852389137435769\n",
      "train loss:0.9947993165462671\n",
      "train loss:0.899695370793054\n",
      "train loss:0.8522388876849787\n",
      "train loss:0.7866589100664254\n",
      "train loss:0.840842149626797\n",
      "train loss:0.7877461178497037\n",
      "train loss:0.9278797096562369\n",
      "train loss:0.8730337637422574\n",
      "train loss:0.9752643568789829\n",
      "train loss:0.8850864133849495\n",
      "train loss:0.953658368642644\n",
      "train loss:0.8878666742019855\n",
      "train loss:1.0588871268117994\n",
      "train loss:0.9629665048004104\n",
      "train loss:0.8332953378541272\n",
      "train loss:0.80836986068824\n",
      "train loss:1.022423867860815\n",
      "train loss:0.9580896731362946\n",
      "train loss:0.9460636436397203\n",
      "train loss:0.9222876648404954\n",
      "train loss:0.8600259703093149\n",
      "train loss:0.8837821189100346\n",
      "train loss:0.7853969382163202\n",
      "train loss:0.8478308652420838\n",
      "train loss:0.9584318016494464\n",
      "train loss:1.0041994390351194\n",
      "train loss:1.017271601041842\n",
      "train loss:0.6663723461892015\n",
      "train loss:0.9652378725054702\n",
      "train loss:1.0006384442866387\n",
      "train loss:0.9125794224875152\n",
      "train loss:0.8080440321200661\n",
      "train loss:0.9929284979890882\n",
      "train loss:0.9179945008895222\n",
      "train loss:1.0012515119773244\n",
      "train loss:1.018972144386478\n",
      "train loss:1.1656693472990711\n",
      "train loss:0.8204744237382325\n",
      "train loss:0.8455332272172202\n",
      "train loss:0.8838997648963995\n",
      "train loss:0.8981333949261671\n",
      "train loss:0.9396035405777229\n",
      "train loss:0.8459417731585103\n",
      "train loss:0.9464636173335844\n",
      "train loss:0.8313327728700726\n",
      "train loss:0.8351583291427721\n",
      "train loss:1.1423717024457907\n",
      "train loss:0.9967444890257724\n",
      "train loss:0.9908274544332659\n",
      "train loss:0.8118197027853371\n",
      "train loss:0.775870769481765\n",
      "train loss:0.7606009196718919\n",
      "train loss:0.7270357449850212\n",
      "train loss:0.8987739515245119\n",
      "train loss:0.9401846967887141\n",
      "train loss:1.0164240370373527\n",
      "train loss:1.2246355486104652\n",
      "train loss:0.8288189107519398\n",
      "train loss:0.8345698292015338\n",
      "train loss:0.9176692248273527\n",
      "train loss:0.830072455370261\n",
      "train loss:1.0296358825102312\n",
      "train loss:0.9014889638069693\n",
      "train loss:0.8621833740980672\n",
      "train loss:0.8536414035699503\n",
      "train loss:0.995166879728734\n",
      "train loss:0.858022511259168\n",
      "train loss:0.6946837131816355\n",
      "train loss:0.8469123220840389\n",
      "train loss:0.8498595307898659\n",
      "train loss:1.0407267482147837\n",
      "train loss:0.9215352010422225\n",
      "train loss:0.6832206168732838\n",
      "train loss:0.7966406271052339\n",
      "train loss:0.9913877855219205\n",
      "train loss:0.7609664326240397\n",
      "train loss:0.9099861309713438\n",
      "train loss:0.8359117171369135\n",
      "train loss:0.8696386876657667\n",
      "train loss:0.9395683392692183\n",
      "train loss:0.8309987359499154\n",
      "train loss:0.7883916383614042\n",
      "train loss:1.0202023183428306\n",
      "train loss:0.9592551203387546\n",
      "train loss:0.8041211790000102\n",
      "train loss:0.8853982231631389\n",
      "train loss:0.8829877369087115\n",
      "train loss:0.9505430121862988\n",
      "train loss:0.7888889098441143\n",
      "train loss:0.9650028228122622\n",
      "train loss:0.7576361275480649\n",
      "train loss:0.9034945380141269\n",
      "train loss:0.8221058848919046\n",
      "train loss:0.864355379457047\n",
      "train loss:0.8910494208204688\n",
      "train loss:0.8972157465405796\n",
      "train loss:0.9792150791097736\n",
      "train loss:0.9094963090817054\n",
      "train loss:0.9115039563806094\n",
      "train loss:0.9023392675147303\n",
      "train loss:0.781975295051629\n",
      "train loss:0.8729883424485112\n",
      "train loss:0.7273385530937427\n",
      "train loss:0.9192216472935393\n",
      "train loss:0.8367934752163024\n",
      "train loss:0.7798268889167411\n",
      "train loss:0.8971634829251036\n",
      "train loss:0.9623637135971341\n",
      "train loss:1.0982566099430444\n",
      "train loss:0.8415092912371517\n",
      "train loss:1.0624760683147974\n",
      "train loss:0.919671717746215\n",
      "train loss:0.9591101596767783\n",
      "train loss:0.9473354697026666\n",
      "train loss:0.782380376883905\n",
      "train loss:1.009074432705701\n",
      "train loss:0.8365627494308887\n",
      "train loss:1.0310032907805808\n",
      "train loss:1.0369467859771775\n",
      "train loss:0.9097188833256223\n",
      "train loss:0.807233710027744\n",
      "train loss:0.8439883007481005\n",
      "train loss:1.0767347275912535\n",
      "train loss:0.9608779860562631\n",
      "train loss:1.0556409043204678\n",
      "train loss:0.9808039086853256\n",
      "train loss:1.067085705672261\n",
      "train loss:0.9136354269987563\n",
      "train loss:1.0155574540406742\n",
      "train loss:0.9070619085936855\n",
      "train loss:0.817686241420576\n",
      "train loss:1.0441067238837345\n",
      "train loss:0.9869318799460803\n",
      "train loss:0.874841213578817\n",
      "train loss:1.0315829107673864\n",
      "train loss:0.8201694975968583\n",
      "train loss:0.8721987613457033\n",
      "train loss:0.8537783477142022\n",
      "train loss:0.8368812414619269\n",
      "train loss:0.7276046794614608\n",
      "train loss:0.8702613945368444\n",
      "train loss:0.9729898679805689\n",
      "train loss:0.8528668624342973\n",
      "train loss:0.9322312285143493\n",
      "train loss:0.7986708985310449\n",
      "train loss:0.7045565294111704\n",
      "train loss:0.8418695320014464\n",
      "train loss:0.7970939042928571\n",
      "train loss:0.9358566669438129\n",
      "train loss:0.8899707652184174\n",
      "train loss:0.9370890382188355\n",
      "train loss:1.007777274873336\n",
      "train loss:0.8388167558909245\n",
      "train loss:0.8965838681709102\n",
      "train loss:1.1061512936614146\n",
      "train loss:0.9216072454465031\n",
      "train loss:0.7743046614369038\n",
      "train loss:1.0303308972280727\n",
      "train loss:0.9077269683696279\n",
      "train loss:0.879307190076385\n",
      "train loss:0.8800943803922232\n",
      "train loss:0.8187290580437664\n",
      "train loss:1.0044282770112256\n",
      "train loss:0.9226439036553811\n",
      "train loss:1.0375526258010783\n",
      "train loss:0.7532710494438042\n",
      "train loss:0.9802909145833598\n",
      "train loss:0.9433564757808922\n",
      "train loss:1.0774577805769086\n",
      "train loss:0.8970001774288352\n",
      "train loss:0.8996132722446785\n",
      "train loss:0.8618848221591623\n",
      "train loss:0.9317042588869203\n",
      "train loss:0.8364490312992386\n",
      "train loss:0.6605272074681697\n",
      "train loss:0.9374270872637898\n",
      "train loss:0.8108053203344471\n",
      "train loss:0.8896551188148467\n",
      "train loss:0.8821247831953142\n",
      "train loss:0.9457438825586515\n",
      "train loss:0.9278061226591306\n",
      "train loss:0.7396500784255277\n",
      "train loss:1.0254304003688512\n",
      "train loss:0.9140874170990795\n",
      "train loss:0.9042663189232085\n",
      "train loss:0.9176183601110375\n",
      "train loss:0.804217684626309\n",
      "train loss:0.9967660328025012\n",
      "train loss:0.8756239366595377\n",
      "train loss:0.8727094218640792\n",
      "train loss:0.9306689014810946\n",
      "train loss:0.943673569953531\n",
      "train loss:0.8424305091292892\n",
      "train loss:0.7752078522720417\n",
      "train loss:0.9378894381769136\n",
      "train loss:0.9234485819401332\n",
      "train loss:0.8239186870135117\n",
      "train loss:0.8037517852630672\n",
      "train loss:0.957104553815664\n",
      "train loss:0.954007012620934\n",
      "train loss:0.9941412010492005\n",
      "train loss:0.9873487308583873\n",
      "train loss:0.8098941044508998\n",
      "train loss:0.7653253245091307\n",
      "train loss:0.9709926440398005\n",
      "train loss:0.9457077384782699\n",
      "train loss:1.0056914575179865\n",
      "train loss:0.8989035256688019\n",
      "train loss:0.8901936227137612\n",
      "train loss:0.9896918715202517\n",
      "train loss:0.966591046345521\n",
      "train loss:0.8553698349332939\n",
      "train loss:0.9381173169265987\n",
      "train loss:0.856192053950323\n",
      "train loss:0.8937217775495441\n",
      "train loss:1.023876695635237\n",
      "train loss:0.8167072409207381\n",
      "train loss:0.8153045821195771\n",
      "train loss:0.96302336397036\n",
      "train loss:0.8016597608782718\n",
      "train loss:1.027695003443177\n",
      "train loss:1.036096959683591\n",
      "train loss:0.9695181162125632\n",
      "train loss:0.8271100445492485\n",
      "train loss:1.0071348315374002\n",
      "train loss:0.9074933786606175\n",
      "train loss:0.8614391762758901\n",
      "train loss:0.8959513307188033\n",
      "train loss:0.8571150184324925\n",
      "train loss:0.9793668053552272\n",
      "train loss:0.7635549778384566\n",
      "train loss:0.932274831895076\n",
      "train loss:0.9626512821359797\n",
      "train loss:0.8062858350689516\n",
      "train loss:0.9494219513551152\n",
      "train loss:1.0070385059852942\n",
      "train loss:1.0392231951427986\n",
      "train loss:0.8450714241277315\n",
      "train loss:1.1159782626304944\n",
      "train loss:0.8611032951965746\n",
      "train loss:0.8082025055431711\n",
      "train loss:0.9328700965127414\n",
      "train loss:0.9752186708517563\n",
      "train loss:1.029188237158326\n",
      "train loss:0.938837167063984\n",
      "train loss:0.8627772730380804\n",
      "train loss:0.8700442668435128\n",
      "train loss:1.0965654257036312\n",
      "train loss:0.8753060915618831\n",
      "train loss:0.9431261204325182\n",
      "train loss:0.9135570419761059\n",
      "train loss:1.0079465541224477\n",
      "train loss:0.831895196678423\n",
      "train loss:0.8184833748842499\n",
      "train loss:0.932230436020318\n",
      "train loss:0.897459753194907\n",
      "train loss:0.8620204667703808\n",
      "train loss:0.7495596850344404\n",
      "train loss:1.0509098312080136\n",
      "train loss:1.0033918572667893\n",
      "train loss:0.8651542484366843\n",
      "train loss:0.8472837404849247\n",
      "train loss:0.9119741926795666\n",
      "train loss:1.001124910530956\n",
      "train loss:1.0597097074926538\n",
      "train loss:1.0091771921356145\n",
      "train loss:0.8924084158272764\n",
      "train loss:0.8941280477909918\n",
      "train loss:0.9567814555214362\n",
      "train loss:0.9617735432052734\n",
      "train loss:0.8627947209122765\n",
      "train loss:0.8225004208224983\n",
      "train loss:0.9158449677151355\n",
      "train loss:0.975192573543005\n",
      "train loss:0.808354036580298\n",
      "train loss:0.9574720883291644\n",
      "train loss:0.9403860989491842\n",
      "train loss:0.9545146508315591\n",
      "train loss:0.916227174321847\n",
      "train loss:0.9659466363483163\n",
      "train loss:1.0490230300052625\n",
      "train loss:0.9814656221046935\n",
      "train loss:0.8061285998419574\n",
      "train loss:0.8254759349671754\n",
      "train loss:0.8721805583819241\n",
      "train loss:0.891540697666899\n",
      "train loss:0.9378117531814315\n",
      "train loss:0.9680478019145988\n",
      "train loss:0.7716104924729223\n",
      "train loss:0.8548232378094105\n",
      "train loss:0.789805664277778\n",
      "train loss:0.9491822373281056\n",
      "train loss:0.9627846392702146\n",
      "train loss:0.8226867461308015\n",
      "train loss:0.6581534131082947\n",
      "train loss:0.9445173356381572\n",
      "train loss:0.8333271764746697\n",
      "train loss:0.9292203876221373\n",
      "train loss:0.7899159224671368\n",
      "train loss:0.9847448504368066\n",
      "train loss:0.9418017249902628\n",
      "train loss:0.9538357874432143\n",
      "train loss:0.8900217437441335\n",
      "train loss:0.9936301717611561\n",
      "train loss:1.0237151738648373\n",
      "train loss:0.9795862792278265\n",
      "train loss:0.9020840717206415\n",
      "train loss:0.8249360427879147\n",
      "train loss:0.9257267292911224\n",
      "train loss:0.8322583384276798\n",
      "train loss:0.9779368542589189\n",
      "train loss:0.8660857693322004\n",
      "train loss:0.816551424336889\n",
      "train loss:0.8268031319168132\n",
      "train loss:0.8351648408494331\n",
      "train loss:0.9241625960124908\n",
      "train loss:0.8473301427366927\n",
      "train loss:0.85857700030174\n",
      "train loss:1.0048253658339577\n",
      "train loss:0.7741860630415952\n",
      "train loss:0.8694055797306242\n",
      "train loss:0.9842929571749317\n",
      "train loss:1.036587354847589\n",
      "train loss:0.8396172090687926\n",
      "train loss:0.946326108905479\n",
      "train loss:0.9049708859930703\n",
      "train loss:0.8522027035286609\n",
      "train loss:0.9670111715653711\n",
      "train loss:0.811161790885593\n",
      "train loss:0.7676933098827787\n",
      "train loss:1.0407213591119697\n",
      "train loss:0.9299474388854801\n",
      "train loss:0.947188730788387\n",
      "train loss:1.014396385451951\n",
      "train loss:0.8875029790381833\n",
      "train loss:0.926486287246157\n",
      "train loss:0.9885525268832913\n",
      "train loss:0.9740400416563975\n",
      "train loss:0.7599170331850306\n",
      "train loss:0.6836655219527675\n",
      "train loss:0.9525555269735634\n",
      "train loss:0.751983252426526\n",
      "train loss:0.8066332537558364\n",
      "train loss:1.0268775359771232\n",
      "train loss:0.8330318334465687\n",
      "train loss:0.8365063888413369\n",
      "train loss:1.0492784376138697\n",
      "train loss:1.0024288271763746\n",
      "train loss:0.9294227447731466\n",
      "train loss:0.9119485771752969\n",
      "train loss:0.9429239960581066\n",
      "train loss:0.9915105975051928\n",
      "train loss:1.0126895141614662\n",
      "train loss:0.8158264333896698\n",
      "train loss:0.9018289734823202\n",
      "train loss:0.9222225081542926\n",
      "train loss:1.0723718628568901\n",
      "train loss:0.8308159858104881\n",
      "train loss:0.8718442565637713\n",
      "train loss:1.0697458644814046\n",
      "train loss:0.8983059666644345\n",
      "train loss:0.8896980031460298\n",
      "train loss:0.8424458193902676\n",
      "train loss:0.9213740053584373\n",
      "train loss:0.8744585619047089\n",
      "train loss:0.8890855142485019\n",
      "train loss:0.8327282689993232\n",
      "train loss:0.9922849066053265\n",
      "train loss:0.8074620429468317\n",
      "train loss:0.9845754018626539\n",
      "train loss:0.9498688185274647\n",
      "train loss:0.7977225091300693\n",
      "train loss:0.9769545499993763\n",
      "train loss:0.924584096342055\n",
      "train loss:0.9892696748390367\n",
      "train loss:1.0536427166313609\n",
      "train loss:0.7170880125373745\n",
      "train loss:0.8369534503652217\n",
      "train loss:0.9453594139689531\n",
      "train loss:0.6523158355485182\n",
      "train loss:0.8652303465323874\n",
      "train loss:0.9214551112548596\n",
      "train loss:0.8442078082281194\n",
      "train loss:0.9564174821999432\n",
      "train loss:0.9051654925336992\n",
      "train loss:0.945203168685374\n",
      "train loss:0.8211781704335688\n",
      "train loss:0.8975161837444194\n",
      "train loss:0.925421045510942\n",
      "train loss:0.9607530682934723\n",
      "train loss:0.9998880176568182\n",
      "train loss:0.7671635633469072\n",
      "train loss:0.8101777726715258\n",
      "train loss:0.8707125695938561\n",
      "train loss:0.9967245412906709\n",
      "train loss:0.9128579172630726\n",
      "train loss:0.9148108190798774\n",
      "train loss:0.9253202321550198\n",
      "train loss:0.9706965518372512\n",
      "train loss:0.7492511227826149\n",
      "train loss:0.7912825117183167\n",
      "train loss:0.8643048150779493\n",
      "train loss:0.8518482995254049\n",
      "train loss:1.0147955996226057\n",
      "train loss:0.8285630476547239\n",
      "train loss:0.9996339001207002\n",
      "train loss:0.9575005719665381\n",
      "train loss:0.7127958996175738\n",
      "train loss:1.0081335128160105\n",
      "train loss:0.8456041727759501\n",
      "train loss:0.8863500143067503\n",
      "train loss:1.0103458572235193\n",
      "train loss:1.1413266041161427\n",
      "train loss:0.8283857891220079\n",
      "train loss:0.9207242507089777\n",
      "train loss:0.9586074370939435\n",
      "train loss:0.9096709108243733\n",
      "train loss:1.0741517206581892\n",
      "train loss:1.0323584572327424\n",
      "train loss:0.8628997388191739\n",
      "train loss:1.0260831915521726\n",
      "train loss:0.8087070339517572\n",
      "train loss:0.8135897638433275\n",
      "train loss:0.8423280280340806\n",
      "train loss:0.9360911873308138\n",
      "train loss:0.778978645520125\n",
      "train loss:0.7989185108666373\n",
      "train loss:1.042358164420329\n",
      "train loss:0.9921642910118148\n",
      "train loss:0.7869710725580639\n",
      "train loss:0.84199122448268\n",
      "train loss:0.8727902459300922\n",
      "train loss:0.7770754255803822\n",
      "train loss:0.8836977353491657\n",
      "train loss:1.0068814402258357\n",
      "train loss:0.9525160341717244\n",
      "train loss:1.0396312823859895\n",
      "train loss:0.8440602330931242\n",
      "train loss:0.8269188943647658\n",
      "train loss:0.8071835508624742\n",
      "train loss:0.8889023938535456\n",
      "train loss:1.0203968745710872\n",
      "train loss:0.9795234173409743\n",
      "train loss:0.8529115722748888\n",
      "train loss:0.9039788041145029\n",
      "train loss:0.7812370351903314\n",
      "train loss:1.0871061221781897\n",
      "train loss:0.7851289555763603\n",
      "train loss:0.7601588707893621\n",
      "train loss:0.9427645075759596\n",
      "train loss:1.0369229930604367\n",
      "train loss:0.7960094006711003\n",
      "train loss:1.02163998407824\n",
      "train loss:1.1074353293698556\n",
      "train loss:1.0051059993379006\n",
      "train loss:0.7881336826657298\n",
      "train loss:0.7597594932338829\n",
      "train loss:1.0016415678043833\n",
      "train loss:0.9492748446592458\n",
      "train loss:0.8824056875327999\n",
      "train loss:0.8272777234332793\n",
      "train loss:0.9106322722314701\n",
      "train loss:0.8377367415586064\n",
      "=== epoch:10, train acc:0.996, test acc:0.994 ===\n",
      "train loss:0.8822445225490861\n",
      "train loss:0.7555727864906675\n",
      "train loss:0.9629405457481031\n",
      "train loss:0.8560429488940432\n",
      "train loss:0.9141197777806969\n",
      "train loss:0.8513506665708438\n",
      "train loss:0.8961907909897429\n",
      "train loss:1.0394990489362883\n",
      "train loss:0.9041139650232242\n",
      "train loss:0.8690721014542488\n",
      "train loss:0.8432137475774509\n",
      "train loss:0.9013818937309162\n",
      "train loss:0.9548080492793176\n",
      "train loss:0.8276919977005762\n",
      "train loss:0.935527175543584\n",
      "train loss:0.8776407903220858\n",
      "train loss:0.8385546715917179\n",
      "train loss:0.9043702741093146\n",
      "train loss:0.9331133016965163\n",
      "train loss:0.8306740458261038\n",
      "train loss:0.8367118248659962\n",
      "train loss:1.0377262984151365\n",
      "train loss:0.8650149622570372\n",
      "train loss:0.9161685283565321\n",
      "train loss:1.038357545539868\n",
      "train loss:0.8786055318269504\n",
      "train loss:1.0015758617864647\n",
      "train loss:0.8621154725551945\n",
      "train loss:0.856114244788243\n",
      "train loss:0.8327893915895995\n",
      "train loss:0.9361810858264383\n",
      "train loss:0.8068415578314071\n",
      "train loss:0.8135716384628208\n",
      "train loss:0.954778351626375\n",
      "train loss:0.8899276678105177\n",
      "train loss:0.9142047963503959\n",
      "train loss:0.8287135168196704\n",
      "train loss:1.0397977512041\n",
      "train loss:0.9654654911481084\n",
      "train loss:1.0936251344147734\n",
      "train loss:0.7670143583489601\n",
      "train loss:0.7864544207979638\n",
      "train loss:0.9317143143466418\n",
      "train loss:1.022657402729441\n",
      "train loss:0.8140120341594853\n",
      "train loss:0.8694389270995962\n",
      "train loss:0.767377804248181\n",
      "train loss:0.7570329576091425\n",
      "train loss:1.0229094480165652\n",
      "train loss:0.8821491200946128\n",
      "train loss:0.9406918207909217\n",
      "train loss:0.8878798926448844\n",
      "train loss:0.8615642939284467\n",
      "train loss:1.028392858019669\n",
      "train loss:0.8155476517632263\n",
      "train loss:0.8179252040721423\n",
      "train loss:0.9913762077242317\n",
      "train loss:0.7935040761632951\n",
      "train loss:0.7933452075980686\n",
      "train loss:1.000581627116341\n",
      "train loss:1.0187327257929006\n",
      "train loss:0.768774242611986\n",
      "train loss:0.9535376743540748\n",
      "train loss:0.9477554304650221\n",
      "train loss:0.8872430426575515\n",
      "train loss:0.7271460958330753\n",
      "train loss:0.9710589731828669\n",
      "train loss:0.863394267071512\n",
      "train loss:0.8624436957932095\n",
      "train loss:1.0371110475403202\n",
      "train loss:0.8424162652275937\n",
      "train loss:0.8623739628390042\n",
      "train loss:0.8373028908965757\n",
      "train loss:0.8389347207327684\n",
      "train loss:1.0264986900541326\n",
      "train loss:0.9339731833698692\n",
      "train loss:0.9522876536128306\n",
      "train loss:1.036661575449522\n",
      "train loss:0.9337958011079971\n",
      "train loss:0.9540915440107912\n",
      "train loss:0.7907154905517964\n",
      "train loss:0.953565352761998\n",
      "train loss:0.8384477730329105\n",
      "train loss:0.7602877220898955\n",
      "train loss:0.8367425160151899\n",
      "train loss:0.9175736716757644\n",
      "train loss:0.737376468894528\n",
      "train loss:0.8764445336209172\n",
      "train loss:0.882023171002682\n",
      "train loss:0.9456461508676399\n",
      "train loss:0.9396767182958291\n",
      "train loss:0.8026293780687994\n",
      "train loss:1.0020505508592559\n",
      "train loss:0.9516758002478027\n",
      "train loss:0.8118341572101104\n",
      "train loss:1.0567909691463258\n",
      "train loss:0.9215653219652086\n",
      "train loss:0.7842255767707753\n",
      "train loss:0.8271093163370637\n",
      "train loss:0.8699246765915948\n",
      "train loss:0.9081593885600502\n",
      "train loss:0.9882778880579933\n",
      "train loss:0.9225427344376083\n",
      "train loss:0.9370866041737087\n",
      "train loss:0.848782552891624\n",
      "train loss:0.7554516363400264\n",
      "train loss:0.8229780530749258\n",
      "train loss:0.8401105553877305\n",
      "train loss:0.9822649124655466\n",
      "train loss:1.0827796923284874\n",
      "train loss:0.9209835794757152\n",
      "train loss:0.8099967430710797\n",
      "train loss:0.9521733208164547\n",
      "train loss:0.8016078923487145\n",
      "train loss:0.9341524218708614\n",
      "train loss:0.9029550287829157\n",
      "train loss:0.9224816424789833\n",
      "train loss:1.0804421142357732\n",
      "train loss:0.7658345452085858\n",
      "train loss:0.8838778401976926\n",
      "train loss:0.9563391063368185\n",
      "train loss:0.871059486342595\n",
      "train loss:0.9431964342419963\n",
      "train loss:0.9675646401637628\n",
      "train loss:0.8425347716694784\n",
      "train loss:0.785080969753999\n",
      "train loss:0.8336512948956633\n",
      "train loss:0.8028200045092296\n",
      "train loss:0.7756848583980778\n",
      "train loss:0.8755748773880632\n",
      "train loss:0.9801286427101447\n",
      "train loss:0.8535205719536921\n",
      "train loss:1.0733270895343048\n",
      "train loss:0.8160027643986676\n",
      "train loss:0.8839196513786611\n",
      "train loss:0.9317969436107392\n",
      "train loss:0.9438849080376039\n",
      "train loss:0.8283120428624968\n",
      "train loss:1.0285082652934225\n",
      "train loss:0.9096911345721871\n",
      "train loss:0.9097973271551213\n",
      "train loss:1.018734282963385\n",
      "train loss:0.9887948616494066\n",
      "train loss:1.0971754521227117\n",
      "train loss:0.9463698247700291\n",
      "train loss:0.7331120716688264\n",
      "train loss:0.8149153701146649\n",
      "train loss:0.9235288881186975\n",
      "train loss:0.8569977281019355\n",
      "train loss:1.109054112426626\n",
      "train loss:0.8363436789590323\n",
      "train loss:0.8480795912385055\n",
      "train loss:0.954976092683001\n",
      "train loss:0.7632118635324332\n",
      "train loss:0.8930508475762263\n",
      "train loss:0.8628808505470136\n",
      "train loss:0.9726973340037776\n",
      "train loss:0.9175277492072819\n",
      "train loss:0.8683891831250328\n",
      "train loss:0.8194266337924802\n",
      "train loss:0.804071346962279\n",
      "train loss:0.9303944226029265\n",
      "train loss:0.9336040674871785\n",
      "train loss:0.8858730771505781\n",
      "train loss:0.7714973158711578\n",
      "train loss:1.0103266755880478\n",
      "train loss:0.9550427877778703\n",
      "train loss:1.1290842851344285\n",
      "train loss:0.9090545191789938\n",
      "train loss:1.017896742570673\n",
      "train loss:0.8850122000848316\n",
      "train loss:0.8631998733742304\n",
      "train loss:0.9317210671816611\n",
      "train loss:0.7827514206658046\n",
      "train loss:0.812124451938707\n",
      "train loss:0.9114485803871178\n",
      "train loss:0.9135198392568864\n",
      "train loss:1.0242186100383517\n",
      "train loss:0.8452551244994947\n",
      "train loss:0.9800015975131439\n",
      "train loss:1.0227974984929347\n",
      "train loss:0.9838823910451855\n",
      "train loss:0.825112750517773\n",
      "train loss:0.7492557745944387\n",
      "train loss:0.7422176675890992\n",
      "train loss:0.8788422383976789\n",
      "train loss:1.0539546554113663\n",
      "train loss:0.8906662835966186\n",
      "train loss:0.889579435936776\n",
      "train loss:0.8407700991790822\n",
      "train loss:0.9224154047657993\n",
      "train loss:1.0841759919297447\n",
      "train loss:0.8305087711314343\n",
      "train loss:0.8426001678849835\n",
      "train loss:0.9229640677009047\n",
      "train loss:0.7542292641260451\n",
      "train loss:0.8719217324335264\n",
      "train loss:0.9597186669250094\n",
      "train loss:1.0762730101845484\n",
      "train loss:0.8183165121251118\n",
      "train loss:0.7787887774059665\n",
      "train loss:0.9251055130569859\n",
      "train loss:0.7632536338275855\n",
      "train loss:0.8745402583161994\n",
      "train loss:0.911238154887197\n",
      "train loss:0.9438308516624463\n",
      "train loss:1.0002418537824822\n",
      "train loss:0.8298232793981245\n",
      "train loss:0.8885006412032501\n",
      "train loss:0.9184668957643102\n",
      "train loss:0.9398681833322817\n",
      "train loss:0.9334009710945125\n",
      "train loss:0.8687519544518634\n",
      "train loss:0.8885799831821007\n",
      "train loss:1.0365969049211838\n",
      "train loss:1.1349338276043488\n",
      "train loss:0.8927250661538189\n",
      "train loss:0.9334805061429617\n",
      "train loss:0.7649855584510092\n",
      "train loss:0.9022269857068221\n",
      "train loss:1.044393987236011\n",
      "train loss:0.6880618019972572\n",
      "train loss:0.8156196259855772\n",
      "train loss:0.9764768079729358\n",
      "train loss:0.8891888336317254\n",
      "train loss:0.9516484907462426\n",
      "train loss:0.9564499746768965\n",
      "train loss:0.849940280536392\n",
      "train loss:0.8383698776690837\n",
      "train loss:0.8175719237086966\n",
      "train loss:0.87774507226877\n",
      "train loss:0.899259478487728\n",
      "train loss:1.0130520892935575\n",
      "train loss:0.8820346529479258\n",
      "train loss:0.8209310779428841\n",
      "train loss:0.9937063847782484\n",
      "train loss:0.757709600224973\n",
      "train loss:0.9263147211425269\n",
      "train loss:0.9455642878116141\n",
      "train loss:0.9142099424999971\n",
      "train loss:0.8470490305836412\n",
      "train loss:0.8297575137296702\n",
      "train loss:0.8388857968803631\n",
      "train loss:0.784408556867788\n",
      "train loss:0.8151905822440189\n",
      "train loss:0.7983341262251374\n",
      "train loss:0.861902883480286\n",
      "train loss:1.0438191921109963\n",
      "train loss:0.802506571125732\n",
      "train loss:0.9706007579920238\n",
      "train loss:0.9686740961203963\n",
      "train loss:0.9198237174200457\n",
      "train loss:0.8070308491118701\n",
      "train loss:0.9782402630869307\n",
      "train loss:0.8721812957715137\n",
      "train loss:0.9615578534462926\n",
      "train loss:0.8837587454629379\n",
      "train loss:0.7977048611266934\n",
      "train loss:0.9277111160400127\n",
      "train loss:0.8636951538819515\n",
      "train loss:0.81891674625457\n",
      "train loss:1.0614645780696814\n",
      "train loss:0.9070940249931632\n",
      "train loss:0.7578380225081517\n",
      "train loss:0.7537359882321182\n",
      "train loss:0.858004110689642\n",
      "train loss:0.7271936212318308\n",
      "train loss:0.9219353462043542\n",
      "train loss:0.9234314199609946\n",
      "train loss:0.9276216977720744\n",
      "train loss:0.900553416047391\n",
      "train loss:0.8764774874959343\n",
      "train loss:0.8147776510192847\n",
      "train loss:1.057057530246742\n",
      "train loss:0.9676791445567328\n",
      "train loss:0.8004362333583547\n",
      "train loss:0.8783198809618413\n",
      "train loss:0.7739487223209187\n",
      "train loss:1.0400254432166738\n",
      "train loss:0.7883594319234354\n",
      "train loss:0.8322156411271908\n",
      "train loss:0.7754288320280347\n",
      "train loss:0.9120854559302056\n",
      "train loss:0.9926611699362148\n",
      "train loss:0.9633811634314506\n",
      "train loss:0.9283497644562386\n",
      "train loss:0.7789719492675805\n",
      "train loss:0.8952870145891785\n",
      "train loss:0.9898673963642881\n",
      "train loss:0.9911909918548301\n",
      "train loss:0.9250349078960839\n",
      "train loss:0.9217712891889692\n",
      "train loss:0.9462978323890846\n",
      "train loss:0.8372248971630211\n",
      "train loss:0.8055432884593998\n",
      "train loss:0.9892651564775075\n",
      "train loss:0.8254767153772097\n",
      "train loss:0.8927770872972053\n",
      "train loss:0.8902853525449471\n",
      "train loss:0.9330052189844489\n",
      "train loss:0.9104449052427301\n",
      "train loss:0.9086117454878807\n",
      "train loss:0.9608104550898999\n",
      "train loss:0.8183818216451054\n",
      "train loss:1.0132671726918356\n",
      "train loss:0.8504190540035091\n",
      "train loss:0.9538572422950256\n",
      "train loss:0.8609431165639563\n",
      "train loss:0.8866330635348532\n",
      "train loss:0.9079783099494192\n",
      "train loss:0.9488119030511484\n",
      "train loss:0.7872140824849833\n",
      "train loss:0.9915421857318196\n",
      "train loss:0.9110598378865867\n",
      "train loss:0.8315155146630991\n",
      "train loss:0.8154171977485889\n",
      "train loss:0.7865930469461516\n",
      "train loss:0.9227435652859214\n",
      "train loss:0.851909492643791\n",
      "train loss:1.0171761137033748\n",
      "train loss:0.7653170318841851\n",
      "train loss:0.8705670109929357\n",
      "train loss:0.797060931479206\n",
      "train loss:0.8139845135615756\n",
      "train loss:0.8270571919080483\n",
      "train loss:1.0652951451663595\n",
      "train loss:0.7996467902342246\n",
      "train loss:0.9235342371074237\n",
      "train loss:0.7771450497395328\n",
      "train loss:1.1016306234308515\n",
      "train loss:0.7481165945877944\n",
      "train loss:0.7082321638520073\n",
      "train loss:0.873892818340343\n",
      "train loss:0.7902435131384661\n",
      "train loss:0.9527731474465289\n",
      "train loss:0.8229335850583526\n",
      "train loss:0.8965679070362323\n",
      "train loss:1.0132055040000196\n",
      "train loss:0.9535880929225491\n",
      "train loss:0.6559416812732191\n",
      "train loss:0.7422412164882981\n",
      "train loss:0.9257031872907129\n",
      "train loss:0.7481692259442343\n",
      "train loss:0.897847632836013\n",
      "train loss:0.8910657309220602\n",
      "train loss:0.8955478066776011\n",
      "train loss:0.9633557184501383\n",
      "train loss:1.036444718465328\n",
      "train loss:0.8723969623515654\n",
      "train loss:0.9045679468268097\n",
      "train loss:0.8810675451721326\n",
      "train loss:0.9780051310171668\n",
      "train loss:0.8124170289417225\n",
      "train loss:0.7134650379309098\n",
      "train loss:0.7691672775178187\n",
      "train loss:0.8694763019654439\n",
      "train loss:0.8734383502745463\n",
      "train loss:1.076298739217606\n",
      "train loss:0.950680628453612\n",
      "train loss:0.9734641414239158\n",
      "train loss:0.9561808930391282\n",
      "train loss:1.021796341059381\n",
      "train loss:0.8607341115688483\n",
      "train loss:0.9571610808722377\n",
      "train loss:0.9515541256257279\n",
      "train loss:0.8405929253721426\n",
      "train loss:0.8820423624639935\n",
      "train loss:0.6477005209080599\n",
      "train loss:0.9828011351309849\n",
      "train loss:0.9432298024411108\n",
      "train loss:0.7520299599147102\n",
      "train loss:1.0174617440211655\n",
      "train loss:0.9111278384940671\n",
      "train loss:0.8710180601303604\n",
      "train loss:0.9221741189702738\n",
      "train loss:0.9985630943549089\n",
      "train loss:0.9563025463484378\n",
      "train loss:0.7808308887266161\n",
      "train loss:0.8594106156213711\n",
      "train loss:0.8337316127239329\n",
      "train loss:0.7928886808897643\n",
      "train loss:0.7693740752613704\n",
      "train loss:0.9483212207400814\n",
      "train loss:0.8806109469692938\n",
      "train loss:0.7977597009436032\n",
      "train loss:0.8900050707920171\n",
      "train loss:0.9246353765270525\n",
      "train loss:1.064463371691302\n",
      "train loss:0.9408497452887314\n",
      "train loss:0.7411855272698906\n",
      "train loss:0.8519435077974242\n",
      "train loss:0.8449693124903402\n",
      "train loss:0.9355262697888799\n",
      "train loss:0.6629023000836011\n",
      "train loss:0.9877112632305546\n",
      "train loss:0.9322993228514117\n",
      "train loss:0.8555530829794047\n",
      "train loss:1.020540122407601\n",
      "train loss:0.8997756346591547\n",
      "train loss:0.8757663510373235\n",
      "train loss:0.8072038605311467\n",
      "train loss:1.060050593094937\n",
      "train loss:0.8163986222657376\n",
      "train loss:0.8191298660742693\n",
      "train loss:0.8105351890102155\n",
      "train loss:0.8486623342167072\n",
      "train loss:0.8860466526626781\n",
      "train loss:0.8372636978861094\n",
      "train loss:1.037248511470108\n",
      "train loss:0.9009070505386124\n",
      "train loss:0.8364296857417997\n",
      "train loss:0.8638164134248899\n",
      "train loss:0.8746226614210585\n",
      "train loss:0.9511069411287452\n",
      "train loss:0.7400933308742933\n",
      "train loss:0.9309994216653176\n",
      "train loss:1.041774062276492\n",
      "train loss:1.1804597242010193\n",
      "train loss:0.7614113597115874\n",
      "train loss:0.8575378759647072\n",
      "train loss:0.9573142690071752\n",
      "train loss:0.9021805206511075\n",
      "train loss:1.0743609957162503\n",
      "train loss:0.7131849056308641\n",
      "train loss:1.1127318338373924\n",
      "train loss:0.9218824992634852\n",
      "train loss:0.8509945379135826\n",
      "train loss:0.9288774283354218\n",
      "train loss:1.110834826465466\n",
      "train loss:0.940990557990038\n",
      "train loss:1.0655286325857303\n",
      "train loss:1.00478911751009\n",
      "train loss:0.8626813460699626\n",
      "train loss:0.920700620098294\n",
      "train loss:0.8353477081993554\n",
      "train loss:0.8087705576127142\n",
      "train loss:0.8638310384815088\n",
      "train loss:0.599749320432397\n",
      "train loss:0.9060492118466857\n",
      "train loss:0.8641115109292774\n",
      "train loss:0.8871093430356961\n",
      "train loss:0.8310702318324723\n",
      "train loss:0.9307775940916373\n",
      "train loss:0.9146655738193482\n",
      "train loss:0.8620907815755866\n",
      "train loss:1.0395328437545341\n",
      "train loss:0.9422236487126899\n",
      "train loss:0.7904069058164382\n",
      "train loss:0.859484833551866\n",
      "train loss:0.9348175005304982\n",
      "train loss:0.8553857295525644\n",
      "train loss:0.8182574099719772\n",
      "train loss:0.9513885599172295\n",
      "train loss:0.8582050474963496\n",
      "train loss:1.0200430034227566\n",
      "train loss:0.9830757481988016\n",
      "train loss:0.9375890892965475\n",
      "train loss:0.8881015507554292\n",
      "train loss:0.8114875153132824\n",
      "train loss:0.8447316113341289\n",
      "train loss:0.9686363419294881\n",
      "train loss:0.9834422022793616\n",
      "train loss:0.7896446086795474\n",
      "train loss:0.8243098024139057\n",
      "train loss:0.7548268169081837\n",
      "train loss:0.9217495711048729\n",
      "train loss:0.9031132943970713\n",
      "train loss:0.9849936397664538\n",
      "train loss:0.8511541650430697\n",
      "train loss:0.7789374450950356\n",
      "train loss:0.8214982034977661\n",
      "train loss:0.82708429866422\n",
      "train loss:1.0849821968261368\n",
      "train loss:0.7885569582550754\n",
      "train loss:1.0763379447744605\n",
      "train loss:0.926487517869663\n",
      "train loss:0.9523575105395884\n",
      "train loss:0.8202375211506773\n",
      "train loss:0.832468707318198\n",
      "train loss:0.8362911855814497\n",
      "train loss:0.9023396000870743\n",
      "train loss:0.9900051999171815\n",
      "train loss:0.921467417807318\n",
      "train loss:1.13761934327848\n",
      "train loss:0.9014653841129536\n",
      "train loss:0.8489302430937801\n",
      "train loss:0.9621788122465443\n",
      "train loss:0.8617246639945413\n",
      "train loss:0.8295095832545836\n",
      "train loss:0.8337254993336838\n",
      "train loss:1.0007176910067612\n",
      "train loss:0.7405951567075714\n",
      "train loss:0.8786713705356785\n",
      "train loss:1.0169175404722994\n",
      "train loss:0.9413682310565761\n",
      "train loss:0.8598996823632258\n",
      "train loss:0.9129692299170595\n",
      "train loss:0.8253873407515044\n",
      "train loss:0.7511703968306978\n",
      "train loss:0.8472390038464994\n",
      "train loss:0.9599326608212649\n",
      "train loss:0.8970330796461239\n",
      "train loss:0.8705547127667758\n",
      "train loss:0.9010388066810846\n",
      "train loss:0.99030136580426\n",
      "train loss:0.9307695914317234\n",
      "train loss:0.8209359130528526\n",
      "train loss:0.8898859012446616\n",
      "train loss:0.7926579174424312\n",
      "train loss:0.8168879055719829\n",
      "train loss:0.7243436908056234\n",
      "train loss:0.8833482530339707\n",
      "train loss:1.043011388603776\n",
      "train loss:0.9705739899061797\n",
      "train loss:0.8238375904564296\n",
      "train loss:0.977688999521728\n",
      "train loss:0.9246814667867436\n",
      "train loss:0.8424492601916289\n",
      "train loss:0.9168759396616779\n",
      "train loss:0.8583770983658395\n",
      "train loss:1.0139988972766323\n",
      "train loss:1.0554496215219114\n",
      "train loss:0.6534505679652064\n",
      "train loss:0.9448023396603976\n",
      "train loss:0.6765576071306892\n",
      "train loss:0.8425089805812513\n",
      "train loss:0.9148740354659267\n",
      "train loss:0.9108227371784055\n",
      "train loss:0.8691177533701746\n",
      "train loss:0.8897824337495543\n",
      "train loss:0.916587113486098\n",
      "train loss:0.9861503623298075\n",
      "train loss:0.8400503654345981\n",
      "train loss:0.8317368693349132\n",
      "train loss:0.8276831317839733\n",
      "train loss:1.0093699879619562\n",
      "train loss:0.7848627074703951\n",
      "train loss:0.9794313891167696\n",
      "train loss:1.0535675123722832\n",
      "train loss:0.9200711088758247\n",
      "train loss:0.8068427904429162\n",
      "train loss:1.0765280747358141\n",
      "train loss:0.8922078777323257\n",
      "train loss:1.0111554589213416\n",
      "train loss:0.8994659517552441\n",
      "train loss:1.0113602163396327\n",
      "train loss:0.8924592236647765\n",
      "train loss:0.8590818750740337\n",
      "train loss:0.6687820552613364\n",
      "train loss:0.7759422386772473\n",
      "train loss:0.9621389105840014\n",
      "train loss:0.7851499469993938\n",
      "train loss:0.7234137959433444\n",
      "train loss:0.8449923140578522\n",
      "train loss:0.9653721059912458\n",
      "train loss:0.95207946850284\n",
      "train loss:0.7787580027167338\n",
      "train loss:0.9082201254861232\n",
      "train loss:0.9757667865294004\n",
      "train loss:0.98646944321258\n",
      "train loss:0.8578326417253792\n",
      "train loss:0.8905869645722675\n",
      "train loss:0.8196314659807716\n",
      "train loss:0.9515501762022572\n",
      "train loss:0.9626042776902564\n",
      "train loss:0.7803830285376303\n",
      "train loss:0.6907508996151435\n",
      "train loss:1.012277487725341\n",
      "train loss:0.8750306302136701\n",
      "train loss:1.0649814090937613\n",
      "train loss:0.6192360793177211\n",
      "train loss:1.0056467921308552\n",
      "train loss:1.0435489727852196\n",
      "train loss:0.8981907911596521\n",
      "train loss:0.9362669521669247\n",
      "train loss:0.720242498638107\n",
      "train loss:0.9138854000423119\n",
      "train loss:0.8786384992230731\n",
      "train loss:0.8517404040032115\n",
      "train loss:0.8489496023226099\n",
      "train loss:1.184153634485452\n",
      "train loss:0.8919015022529938\n",
      "train loss:0.7585060541033005\n",
      "train loss:0.9382411034005839\n",
      "train loss:1.0078335750053626\n",
      "train loss:0.8554493729565198\n",
      "train loss:1.1028338049558801\n",
      "train loss:0.889252874914825\n",
      "train loss:0.9685320245538963\n",
      "train loss:0.7888504583497788\n",
      "train loss:0.8529545432666804\n",
      "train loss:0.9474639178980864\n",
      "train loss:0.9815989172203048\n",
      "train loss:0.7759914516981256\n",
      "train loss:0.9308627402854899\n",
      "train loss:0.9992979769440804\n",
      "train loss:0.8456796287777748\n",
      "train loss:0.8616124531015288\n",
      "train loss:0.9062764739453236\n",
      "train loss:0.8838805053186953\n",
      "=== epoch:11, train acc:0.994, test acc:0.991 ===\n",
      "train loss:0.9401337079996966\n",
      "train loss:0.812570256464413\n",
      "train loss:0.8440516221980522\n",
      "train loss:0.9606688685561136\n",
      "train loss:0.8918799690812513\n",
      "train loss:0.7496482772490584\n",
      "train loss:0.864675810506048\n",
      "train loss:0.9171267307594226\n",
      "train loss:0.9093551527401132\n",
      "train loss:0.9601126213806943\n",
      "train loss:0.9215033595850673\n",
      "train loss:1.0670588227065283\n",
      "train loss:0.810537803633566\n",
      "train loss:0.8352402897371286\n",
      "train loss:0.9271566273908928\n",
      "train loss:0.9396181603240593\n",
      "train loss:0.7728760313519561\n",
      "train loss:0.900328126532838\n",
      "train loss:0.9561865246194552\n",
      "train loss:0.9943953003318065\n",
      "train loss:0.8293749904909024\n",
      "train loss:0.8909102984329739\n",
      "train loss:0.8744215657774325\n",
      "train loss:0.9055074282616882\n",
      "train loss:0.8916785031369017\n",
      "train loss:0.8154689091006974\n",
      "train loss:0.8953176160847398\n",
      "train loss:0.9860124524059786\n",
      "train loss:0.9633675376036347\n",
      "train loss:0.864734869984156\n",
      "train loss:0.8951952467320752\n",
      "train loss:0.7082283560227524\n",
      "train loss:1.1423060175578414\n",
      "train loss:0.8292890226834211\n",
      "train loss:0.9125323404349527\n",
      "train loss:0.8675824225835105\n",
      "train loss:0.8459102630988702\n",
      "train loss:0.8523861633902234\n",
      "train loss:0.7290155877669702\n",
      "train loss:0.6688664292073309\n",
      "train loss:0.8165482806270217\n",
      "train loss:0.7479352840248156\n",
      "train loss:0.723227551466831\n",
      "train loss:0.952687961803685\n",
      "train loss:0.752051705028143\n",
      "train loss:0.846188155305849\n",
      "train loss:0.8063154091197765\n",
      "train loss:0.983641496658991\n",
      "train loss:0.7961259909962246\n",
      "train loss:0.9258035741422204\n",
      "train loss:0.7672746118543587\n",
      "train loss:0.8873567586818636\n",
      "train loss:1.0553227511997223\n",
      "train loss:0.836839836580123\n",
      "train loss:0.8221150263963893\n",
      "train loss:1.0003370281701578\n",
      "train loss:0.8277609174839156\n",
      "train loss:0.9005145673315353\n",
      "train loss:0.9423729063023473\n",
      "train loss:0.928534277371948\n",
      "train loss:0.9216038809958215\n",
      "train loss:0.8396060722770329\n",
      "train loss:0.9803092833015108\n",
      "train loss:0.8093089594840056\n",
      "train loss:0.9222580494481053\n",
      "train loss:1.1840103145102985\n",
      "train loss:0.8169901126281971\n",
      "train loss:0.8419767284611883\n",
      "train loss:0.8592681564962602\n",
      "train loss:0.976702196114398\n",
      "train loss:0.9016066797054471\n",
      "train loss:0.806035517045185\n",
      "train loss:0.9046286750410715\n",
      "train loss:0.9563654335366807\n",
      "train loss:0.9676419295467237\n",
      "train loss:0.8610082161001469\n",
      "train loss:0.9312380427328293\n",
      "train loss:0.8882551786327454\n",
      "train loss:0.8338005882723849\n",
      "train loss:0.8260930465317559\n",
      "train loss:0.8483233988771909\n",
      "train loss:0.8276296576959004\n",
      "train loss:0.8832297413626189\n",
      "train loss:1.0005183970394582\n",
      "train loss:0.8028598970032202\n",
      "train loss:0.8926067316956465\n",
      "train loss:0.8387494409333692\n",
      "train loss:0.9473787989121427\n",
      "train loss:0.8551725295806111\n",
      "train loss:0.8116634700816515\n",
      "train loss:0.9265082123209913\n",
      "train loss:0.7713134649095771\n",
      "train loss:0.8057419272945033\n",
      "train loss:0.9840126897926065\n",
      "train loss:0.9794260937225344\n",
      "train loss:0.8539581769857595\n",
      "train loss:0.7692044833930151\n",
      "train loss:0.9713613347741885\n",
      "train loss:0.7373093973154031\n",
      "train loss:0.9245321141750545\n",
      "train loss:0.8273761725325164\n",
      "train loss:0.9835834521933942\n",
      "train loss:0.9814911009375408\n",
      "train loss:0.9036353936191722\n",
      "train loss:0.8370062105842806\n",
      "train loss:0.8016892444212192\n",
      "train loss:0.8854426299885775\n",
      "train loss:0.880046744944178\n",
      "train loss:1.0104353814229687\n",
      "train loss:0.8120208808369711\n",
      "train loss:0.8230244464982184\n",
      "train loss:0.8788966577357844\n",
      "train loss:0.9074561886688696\n",
      "train loss:0.8525484210402027\n",
      "train loss:0.9679822391670518\n",
      "train loss:1.0097246528430153\n",
      "train loss:0.9013120230542924\n",
      "train loss:0.8854987216225346\n",
      "train loss:0.8934339964090282\n",
      "train loss:0.9295536736388454\n",
      "train loss:0.7162712882532075\n",
      "train loss:0.8375778074156845\n",
      "train loss:0.9773105302668701\n",
      "train loss:1.0903320471328306\n",
      "train loss:0.8615219397575663\n",
      "train loss:0.8286797451797842\n",
      "train loss:0.8483618087783951\n",
      "train loss:0.9631156008891998\n",
      "train loss:0.7366663135355066\n",
      "train loss:0.9181112654830831\n",
      "train loss:1.0865586253805715\n",
      "train loss:0.8396287652637204\n",
      "train loss:0.8941735660514238\n",
      "train loss:0.8608285301126749\n",
      "train loss:0.9774668488600503\n",
      "train loss:1.0470072370231143\n",
      "train loss:0.9910869467953289\n",
      "train loss:0.8802308047475642\n",
      "train loss:0.9245722842834598\n",
      "train loss:1.0114324116186757\n",
      "train loss:0.8983029420853544\n",
      "train loss:1.0148444976698465\n",
      "train loss:0.8416326660712191\n",
      "train loss:0.8858344424908128\n",
      "train loss:0.9171131653964071\n",
      "train loss:0.8746287175086206\n",
      "train loss:0.9703207582875898\n",
      "train loss:0.8708104967989204\n",
      "train loss:0.8944189611727316\n",
      "train loss:0.9050735235776564\n",
      "train loss:1.0381374248110848\n",
      "train loss:0.7910360858745722\n",
      "train loss:0.7374412376039716\n",
      "train loss:0.8769770251981427\n",
      "train loss:0.8037994371447823\n",
      "train loss:1.029752930412566\n",
      "train loss:0.8243755773511533\n",
      "train loss:1.053736109724429\n",
      "train loss:0.8387772995397422\n",
      "train loss:0.796251257944996\n",
      "train loss:0.7546791412879986\n",
      "train loss:0.8683380023076479\n",
      "train loss:0.9248807556475498\n",
      "train loss:1.0855290216592386\n",
      "train loss:0.814563339427676\n",
      "train loss:0.8477479089507347\n",
      "train loss:0.8358113644899425\n",
      "train loss:0.97465020147006\n",
      "train loss:1.0440154768804037\n",
      "train loss:0.9366007433997029\n",
      "train loss:0.9904122744247809\n",
      "train loss:0.8700048127663584\n",
      "train loss:0.9170644099516356\n",
      "train loss:0.7408113671766623\n",
      "train loss:0.8832272482393155\n",
      "train loss:0.8589669989731257\n",
      "train loss:0.970487546449739\n",
      "train loss:0.8615027287017307\n",
      "train loss:0.7752602041038179\n",
      "train loss:1.050369520138989\n",
      "train loss:0.9229434526753829\n",
      "train loss:0.8238531685118473\n",
      "train loss:0.8198881687508118\n",
      "train loss:0.8684446478139002\n",
      "train loss:0.9062741421384366\n",
      "train loss:0.8582731135076509\n",
      "train loss:0.9404850170425489\n",
      "train loss:0.9997432994275723\n",
      "train loss:0.7872547573805173\n",
      "train loss:0.8474016816967763\n",
      "train loss:0.7967152517051609\n",
      "train loss:0.8828188039902508\n",
      "train loss:0.8559309477087815\n",
      "train loss:1.0360248424260876\n",
      "train loss:0.9543409863858184\n",
      "train loss:0.8884012815217995\n",
      "train loss:0.889921572089612\n",
      "train loss:0.8695438810423057\n",
      "train loss:1.0003048192554926\n",
      "train loss:0.9647858537560758\n",
      "train loss:0.8689856310303473\n",
      "train loss:0.8017975414964583\n",
      "train loss:0.8333422028029872\n",
      "train loss:0.8851562903521732\n",
      "train loss:0.7941900647949935\n",
      "train loss:0.8787427194782071\n",
      "train loss:0.8886645129996491\n",
      "train loss:0.9676906331240178\n",
      "train loss:0.9974511043588682\n",
      "train loss:0.9472896155590885\n",
      "train loss:1.040019337603556\n",
      "train loss:1.0062580660694145\n",
      "train loss:0.7733755965426203\n",
      "train loss:0.7768858195140581\n",
      "train loss:0.9895354147421468\n",
      "train loss:0.9019249680583801\n",
      "train loss:0.7647060604950134\n",
      "train loss:1.050765473855405\n",
      "train loss:0.9351453891369174\n",
      "train loss:0.9331935294862604\n",
      "train loss:1.0019655792698012\n",
      "train loss:0.8757923700866905\n",
      "train loss:0.9410937908698844\n",
      "train loss:0.8341251174906994\n",
      "train loss:0.9645568972034623\n",
      "train loss:0.7391831984891118\n",
      "train loss:0.9785245118631299\n",
      "train loss:1.0029132813668769\n",
      "train loss:0.823856820606427\n",
      "train loss:0.8446490067909109\n",
      "train loss:0.9898042226312623\n",
      "train loss:0.879159176958236\n",
      "train loss:0.9682798120649271\n",
      "train loss:0.890273248858683\n",
      "train loss:0.8668558434436499\n",
      "train loss:0.8562747207541703\n",
      "train loss:0.8853374943221333\n",
      "train loss:0.8975344301555279\n",
      "train loss:0.8610293060032166\n",
      "train loss:0.813702591055985\n",
      "train loss:0.753973906006039\n",
      "train loss:0.5664518381144257\n",
      "train loss:0.853382017682949\n",
      "train loss:0.9561861124044967\n",
      "train loss:0.8306284873298706\n",
      "train loss:0.8689733547393702\n",
      "train loss:0.9561413308398731\n",
      "train loss:0.8590687090139184\n",
      "train loss:0.8003497059343708\n",
      "train loss:0.9426540898926125\n",
      "train loss:0.7759491816415802\n",
      "train loss:0.8902709408544491\n",
      "train loss:0.8880901993686158\n",
      "train loss:1.0046077238414421\n",
      "train loss:0.8857258093400788\n",
      "train loss:0.914082342135537\n",
      "train loss:0.7881064733043196\n",
      "train loss:0.8448963944890392\n",
      "train loss:0.9070248215325384\n",
      "train loss:0.8959073758261366\n",
      "train loss:0.8593282485667438\n",
      "train loss:1.0468585245704076\n",
      "train loss:1.0000748357754945\n",
      "train loss:0.7572076731093338\n",
      "train loss:0.8410028586310717\n",
      "train loss:0.9149376053832202\n",
      "train loss:1.1143967797610697\n",
      "train loss:0.9372684685003476\n",
      "train loss:0.7742049305953731\n",
      "train loss:0.8784323229660598\n",
      "train loss:0.938786371429536\n",
      "train loss:0.7794358083427615\n",
      "train loss:0.9038021036215999\n",
      "train loss:1.1005740356551192\n",
      "train loss:0.8581057399303609\n",
      "train loss:0.928354390784481\n",
      "train loss:0.7750118076644842\n",
      "train loss:0.9820541338754447\n",
      "train loss:0.8225676001154494\n",
      "train loss:0.9952684086338357\n",
      "train loss:0.7198253303821823\n",
      "train loss:0.8435276649159746\n",
      "train loss:1.0176052245785159\n",
      "train loss:0.844124463910193\n",
      "train loss:0.8686190025909692\n",
      "train loss:0.8404272305283831\n",
      "train loss:0.867608145825872\n",
      "train loss:0.8849439489813209\n",
      "train loss:1.0046033134129808\n",
      "train loss:0.8601494304535915\n",
      "train loss:0.9111206002131076\n",
      "train loss:1.004060425299409\n",
      "train loss:0.9807156620478622\n",
      "train loss:0.7942689963649555\n",
      "train loss:0.9762988138128074\n",
      "train loss:0.9898522528924579\n",
      "train loss:0.9825087108101281\n",
      "train loss:0.9134602634428702\n",
      "train loss:0.8590212797744641\n",
      "train loss:0.8783322165380827\n",
      "train loss:1.0044977139018876\n",
      "train loss:0.9832925683064039\n",
      "train loss:0.9021324545383911\n",
      "train loss:0.9710034289498229\n",
      "train loss:0.8780891987922318\n",
      "train loss:0.8342712678015303\n",
      "train loss:0.7844157044777853\n",
      "train loss:1.0854963628564127\n",
      "train loss:0.8765569741158853\n",
      "train loss:0.6559857188307952\n",
      "train loss:0.8641238045954289\n",
      "train loss:0.9459866901301187\n",
      "train loss:0.9278661922617636\n",
      "train loss:0.8731773646487921\n",
      "train loss:0.9210146974297733\n",
      "train loss:0.7473803531568411\n",
      "train loss:1.0302210793670725\n",
      "train loss:0.7418495749392907\n",
      "train loss:0.8572705371331379\n",
      "train loss:0.8186087800122225\n",
      "train loss:0.9578468188904964\n",
      "train loss:1.0090615836120762\n",
      "train loss:0.8530638328019136\n",
      "train loss:1.0564863647505052\n",
      "train loss:1.1274400646542817\n",
      "train loss:0.9834168554533314\n",
      "train loss:0.8768621467219472\n",
      "train loss:0.9324471778596363\n",
      "train loss:0.9171394385149076\n",
      "train loss:0.7427185611246206\n",
      "train loss:0.9696320592271824\n",
      "train loss:0.9935207302701174\n",
      "train loss:0.9804397295249407\n",
      "train loss:0.976844895906909\n",
      "train loss:0.8891209290596761\n",
      "train loss:0.9295266368421516\n",
      "train loss:0.861221213695038\n",
      "train loss:0.9078001389837038\n",
      "train loss:0.7745402156842728\n",
      "train loss:0.8522055837976035\n",
      "train loss:1.0739037322899252\n",
      "train loss:0.7269514921998667\n",
      "train loss:0.8343679319796966\n",
      "train loss:0.918401212476398\n",
      "train loss:0.90647723089339\n",
      "train loss:0.9488230423247798\n",
      "train loss:0.9430673495308878\n",
      "train loss:0.8585593285101218\n",
      "train loss:0.9449365448507199\n",
      "train loss:0.8072831611761305\n",
      "train loss:0.8999949956124551\n",
      "train loss:1.001582403459716\n",
      "train loss:0.9414402446018683\n",
      "train loss:0.766932839204795\n",
      "train loss:0.9469130709105548\n",
      "train loss:0.7622035841572555\n",
      "train loss:0.8261555611394438\n",
      "train loss:0.8490696465301147\n",
      "train loss:0.9313542903491399\n",
      "train loss:0.9014965218501513\n",
      "train loss:0.8131175360761332\n",
      "train loss:1.1880093628850512\n",
      "train loss:0.7542724623108849\n",
      "train loss:0.7785029834092427\n",
      "train loss:0.8790406675877872\n",
      "train loss:0.9123671042111252\n",
      "train loss:0.8767906665410509\n",
      "train loss:0.8751352767115503\n",
      "train loss:0.8918047863992112\n",
      "train loss:1.0724798453677549\n",
      "train loss:0.7852448866657364\n",
      "train loss:0.8175702159011222\n",
      "train loss:1.0240514204888314\n",
      "train loss:0.9677647775594435\n",
      "train loss:0.84441956204722\n",
      "train loss:0.7724866192992339\n",
      "train loss:0.7412858655596111\n",
      "train loss:0.8421399948711829\n",
      "train loss:0.8373187402494819\n",
      "train loss:0.7997726089279825\n",
      "train loss:0.9148982616139618\n",
      "train loss:0.8087622161581516\n",
      "train loss:0.7266642277859384\n",
      "train loss:0.9238258163920162\n",
      "train loss:0.8362681335554366\n",
      "train loss:0.7585222962560255\n",
      "train loss:0.8425425645994093\n",
      "train loss:0.9447478527063123\n",
      "train loss:0.7571797804283676\n",
      "train loss:0.8948040459463581\n",
      "train loss:0.7774467819014913\n",
      "train loss:0.8050389273634272\n",
      "train loss:0.850927906334852\n",
      "train loss:0.8391995343854812\n",
      "train loss:0.8829467884877414\n",
      "train loss:0.9290444438097711\n",
      "train loss:0.776210747613649\n",
      "train loss:0.9355499846330854\n",
      "train loss:0.8185718152693167\n",
      "train loss:1.0440741503308177\n",
      "train loss:0.8733016283853763\n",
      "train loss:0.9630435697780019\n",
      "train loss:0.7948594502958981\n",
      "train loss:0.7779479226514465\n",
      "train loss:0.979846829508232\n",
      "train loss:0.8117712431076916\n",
      "train loss:0.7620066095582569\n",
      "train loss:0.9682545579327062\n",
      "train loss:0.8971689106671952\n",
      "train loss:0.9323637859725885\n",
      "train loss:0.8870509702850264\n",
      "train loss:0.8775259495763534\n",
      "train loss:0.8665062748667448\n",
      "train loss:0.9680185331727114\n",
      "train loss:0.8919689137190225\n",
      "train loss:0.940960561938996\n",
      "train loss:0.8047923012921805\n",
      "train loss:0.8769753083413486\n",
      "train loss:0.9024365605179453\n",
      "train loss:0.7512533316767244\n",
      "train loss:0.8161334481125877\n",
      "train loss:0.8965246706489189\n",
      "train loss:0.8594337456643877\n",
      "train loss:0.8781353991046149\n",
      "train loss:0.8724693027659378\n",
      "train loss:0.6583089835118782\n",
      "train loss:0.7305615611861588\n",
      "train loss:0.7884169794699152\n",
      "train loss:0.9434148155406961\n",
      "train loss:0.8681373881002297\n",
      "train loss:0.8978172355835562\n",
      "train loss:0.8477932109962997\n",
      "train loss:0.906965199184841\n",
      "train loss:0.8703260217367113\n",
      "train loss:0.8966494397984485\n",
      "train loss:0.8783012927634815\n",
      "train loss:0.9192356250860919\n",
      "train loss:0.8909673449352467\n",
      "train loss:0.9202970553591965\n",
      "train loss:0.800204401416007\n",
      "train loss:0.8921450875431637\n",
      "train loss:0.9120943947233967\n",
      "train loss:0.9384626371884082\n",
      "train loss:1.0356551244154197\n",
      "train loss:0.868252379858053\n",
      "train loss:1.0766864547894537\n",
      "train loss:0.8295630199668392\n",
      "train loss:0.7729730631555892\n",
      "train loss:1.037834390782728\n",
      "train loss:0.8755022474466699\n",
      "train loss:0.9308713498911705\n",
      "train loss:0.9207721052640703\n",
      "train loss:0.8302844476639031\n",
      "train loss:0.7398091978150748\n",
      "train loss:0.9413802459053718\n",
      "train loss:0.950762778865504\n",
      "train loss:0.8559123752316\n",
      "train loss:0.8942698397273631\n",
      "train loss:0.9074144698678555\n",
      "train loss:0.9701677336870661\n",
      "train loss:1.0970908765782665\n",
      "train loss:0.8264298056299016\n",
      "train loss:1.13567600947248\n",
      "train loss:0.8725627988171337\n",
      "train loss:1.0594218311752832\n",
      "train loss:0.9249248254576866\n",
      "train loss:0.9444386222722337\n",
      "train loss:0.8821099272750348\n",
      "train loss:0.9463578922088703\n",
      "train loss:1.093191556672312\n",
      "train loss:0.882498213954015\n",
      "train loss:0.8784584649284143\n",
      "train loss:0.8593422006592553\n",
      "train loss:0.9170538842519238\n",
      "train loss:0.8161197670673692\n",
      "train loss:0.8888440252235656\n",
      "train loss:0.7248332259814926\n",
      "train loss:0.8005311647302663\n",
      "train loss:0.9129238452292742\n",
      "train loss:0.9480844364101781\n",
      "train loss:0.8286462802771313\n",
      "train loss:1.0243495800550615\n",
      "train loss:0.8112190989146901\n",
      "train loss:0.9223181783470098\n",
      "train loss:0.8445690386164838\n",
      "train loss:1.0497221435962967\n",
      "train loss:0.8442680510862646\n",
      "train loss:0.8066512005425546\n",
      "train loss:0.8154958584405537\n",
      "train loss:0.6603617933557778\n",
      "train loss:0.9442713127339922\n",
      "train loss:1.0119536411135417\n",
      "train loss:0.8223908743960078\n",
      "train loss:0.9666168482777944\n",
      "train loss:0.9779066705849562\n",
      "train loss:0.810902131011369\n",
      "train loss:0.9970389248290131\n",
      "train loss:0.8351316548958329\n",
      "train loss:0.9003226748841642\n",
      "train loss:0.9906165823145525\n",
      "train loss:0.9213464486776821\n",
      "train loss:0.9523980446672712\n",
      "train loss:0.8502425816649237\n",
      "train loss:0.990970865139489\n",
      "train loss:0.9030223399197306\n",
      "train loss:0.734109433779149\n",
      "train loss:0.7891631194567207\n",
      "train loss:0.8403691147410755\n",
      "train loss:0.931664989324276\n",
      "train loss:0.9293480715983695\n",
      "train loss:0.7702555596369602\n",
      "train loss:0.9334556163413609\n",
      "train loss:1.0056555593262195\n",
      "train loss:0.9353526820870642\n",
      "train loss:0.9423006030054651\n",
      "train loss:0.6935621716270827\n",
      "train loss:0.952867087243543\n",
      "train loss:0.8465956876564179\n",
      "train loss:0.9723003142219839\n",
      "train loss:0.7880316404949476\n",
      "train loss:0.8110902650430489\n",
      "train loss:0.9246397534284501\n",
      "train loss:0.7890373470812858\n",
      "train loss:0.8582795248532811\n",
      "train loss:0.8965767304850074\n",
      "train loss:0.8207030288318409\n",
      "train loss:0.8570543232855737\n",
      "train loss:0.8747189610555466\n",
      "train loss:1.014533029270274\n",
      "train loss:0.8804765743653195\n",
      "train loss:0.9774240929975209\n",
      "train loss:0.9855497716542898\n",
      "train loss:0.8397238227509743\n",
      "train loss:1.0023683515478554\n",
      "train loss:0.8073573027583005\n",
      "train loss:0.8279924355779936\n",
      "train loss:0.7678599519892508\n",
      "train loss:0.9293360481764951\n",
      "train loss:0.8215351721462192\n",
      "train loss:0.8210306882272879\n",
      "train loss:0.8245367483382053\n",
      "train loss:0.8767334259614369\n",
      "train loss:0.7716292956356119\n",
      "train loss:0.9259340946048418\n",
      "train loss:0.987665334817413\n",
      "train loss:0.963001801850723\n",
      "train loss:0.8655255842126279\n",
      "train loss:0.888753297868143\n",
      "train loss:0.7308234096735076\n",
      "train loss:0.8845357086033613\n",
      "train loss:0.8383806071580456\n",
      "train loss:0.8237003728265533\n",
      "train loss:0.9265922164846431\n",
      "train loss:0.7467942057317657\n",
      "train loss:1.094520323220826\n",
      "train loss:1.0439684574284775\n",
      "train loss:0.811552311426258\n",
      "train loss:0.7324839429678819\n",
      "train loss:0.777617315894308\n",
      "train loss:0.8925633340775984\n",
      "train loss:1.0261425907601924\n",
      "train loss:0.9558655901079335\n",
      "train loss:0.807606003443955\n",
      "train loss:0.8946108591927477\n",
      "train loss:0.9089136614771937\n",
      "train loss:0.7338346014506436\n",
      "train loss:1.0307536142689389\n",
      "train loss:0.8805898196591009\n",
      "train loss:0.8498198334011674\n",
      "train loss:0.8893041642401126\n",
      "train loss:0.8849444652885016\n",
      "train loss:0.8348317883624398\n",
      "train loss:0.8417437127336181\n",
      "train loss:0.9502528201657066\n",
      "train loss:0.9011072894465475\n",
      "train loss:0.7941574260709245\n",
      "train loss:0.7805943932765202\n",
      "train loss:0.8686636945876586\n",
      "train loss:0.6373250896999794\n",
      "train loss:1.0052848563318535\n",
      "train loss:0.7767324947636801\n",
      "train loss:0.8897813558989717\n",
      "train loss:0.8853900802395451\n",
      "train loss:0.8900570780821431\n",
      "train loss:0.9470495844443529\n",
      "train loss:0.8558007706050135\n",
      "train loss:0.891097426062328\n",
      "train loss:0.9082868150762589\n",
      "train loss:1.0693837489044666\n",
      "train loss:0.9327985784728218\n",
      "train loss:0.8108826487879374\n",
      "train loss:0.84348060178514\n",
      "train loss:0.6922207711259807\n",
      "train loss:1.001803684194659\n",
      "train loss:0.8829442024300584\n",
      "train loss:0.8525454101016688\n",
      "train loss:0.8251290057931844\n",
      "train loss:0.8660026290480901\n",
      "train loss:0.7774635820954933\n",
      "train loss:0.9941255803498619\n",
      "=== epoch:12, train acc:0.997, test acc:0.995 ===\n",
      "train loss:0.8389644507766475\n",
      "train loss:0.8937066702373034\n",
      "train loss:0.8994587952376106\n",
      "train loss:0.8570878966089677\n",
      "train loss:1.1152868412009567\n",
      "train loss:0.8471067596930275\n",
      "train loss:0.9868537566204766\n",
      "train loss:0.9038310152960117\n",
      "train loss:0.8111185981072444\n",
      "train loss:0.7239733188831334\n",
      "train loss:0.9052482785877295\n",
      "train loss:0.7817819576147487\n",
      "train loss:0.9798981574841737\n",
      "train loss:1.0684191469116486\n",
      "train loss:0.728661975632897\n",
      "train loss:0.8607905842524319\n",
      "train loss:1.0723526763101374\n",
      "train loss:0.9100592312715696\n",
      "train loss:0.7668797559579944\n",
      "train loss:1.0434073124296923\n",
      "train loss:1.011044762851216\n",
      "train loss:0.8202327610572404\n",
      "train loss:0.9564570343807283\n",
      "train loss:0.8591292394018027\n",
      "train loss:0.9335447197932686\n",
      "train loss:0.8643280223485482\n",
      "train loss:0.7801725626053435\n",
      "train loss:0.906391622538624\n",
      "train loss:0.817969374361188\n",
      "train loss:0.7087261868487552\n",
      "train loss:0.9709638580587332\n",
      "train loss:0.8366067590040154\n",
      "train loss:1.0348457876518722\n",
      "train loss:0.7575305592195554\n",
      "train loss:0.9421094278375601\n",
      "train loss:0.9768052024118928\n",
      "train loss:0.9219981754227904\n",
      "train loss:0.8943683066254973\n",
      "train loss:0.8101802646820181\n",
      "train loss:0.8541600414070732\n",
      "train loss:1.0146249146964506\n",
      "train loss:0.9017362220195563\n",
      "train loss:0.8884295674062962\n",
      "train loss:0.9949220257161948\n",
      "train loss:0.8829697159342474\n",
      "train loss:1.0604909763300319\n",
      "train loss:0.8208489943072363\n",
      "train loss:0.848119505960016\n",
      "train loss:0.872066204055688\n",
      "train loss:1.0191811052285704\n",
      "train loss:0.8114395351433733\n",
      "train loss:0.8621451550925933\n",
      "train loss:0.8721449374954109\n",
      "train loss:0.7448756359991687\n",
      "train loss:0.825943467238931\n",
      "train loss:0.885479412501999\n",
      "train loss:0.8084536726800348\n",
      "train loss:0.9024359553806309\n",
      "train loss:0.9756751519377524\n",
      "train loss:0.8237011766487757\n",
      "train loss:0.86274066760063\n",
      "train loss:0.765024920012135\n",
      "train loss:0.8826893205521293\n",
      "train loss:0.743015802072806\n",
      "train loss:0.938576073158347\n",
      "train loss:0.9106715967256983\n",
      "train loss:0.7891649940617849\n",
      "train loss:0.7534916221284099\n",
      "train loss:0.7295467628562623\n",
      "train loss:0.9093997635934987\n",
      "train loss:0.8406359936950749\n",
      "train loss:0.8930386666713774\n",
      "train loss:0.7248926167754568\n",
      "train loss:0.9543588086492275\n",
      "train loss:0.8081332562381083\n",
      "train loss:0.9638600172456957\n",
      "train loss:0.9536914192570272\n",
      "train loss:1.042052041186375\n",
      "train loss:0.7033707917799112\n",
      "train loss:0.8099237796955367\n",
      "train loss:0.8715900978144222\n",
      "train loss:0.9358515363331585\n",
      "train loss:0.6953429991433491\n",
      "train loss:0.7601033034004536\n",
      "train loss:0.9717138193345407\n",
      "train loss:1.0299820844522312\n",
      "train loss:1.0055646499740063\n",
      "train loss:0.8220817006305792\n",
      "train loss:0.9156479868227189\n",
      "train loss:0.8703075178705139\n",
      "train loss:0.8769700568265448\n",
      "train loss:0.879181779039726\n",
      "train loss:0.8508370390709152\n",
      "train loss:0.849358245229934\n",
      "train loss:0.8122485119644761\n",
      "train loss:0.8650958723466006\n",
      "train loss:0.7053182742451289\n",
      "train loss:0.8552527383439923\n",
      "train loss:1.0211874110374972\n",
      "train loss:1.021906310408503\n",
      "train loss:0.8180969297971632\n",
      "train loss:0.8703143482465713\n",
      "train loss:0.9299755738271697\n",
      "train loss:0.928031677270194\n",
      "train loss:0.8804503451165216\n",
      "train loss:0.8569323308679136\n",
      "train loss:0.8649480683465108\n",
      "train loss:0.807554792542398\n",
      "train loss:0.9094199097459206\n",
      "train loss:0.7997107731334248\n",
      "train loss:0.6676665703200797\n",
      "train loss:0.8505968933939653\n",
      "train loss:0.8052125858159873\n",
      "train loss:0.9918409983692594\n",
      "train loss:0.8778485756055041\n",
      "train loss:0.8605055313950802\n",
      "train loss:0.7864495060825182\n",
      "train loss:1.0910798083666535\n",
      "train loss:0.9302798819835912\n",
      "train loss:0.7912778544937928\n",
      "train loss:0.7305012574806672\n",
      "train loss:0.9016055289864415\n",
      "train loss:0.7751657031264917\n",
      "train loss:0.8019862796876583\n",
      "train loss:0.7967430495931878\n",
      "train loss:0.8483612699964741\n",
      "train loss:0.8087016129133415\n",
      "train loss:0.7376097654376039\n",
      "train loss:0.9099527626687092\n",
      "train loss:0.9166484560193605\n",
      "train loss:0.8235380169460588\n",
      "train loss:0.816445603847552\n",
      "train loss:0.9473332789076031\n",
      "train loss:0.7912655091409192\n",
      "train loss:0.8291176729038154\n",
      "train loss:0.7886426709758276\n",
      "train loss:1.044284884996697\n",
      "train loss:0.7800082039153124\n",
      "train loss:0.8771355241819208\n",
      "train loss:0.9297715323764695\n",
      "train loss:0.8173341227036438\n",
      "train loss:0.9587925973575199\n",
      "train loss:0.8894553231048432\n",
      "train loss:0.9167017517945227\n",
      "train loss:0.9272730969202145\n",
      "train loss:0.9129478717691119\n",
      "train loss:0.9921681138927886\n",
      "train loss:0.945071194507858\n",
      "train loss:0.7549157384490331\n",
      "train loss:0.8387386444813794\n",
      "train loss:0.8558751882844027\n",
      "train loss:0.8088742963833546\n",
      "train loss:0.9615182069791444\n",
      "train loss:0.8511186900997048\n",
      "train loss:0.8868729018201339\n",
      "train loss:0.942480643663244\n",
      "train loss:0.8321803418607715\n",
      "train loss:0.9690366671567167\n",
      "train loss:0.9429618689109915\n",
      "train loss:0.8273647019326548\n",
      "train loss:0.8565938006148969\n",
      "train loss:0.8246348354272528\n",
      "train loss:0.9993226525831489\n",
      "train loss:0.8570296953327435\n",
      "train loss:0.7923933829718964\n",
      "train loss:0.8580234852111518\n",
      "train loss:0.6766423096410749\n",
      "train loss:0.8451625524354097\n",
      "train loss:0.7702842628508217\n",
      "train loss:0.8425997764070194\n",
      "train loss:0.8092096102934602\n",
      "train loss:0.8075383597384567\n",
      "train loss:0.9282818286770741\n",
      "train loss:0.9106879451259497\n",
      "train loss:0.9201103485049582\n",
      "train loss:0.9688415657415922\n",
      "train loss:0.7426285969683452\n",
      "train loss:0.9962480766207671\n",
      "train loss:0.972204222702095\n",
      "train loss:0.9249402503196865\n",
      "train loss:0.7316964090285307\n",
      "train loss:0.9656860390597817\n",
      "train loss:0.6978248254454554\n",
      "train loss:0.776728318602798\n",
      "train loss:0.8105936446523496\n",
      "train loss:0.8745521733185018\n",
      "train loss:0.8900553200762473\n",
      "train loss:0.799599474505055\n",
      "train loss:0.8093637998441352\n",
      "train loss:0.8715037310933392\n",
      "train loss:0.8410137687909952\n",
      "train loss:0.795485507475629\n",
      "train loss:0.9236761822392381\n",
      "train loss:0.8013338367353032\n",
      "train loss:0.7824607054684418\n",
      "train loss:0.726451737779349\n",
      "train loss:0.9056271115706218\n",
      "train loss:0.9640040388932124\n",
      "train loss:0.8499293096025474\n",
      "train loss:0.8869505655240907\n",
      "train loss:0.8461254754970031\n",
      "train loss:0.7831447933583466\n",
      "train loss:0.8824095154028303\n",
      "train loss:0.9004591699873677\n",
      "train loss:0.8507506030821084\n",
      "train loss:0.7704481794603365\n",
      "train loss:0.8683277010751748\n",
      "train loss:1.0650138843701276\n",
      "train loss:0.7093633887060216\n",
      "train loss:0.8960215313201735\n",
      "train loss:0.8554903789132158\n",
      "train loss:0.9398391455098307\n",
      "train loss:0.7374967871306862\n",
      "train loss:0.7456676089835065\n",
      "train loss:1.033652652059101\n",
      "train loss:1.1618305624225542\n",
      "train loss:0.9567051598096209\n",
      "train loss:0.8490176484640901\n",
      "train loss:0.9764563380932271\n",
      "train loss:1.0541512850203052\n",
      "train loss:0.7638641812099628\n",
      "train loss:1.0031160271095294\n",
      "train loss:0.768444476779978\n",
      "train loss:0.8087046312369683\n",
      "train loss:0.8709051428702552\n",
      "train loss:0.9318385064854304\n",
      "train loss:0.7608341353069877\n",
      "train loss:0.8898376825343033\n",
      "train loss:1.0095795491559787\n",
      "train loss:0.8517859837053101\n",
      "train loss:0.7947474920248441\n",
      "train loss:0.7781964092112683\n",
      "train loss:0.9033841506559304\n",
      "train loss:0.9255986149639174\n",
      "train loss:0.8806325718810668\n",
      "train loss:0.8818251925668958\n",
      "train loss:1.0331419361236431\n",
      "train loss:0.9121249353501147\n",
      "train loss:0.8379619707459082\n",
      "train loss:0.7370107324295307\n",
      "train loss:0.9632623462535043\n",
      "train loss:1.0086068426345036\n",
      "train loss:0.9308253030693484\n",
      "train loss:0.858057441995565\n",
      "train loss:0.7230233789604443\n",
      "train loss:0.9395568244071161\n",
      "train loss:0.975025335762208\n",
      "train loss:0.8514319803995565\n",
      "train loss:0.947256179471376\n",
      "train loss:0.8130230692907168\n",
      "train loss:0.7738147449077502\n",
      "train loss:0.8129409509615977\n",
      "train loss:1.1378673445617458\n",
      "train loss:0.8647283374761982\n",
      "train loss:0.9528666751567105\n",
      "train loss:0.8805103302630084\n",
      "train loss:0.8381891256000555\n",
      "train loss:1.0384420630031117\n",
      "train loss:0.8384034488764196\n",
      "train loss:1.0606126582234519\n",
      "train loss:0.8296365732994946\n",
      "train loss:0.8772011158016165\n",
      "train loss:0.9504706236210336\n",
      "train loss:0.9211915893819217\n",
      "train loss:0.8680595830300074\n",
      "train loss:0.8737671277197373\n",
      "train loss:0.8540611717620703\n",
      "train loss:0.8936686855572007\n",
      "train loss:0.8077889277376978\n",
      "train loss:0.647607606914364\n",
      "train loss:0.7447539142750529\n",
      "train loss:0.8448305987266004\n",
      "train loss:0.9220984851679437\n",
      "train loss:0.9361353032621451\n",
      "train loss:0.8813185595246108\n",
      "train loss:0.8670311322887544\n",
      "train loss:0.9120531417146777\n",
      "train loss:0.8873508946686135\n",
      "train loss:0.7302055509783283\n",
      "train loss:1.0248074595943037\n",
      "train loss:0.707367512117359\n",
      "train loss:0.834872620132036\n",
      "train loss:0.884067341386765\n",
      "train loss:0.97070836095246\n",
      "train loss:0.9862920580481473\n",
      "train loss:0.785828780591205\n",
      "train loss:0.7802683841344461\n",
      "train loss:0.8643502410479682\n",
      "train loss:0.8138632001727796\n",
      "train loss:0.967671875931387\n",
      "train loss:0.8640380032151468\n",
      "train loss:0.8740376934516131\n",
      "train loss:0.8115151626025642\n",
      "train loss:0.8606530049299436\n",
      "train loss:0.8787026076813911\n",
      "train loss:0.9499139323818754\n",
      "train loss:1.008444812473772\n",
      "train loss:0.9121524887825154\n",
      "train loss:0.934334338347209\n",
      "train loss:0.7631377936960128\n",
      "train loss:0.9529404916201575\n",
      "train loss:1.2074072049621498\n",
      "train loss:0.7906657652964136\n",
      "train loss:0.7238861761681683\n",
      "train loss:0.8969385469930619\n",
      "train loss:0.9490793457382161\n",
      "train loss:0.8515044864412961\n",
      "train loss:0.7244108928076065\n",
      "train loss:0.830130584227686\n",
      "train loss:0.876941365753492\n",
      "train loss:0.8581045279066718\n",
      "train loss:1.0189207379814602\n",
      "train loss:0.9315482539284413\n",
      "train loss:0.7562790577006056\n",
      "train loss:0.8064496475670299\n",
      "train loss:0.8734617987653551\n",
      "train loss:0.8673073591423909\n",
      "train loss:0.8438898466765766\n",
      "train loss:0.8911619214846231\n",
      "train loss:0.9574784639301878\n",
      "train loss:0.6909322319129535\n",
      "train loss:0.772374719345563\n",
      "train loss:0.936780701257622\n",
      "train loss:0.9477516990841469\n",
      "train loss:0.9485214568630391\n",
      "train loss:0.8909831446003232\n",
      "train loss:0.8043603435887878\n",
      "train loss:0.8638709829590308\n",
      "train loss:0.9383737240721436\n",
      "train loss:0.9013612250954658\n",
      "train loss:0.8229279090799305\n",
      "train loss:0.8398018190321811\n",
      "train loss:0.8086905071085879\n",
      "train loss:0.9405892296783143\n",
      "train loss:0.8805964481926111\n",
      "train loss:0.7460276340436818\n",
      "train loss:0.8197342158710762\n",
      "train loss:0.8708309456759592\n",
      "train loss:0.9419711225916152\n",
      "train loss:0.8441813474012038\n",
      "train loss:0.9276149716901122\n",
      "train loss:0.8709224890049732\n",
      "train loss:0.7298212912449209\n",
      "train loss:0.9199121198587129\n",
      "train loss:0.9360192786702577\n",
      "train loss:0.8137137826658494\n",
      "train loss:0.9747298386380367\n",
      "train loss:0.8382436602350887\n",
      "train loss:0.8969030490061501\n",
      "train loss:0.6983304287765886\n",
      "train loss:0.7794439882303714\n",
      "train loss:0.7712431233868451\n",
      "train loss:0.882314053338926\n",
      "train loss:0.8745797222043116\n",
      "train loss:0.860179613056438\n",
      "train loss:0.9497020037405518\n",
      "train loss:0.8937773713077718\n",
      "train loss:0.9973200509784675\n",
      "train loss:0.8358101542243352\n",
      "train loss:0.9873162951030785\n",
      "train loss:0.8672630683100992\n",
      "train loss:0.9979893959429386\n",
      "train loss:0.8259794924045277\n",
      "train loss:0.9027526019021088\n",
      "train loss:0.9095127694242987\n",
      "train loss:0.8873541051405958\n",
      "train loss:0.958788976034628\n",
      "train loss:0.931742658298294\n",
      "train loss:0.69504372948713\n",
      "train loss:0.7958210399028495\n",
      "train loss:1.0618121544162766\n",
      "train loss:0.9423353631014996\n",
      "train loss:0.7995292872077484\n",
      "train loss:1.027224739454682\n",
      "train loss:0.9781387141830558\n",
      "train loss:0.8687764851547254\n",
      "train loss:1.0600280652904486\n",
      "train loss:0.9045184146884158\n",
      "train loss:1.1040555737894322\n",
      "train loss:1.0248425480085221\n",
      "train loss:0.9374583341470968\n",
      "train loss:1.0889615542398163\n",
      "train loss:0.9845043420158848\n",
      "train loss:0.8784918585356845\n",
      "train loss:0.9648889040248401\n",
      "train loss:0.697784277640279\n",
      "train loss:0.9167901791915483\n",
      "train loss:0.872348886931926\n",
      "train loss:0.8133687366111728\n",
      "train loss:0.839274646625925\n",
      "train loss:1.0009045604558036\n",
      "train loss:0.8706255295711892\n",
      "train loss:0.6737751779352421\n",
      "train loss:0.8196734930427403\n",
      "train loss:1.0639830836043536\n",
      "train loss:0.9586254933081539\n",
      "train loss:0.847115468014807\n",
      "train loss:0.8011663278112668\n",
      "train loss:1.0431626672355139\n",
      "train loss:0.9030375818365002\n",
      "train loss:0.8284653362672704\n",
      "train loss:0.8801177596501901\n",
      "train loss:0.7753287890890335\n",
      "train loss:0.8154427718441724\n",
      "train loss:0.7557190480196351\n",
      "train loss:0.9938399684855505\n",
      "train loss:0.9705856591839838\n",
      "train loss:1.0498384740840432\n",
      "train loss:0.8578625163762941\n",
      "train loss:0.8106405271423551\n",
      "train loss:0.9502301746353277\n",
      "train loss:0.833048165245231\n",
      "train loss:0.8368622492944351\n",
      "train loss:0.9142857378494971\n",
      "train loss:0.9707157310628501\n",
      "train loss:0.8577003161211298\n",
      "train loss:0.7178702677675318\n",
      "train loss:0.7951143358248952\n",
      "train loss:0.9983205069447746\n",
      "train loss:0.8311294611762081\n",
      "train loss:0.9037907779764286\n",
      "train loss:0.8613429165354295\n",
      "train loss:0.9148524790147969\n",
      "train loss:1.0328368646895338\n",
      "train loss:0.950632245459313\n",
      "train loss:0.7962350800176557\n",
      "train loss:0.8898529459807064\n",
      "train loss:0.6877608146450354\n",
      "train loss:0.8292498322030835\n",
      "train loss:0.8775632501382524\n",
      "train loss:0.9298102283470007\n",
      "train loss:0.928500511592953\n",
      "train loss:0.8215420388344039\n",
      "train loss:0.9600580548061979\n",
      "train loss:0.8830562110744871\n",
      "train loss:0.7460795706737783\n",
      "train loss:1.0319372244811478\n",
      "train loss:0.841369756723917\n",
      "train loss:0.9005792645067217\n",
      "train loss:0.7078769174656889\n",
      "train loss:0.9396691747839728\n",
      "train loss:1.0507288618841286\n",
      "train loss:0.79174711030423\n",
      "train loss:0.8679605227301194\n",
      "train loss:0.9303127465971006\n",
      "train loss:0.7371953265821058\n",
      "train loss:0.9491046324295183\n",
      "train loss:1.1198780076116142\n",
      "train loss:1.0046184463763885\n",
      "train loss:0.7396436176946041\n",
      "train loss:0.8731648104351897\n",
      "train loss:1.0080605491376817\n",
      "train loss:0.9506599475824669\n",
      "train loss:0.8026035300032811\n",
      "train loss:0.9738805443305165\n",
      "train loss:0.8712848432818745\n",
      "train loss:1.0407000007039833\n",
      "train loss:1.0481277868060273\n",
      "train loss:0.9266422685426348\n",
      "train loss:1.0556054785489113\n",
      "train loss:0.8442759180562747\n",
      "train loss:0.8264581458645899\n",
      "train loss:0.8851434043145103\n",
      "train loss:0.8070526304122149\n",
      "train loss:0.8744213713261141\n",
      "train loss:0.761624062395707\n",
      "train loss:1.0205919545870414\n",
      "train loss:0.9368114458111184\n",
      "train loss:0.8576238886382125\n",
      "train loss:0.8547844522371326\n",
      "train loss:0.8113971272431205\n",
      "train loss:0.9148550472776645\n",
      "train loss:0.9121122261053126\n",
      "train loss:0.7807202953161121\n",
      "train loss:0.8572783499379146\n",
      "train loss:0.7821294824550915\n",
      "train loss:0.9463956169485823\n",
      "train loss:1.029981447849403\n",
      "train loss:0.858396078692709\n",
      "train loss:0.901780442131695\n",
      "train loss:0.9727813152110792\n",
      "train loss:0.8615675215489661\n",
      "train loss:0.7953692544493426\n",
      "train loss:0.9825180702146669\n",
      "train loss:0.7358902940583083\n",
      "train loss:0.8031716566070982\n",
      "train loss:0.6898987480391164\n",
      "train loss:0.7978115343729449\n",
      "train loss:0.8520108316768034\n",
      "train loss:0.9590903149051805\n",
      "train loss:0.9301676369969353\n",
      "train loss:0.8605039107510062\n",
      "train loss:0.8591166324501196\n",
      "train loss:0.9252769074392724\n",
      "train loss:0.9286398752652849\n",
      "train loss:0.9172088658553739\n",
      "train loss:1.0009164658038816\n",
      "train loss:0.8386261735151923\n",
      "train loss:0.8857491340095679\n",
      "train loss:0.7067604216800325\n",
      "train loss:0.9747591052145083\n",
      "train loss:0.7476428111471844\n",
      "train loss:0.8189995049883927\n",
      "train loss:0.8932388290828353\n",
      "train loss:0.7163390811287238\n",
      "train loss:0.838389912368535\n",
      "train loss:0.9446368338575328\n",
      "train loss:0.8193722855304576\n",
      "train loss:1.0271484812678324\n",
      "train loss:0.787263056183333\n",
      "train loss:0.8355869376549494\n",
      "train loss:0.8745874166717468\n",
      "train loss:0.9389570195592364\n",
      "train loss:0.8833968653848041\n",
      "train loss:0.7754486588015692\n",
      "train loss:0.6368271420109572\n",
      "train loss:0.7069232002785939\n",
      "train loss:0.8683151550464207\n",
      "train loss:0.7652007989772595\n",
      "train loss:0.8737347812414117\n",
      "train loss:0.6956184620605105\n",
      "train loss:0.8765256469027536\n",
      "train loss:0.7519881429362993\n",
      "train loss:0.8653335806941236\n",
      "train loss:0.9515528989405196\n",
      "train loss:0.7938568291850949\n",
      "train loss:1.0013066476802406\n",
      "train loss:1.2306132976878092\n",
      "train loss:0.8954178589483797\n",
      "train loss:0.8419807210815685\n",
      "train loss:1.1683084075539438\n",
      "train loss:1.0175742798788783\n",
      "train loss:1.0474145900110974\n",
      "train loss:0.9538193462490279\n",
      "train loss:0.9081213724032051\n",
      "train loss:0.9058034443715958\n",
      "train loss:0.8634656829990606\n",
      "train loss:0.939887955630782\n",
      "train loss:0.9553260368599418\n",
      "train loss:0.7625429648169667\n",
      "train loss:0.8112578371939675\n",
      "train loss:0.7159298612242333\n",
      "train loss:0.7284447148554675\n",
      "train loss:0.8331295523234326\n",
      "train loss:0.8346626383402621\n",
      "train loss:0.9089117826492753\n",
      "train loss:1.002547597522034\n",
      "train loss:0.8942460363758404\n",
      "train loss:0.8796461744658515\n",
      "train loss:0.7953056779097456\n",
      "train loss:0.7836708827977716\n",
      "train loss:0.8933206944484284\n",
      "train loss:0.9262556868035212\n",
      "train loss:0.9042448466490599\n",
      "train loss:0.9440465682962119\n",
      "train loss:0.8344325526823497\n",
      "train loss:0.7629229392202332\n",
      "train loss:0.7534915332693781\n",
      "train loss:0.8632617069151333\n",
      "train loss:0.7611317641097554\n",
      "train loss:0.8032357031479488\n",
      "train loss:0.8995328267408751\n",
      "train loss:0.7767331140798004\n",
      "train loss:0.8441267144796173\n",
      "train loss:0.9155008856023394\n",
      "train loss:0.7768998988307829\n",
      "train loss:0.8581470786780564\n",
      "train loss:0.8065717013001312\n",
      "train loss:1.0194242258845165\n",
      "train loss:0.8129456871818124\n",
      "train loss:0.9553973112582769\n",
      "train loss:0.9288136612327303\n",
      "train loss:0.9226826976783536\n",
      "train loss:0.8240544305247064\n",
      "train loss:0.8132509121448609\n",
      "train loss:0.8363411271357762\n",
      "train loss:0.9233386706442073\n",
      "train loss:0.8323486063897009\n",
      "train loss:0.8134926647819373\n",
      "train loss:0.9331541413896445\n",
      "train loss:0.7598981778409045\n",
      "train loss:0.8668442275760003\n",
      "train loss:0.7699861299013332\n",
      "train loss:0.839490572611939\n",
      "train loss:1.0842282818462625\n",
      "train loss:0.8633952852169845\n",
      "train loss:0.892135990777383\n",
      "train loss:0.9705215610202039\n",
      "train loss:0.6923432677416537\n",
      "train loss:0.8359433763639997\n",
      "train loss:0.821738898249896\n",
      "train loss:0.7784397082264145\n",
      "train loss:1.0301019629206574\n",
      "train loss:0.9307356902563566\n",
      "train loss:0.8235309445670258\n",
      "train loss:1.0178345064782075\n",
      "train loss:0.7302925762536253\n",
      "train loss:0.8111560978160952\n",
      "train loss:1.0043096483677625\n",
      "train loss:0.8403219880898206\n",
      "=== epoch:13, train acc:0.996, test acc:0.991 ===\n",
      "train loss:0.8081899923871987\n",
      "train loss:0.8310816667719315\n",
      "train loss:0.8705528884149893\n",
      "train loss:0.7884970985700668\n",
      "train loss:0.9030641271657575\n",
      "train loss:0.7459657094041865\n",
      "train loss:0.9341629877588544\n",
      "train loss:1.0399781198608746\n",
      "train loss:0.8349676007382767\n",
      "train loss:0.883513763262562\n",
      "train loss:0.7922088521923553\n",
      "train loss:0.973945606174294\n",
      "train loss:0.7764888492048548\n",
      "train loss:0.9209469721125219\n",
      "train loss:0.9454427880132675\n",
      "train loss:0.8818023872837629\n",
      "train loss:0.7430451352045873\n",
      "train loss:0.5268809754677516\n",
      "train loss:0.9886601824727506\n",
      "train loss:0.6750140257228368\n",
      "train loss:0.8432357145851931\n",
      "train loss:0.9835390982570814\n",
      "train loss:1.027311739434857\n",
      "train loss:0.9032186509160358\n",
      "train loss:0.9254864119488245\n",
      "train loss:0.9324457498116173\n",
      "train loss:0.7564903702327134\n",
      "train loss:0.869761654558136\n",
      "train loss:0.8122117627813117\n",
      "train loss:0.9090192617056932\n",
      "train loss:0.8335879232163509\n",
      "train loss:1.064223823344711\n",
      "train loss:0.9313646625276901\n",
      "train loss:0.8711144926737313\n",
      "train loss:0.7772381034373597\n",
      "train loss:0.9433879423429122\n",
      "train loss:0.8695496251780982\n",
      "train loss:0.9185641218281162\n",
      "train loss:0.9473178856700818\n",
      "train loss:0.7661109366505879\n",
      "train loss:0.8519504188973016\n",
      "train loss:0.8114138121342742\n",
      "train loss:0.9285611356292255\n",
      "train loss:0.8613099136069903\n",
      "train loss:1.006169239053178\n",
      "train loss:0.7589134771179438\n",
      "train loss:0.8391588141243127\n",
      "train loss:0.7543773164462724\n",
      "train loss:0.8089442126149432\n",
      "train loss:0.9712911518116636\n",
      "train loss:1.0289792050865172\n",
      "train loss:0.8614559903946902\n",
      "train loss:0.9880666289121239\n",
      "train loss:0.9484893703690134\n",
      "train loss:0.8927274654102634\n",
      "train loss:0.8970855081006843\n",
      "train loss:0.9183559110049413\n",
      "train loss:0.8620189628758765\n",
      "train loss:0.8645010411999732\n",
      "train loss:0.9744447714861971\n",
      "train loss:0.8903170026724768\n",
      "train loss:0.9886337200949872\n",
      "train loss:0.8408038378623715\n",
      "train loss:0.8684993212473525\n",
      "train loss:0.8655395732123772\n",
      "train loss:0.6989157068687031\n",
      "train loss:0.9353686330751388\n",
      "train loss:0.8567903365926673\n",
      "train loss:0.993009274531981\n",
      "train loss:0.8647990364541029\n",
      "train loss:0.7883633815862465\n",
      "train loss:0.9086152927916938\n",
      "train loss:0.8859454658895903\n",
      "train loss:0.9577967672883\n",
      "train loss:0.8160095737178565\n",
      "train loss:0.7793055367820287\n",
      "train loss:0.759407110045226\n",
      "train loss:1.0300705944089807\n",
      "train loss:0.8950424300195695\n",
      "train loss:0.9338596116315853\n",
      "train loss:0.9081447687506102\n",
      "train loss:0.7976876645389542\n",
      "train loss:0.7802095774362091\n",
      "train loss:0.8354420141201109\n",
      "train loss:0.897014888874979\n",
      "train loss:0.7999489167934645\n",
      "train loss:0.5991460047122762\n",
      "train loss:1.033995761112548\n",
      "train loss:0.8832994047906074\n",
      "train loss:0.8660083077305616\n",
      "train loss:0.8387742658575651\n",
      "train loss:0.8711296219412867\n",
      "train loss:0.7582546646107532\n",
      "train loss:0.7775698078456643\n",
      "train loss:0.846097545434613\n",
      "train loss:0.9056123244165394\n",
      "train loss:0.882738506638906\n",
      "train loss:0.8866652662199433\n",
      "train loss:0.8805622377296443\n",
      "train loss:0.8396065992671352\n",
      "train loss:0.9614963745444152\n",
      "train loss:0.9543223579139173\n",
      "train loss:0.8670300336933815\n",
      "train loss:0.6893837188371537\n",
      "train loss:0.7204722763952183\n",
      "train loss:0.9453504709004652\n",
      "train loss:0.9329997558607701\n",
      "train loss:0.7487368273981195\n",
      "train loss:0.7974201827555453\n",
      "train loss:1.0265304048024018\n",
      "train loss:0.7940292252701986\n",
      "train loss:1.0157530038914744\n",
      "train loss:0.9085764724184756\n",
      "train loss:0.9112785757821392\n",
      "train loss:1.0106527653909085\n",
      "train loss:0.8953838346094598\n",
      "train loss:0.73740431495813\n",
      "train loss:0.9654247806890116\n",
      "train loss:0.7735808807565541\n",
      "train loss:0.825844495817523\n",
      "train loss:0.9025619197006876\n",
      "train loss:0.890911532659981\n",
      "train loss:0.8035285283860452\n",
      "train loss:0.8448099280684598\n",
      "train loss:0.8771356187775976\n",
      "train loss:0.9909223301729138\n",
      "train loss:0.7723286038100986\n",
      "train loss:0.9006499102456652\n",
      "train loss:0.8321760894823459\n",
      "train loss:0.8443160149823139\n",
      "train loss:1.0140027811345131\n",
      "train loss:1.0633724808061886\n",
      "train loss:0.9449065158294404\n",
      "train loss:0.9645120496384905\n",
      "train loss:0.8393052683862746\n",
      "train loss:0.8931793743192011\n",
      "train loss:1.0401175578841857\n",
      "train loss:0.7445211296528944\n",
      "train loss:1.148486057727526\n",
      "train loss:0.7768272904656353\n",
      "train loss:0.9232134337158641\n",
      "train loss:0.8644087548362601\n",
      "train loss:0.8346627711714153\n",
      "train loss:0.8996240502123559\n",
      "train loss:0.8473726620154503\n",
      "train loss:0.7373221502364758\n",
      "train loss:0.8218717286599785\n",
      "train loss:1.1417856465616307\n",
      "train loss:0.864261994992005\n",
      "train loss:0.8150657527390753\n",
      "train loss:0.8630335960821433\n",
      "train loss:0.8820870513843072\n",
      "train loss:0.7269246175682802\n",
      "train loss:0.7788106079117757\n",
      "train loss:0.9743523883126299\n",
      "train loss:0.8238484263044816\n",
      "train loss:0.780427711326086\n",
      "train loss:0.8357341728060912\n",
      "train loss:0.7367649711074918\n",
      "train loss:0.6928419553384845\n",
      "train loss:0.7294461334389511\n",
      "train loss:0.899555007754679\n",
      "train loss:0.7654902029595659\n",
      "train loss:0.9120034647569994\n",
      "train loss:0.7693915107426759\n",
      "train loss:0.7842429263627557\n",
      "train loss:0.8094986431744576\n",
      "train loss:1.0203481548478286\n",
      "train loss:1.0092812160595235\n",
      "train loss:0.7932337906422455\n",
      "train loss:0.8480979754982867\n",
      "train loss:0.7826910691388613\n",
      "train loss:1.0244969858365296\n",
      "train loss:1.0177323721574933\n",
      "train loss:0.989359795936694\n",
      "train loss:0.9134650542736835\n",
      "train loss:0.9694205473692469\n",
      "train loss:0.8178296624301393\n",
      "train loss:0.80601115751208\n",
      "train loss:0.8925904453695539\n",
      "train loss:0.9295986708360349\n",
      "train loss:0.8487826259258222\n",
      "train loss:0.9487558786964739\n",
      "train loss:0.8948508834654906\n",
      "train loss:0.7376715183225212\n",
      "train loss:0.9103190579026752\n",
      "train loss:0.9432377284030564\n",
      "train loss:0.6850987779357702\n",
      "train loss:0.9589940587260698\n",
      "train loss:0.8775938840411578\n",
      "train loss:0.9278881579441597\n",
      "train loss:0.8511787888903304\n",
      "train loss:0.8912263103503245\n",
      "train loss:0.9053007261368151\n",
      "train loss:0.9035551970051933\n",
      "train loss:0.8200011747503698\n",
      "train loss:0.8226165126004368\n",
      "train loss:1.0122574171673708\n",
      "train loss:0.816764606920697\n",
      "train loss:0.8565646619710343\n",
      "train loss:0.8215088620448107\n",
      "train loss:0.9759650266752301\n",
      "train loss:0.9250163372773292\n",
      "train loss:0.7920927856772103\n",
      "train loss:0.8793058255827669\n",
      "train loss:0.9440548662271036\n",
      "train loss:0.933476182513211\n",
      "train loss:0.7459020211760184\n",
      "train loss:0.9772044298267089\n",
      "train loss:0.862908028754382\n",
      "train loss:0.7347637808200952\n",
      "train loss:0.8434821699134212\n",
      "train loss:0.7958324895977398\n",
      "train loss:1.019106947111724\n",
      "train loss:0.9725766253570193\n",
      "train loss:0.7717567391000182\n",
      "train loss:0.8181028585313652\n",
      "train loss:0.8198761866437748\n",
      "train loss:0.8434305998611865\n",
      "train loss:0.8813977353236081\n",
      "train loss:0.7197439757279848\n",
      "train loss:0.7206719473052834\n",
      "train loss:0.890358374900888\n",
      "train loss:0.9887225747724628\n",
      "train loss:0.9458451595746468\n",
      "train loss:0.7855157938851307\n",
      "train loss:0.8440395150194998\n",
      "train loss:0.8862319674648209\n",
      "train loss:0.9552372069907514\n",
      "train loss:0.7404009330681579\n",
      "train loss:0.836141000062294\n",
      "train loss:1.028190915156415\n",
      "train loss:0.6633395574129373\n",
      "train loss:0.8098995433715893\n",
      "train loss:0.7515398754209593\n",
      "train loss:0.8906940765056519\n",
      "train loss:0.7984707852489847\n",
      "train loss:0.9860946347343098\n",
      "train loss:0.8458042760980686\n",
      "train loss:0.8453336930010364\n",
      "train loss:0.7897980536895136\n",
      "train loss:0.6829034538075794\n",
      "train loss:0.877874410859367\n",
      "train loss:0.9055758890122168\n",
      "train loss:0.9761009780651199\n",
      "train loss:0.8721998399181039\n",
      "train loss:0.8461292299144373\n",
      "train loss:0.838489452907\n",
      "train loss:0.7799719086327483\n",
      "train loss:0.9263440536420546\n",
      "train loss:1.0215817047983249\n",
      "train loss:0.9238265509755031\n",
      "train loss:0.7570427791799038\n",
      "train loss:0.8513045588076459\n",
      "train loss:0.9306503625000829\n",
      "train loss:0.9621330530598996\n",
      "train loss:1.043642148454142\n",
      "train loss:1.0391063032753929\n",
      "train loss:0.8989209128729883\n",
      "train loss:0.7198348596951115\n",
      "train loss:0.699176602355649\n",
      "train loss:0.9022907671765238\n",
      "train loss:0.8266616964456571\n",
      "train loss:1.0211088167827116\n",
      "train loss:0.9257490923280401\n",
      "train loss:0.9861153677202273\n",
      "train loss:0.7820118317444124\n",
      "train loss:0.8299464533635943\n",
      "train loss:0.8490508815805043\n",
      "train loss:0.8677088748232713\n",
      "train loss:0.8429860157922409\n",
      "train loss:0.8929357975192781\n",
      "train loss:0.9089384029831011\n",
      "train loss:0.9718798255143802\n",
      "train loss:0.8563851906540692\n",
      "train loss:1.0208211070409243\n",
      "train loss:0.9130207247446529\n",
      "train loss:0.7135789150085805\n",
      "train loss:0.7433063276542459\n",
      "train loss:0.8772247020955274\n",
      "train loss:0.9440201851732326\n",
      "train loss:0.8117686144827237\n",
      "train loss:1.0438839306764434\n",
      "train loss:0.8518897847729434\n",
      "train loss:0.8026920686876615\n",
      "train loss:0.9012485639430846\n",
      "train loss:0.9038454617166835\n",
      "train loss:0.8487577320825384\n",
      "train loss:0.7003975074421435\n",
      "train loss:0.8805740415651807\n",
      "train loss:0.7724402388604896\n",
      "train loss:1.0954263644265088\n",
      "train loss:0.7084144471466578\n",
      "train loss:0.8949317626634584\n",
      "train loss:0.9386640841702685\n",
      "train loss:0.8011443309918171\n",
      "train loss:0.9134317826439282\n",
      "train loss:0.7307529113655835\n",
      "train loss:0.6122104685192652\n",
      "train loss:0.8431162227038513\n",
      "train loss:0.977636619754508\n",
      "train loss:0.8437295316724186\n",
      "train loss:0.9573312868100347\n",
      "train loss:0.9585007642675296\n",
      "train loss:0.7887490084370766\n",
      "train loss:0.8832242793311531\n",
      "train loss:0.9063568138221154\n",
      "train loss:1.0637061937967538\n",
      "train loss:0.9900951235996829\n",
      "train loss:0.9545867093980844\n",
      "train loss:0.7636644392744895\n",
      "train loss:0.826865514590561\n",
      "train loss:0.811141866621093\n",
      "train loss:0.9802478067982372\n",
      "train loss:0.9649183945236005\n",
      "train loss:0.7078593301815329\n",
      "train loss:0.7750453429058359\n",
      "train loss:0.9022736732940139\n",
      "train loss:0.9699730910140361\n",
      "train loss:0.7277424603270576\n",
      "train loss:0.8216152461874268\n",
      "train loss:0.7775200728546007\n",
      "train loss:0.9080586785353526\n",
      "train loss:0.9218727471185392\n",
      "train loss:0.6751074630912848\n",
      "train loss:0.783069732738117\n",
      "train loss:0.8204747002938083\n",
      "train loss:0.9065750326107856\n",
      "train loss:0.8685789762988811\n",
      "train loss:0.6768981699505724\n",
      "train loss:0.9555905129610562\n",
      "train loss:0.8392693397431258\n",
      "train loss:0.9402243148315402\n",
      "train loss:0.9125851031579632\n",
      "train loss:1.0529931812498854\n",
      "train loss:0.9312354341835092\n",
      "train loss:0.7893306901107928\n",
      "train loss:0.8876095901336284\n",
      "train loss:0.9212779416086571\n",
      "train loss:0.8253196153853217\n",
      "train loss:0.9006077356437081\n",
      "train loss:0.8630125091974361\n",
      "train loss:0.8471485296288214\n",
      "train loss:0.8495298858713669\n",
      "train loss:0.7567453257121141\n",
      "train loss:0.952579135143073\n",
      "train loss:0.8491990838172389\n",
      "train loss:0.8920677692526184\n",
      "train loss:0.8724420994611316\n",
      "train loss:0.9322140463526343\n",
      "train loss:0.9211398732366008\n",
      "train loss:0.9023647660631223\n",
      "train loss:0.8588252350726998\n",
      "train loss:0.6986984768278603\n",
      "train loss:0.9903596827328444\n",
      "train loss:0.9069217664461232\n",
      "train loss:0.7622504738007333\n",
      "train loss:0.984978633476679\n",
      "train loss:1.2744203006052965\n",
      "train loss:0.839875041966619\n",
      "train loss:0.9030626633234384\n",
      "train loss:0.835647518666429\n",
      "train loss:0.8585310898494223\n",
      "train loss:0.866540708149559\n",
      "train loss:0.855716442017341\n",
      "train loss:0.77751496836947\n",
      "train loss:0.8106797964928818\n",
      "train loss:0.8712404210209176\n",
      "train loss:0.9404730560818318\n",
      "train loss:0.8440377242715534\n",
      "train loss:0.7982503599123624\n",
      "train loss:0.9490166855679343\n",
      "train loss:0.8900747221851172\n",
      "train loss:0.846733387625018\n",
      "train loss:0.8683272260097096\n",
      "train loss:0.9024353438626956\n",
      "train loss:0.9360369316618576\n",
      "train loss:0.8508032603282147\n",
      "train loss:0.9208536540086958\n",
      "train loss:0.7881547748348933\n",
      "train loss:0.8338468756098005\n",
      "train loss:0.7885112531014911\n",
      "train loss:0.7742273652908185\n",
      "train loss:0.7821630356757179\n",
      "train loss:0.9250625458951383\n",
      "train loss:0.980922990003618\n",
      "train loss:0.7630068119678322\n",
      "train loss:0.8511869756172078\n",
      "train loss:0.9468325031597489\n",
      "train loss:0.8317677256474534\n",
      "train loss:0.8515096647978782\n",
      "train loss:0.8158411359260996\n",
      "train loss:0.8327346023789284\n",
      "train loss:0.9260432068401324\n",
      "train loss:0.9724300146113106\n",
      "train loss:0.7664870041565749\n",
      "train loss:0.8350529467199785\n",
      "train loss:0.9825422370969319\n",
      "train loss:0.8506390740632227\n",
      "train loss:0.960367716183852\n",
      "train loss:0.9451097751740669\n",
      "train loss:0.822602600009676\n",
      "train loss:1.1074778223084498\n",
      "train loss:0.779303186689156\n",
      "train loss:0.9201419555975632\n",
      "train loss:0.8290637505139496\n",
      "train loss:1.0172021679306502\n",
      "train loss:0.9634459173079716\n",
      "train loss:0.8749943987970148\n",
      "train loss:0.9719979281785914\n",
      "train loss:0.9685489936076493\n",
      "train loss:0.9551417070973106\n",
      "train loss:0.8838391749671685\n",
      "train loss:0.8911618786591322\n",
      "train loss:0.8803814979189386\n",
      "train loss:0.9184054873917874\n",
      "train loss:0.7732496274963043\n",
      "train loss:0.7642557686784179\n",
      "train loss:0.9208772360078334\n",
      "train loss:0.8412118517300818\n",
      "train loss:0.9461048725354655\n",
      "train loss:1.1118239882821879\n",
      "train loss:0.9697448912543132\n",
      "train loss:0.9004156021224753\n",
      "train loss:1.0654905103448742\n",
      "train loss:0.8166799471248732\n",
      "train loss:0.9480413079430575\n",
      "train loss:0.9309096062322173\n",
      "train loss:0.8738092556088979\n",
      "train loss:0.859207532164612\n",
      "train loss:0.7523009619708578\n",
      "train loss:0.9951855863938696\n",
      "train loss:0.839034224490306\n",
      "train loss:0.7671550589607433\n",
      "train loss:0.8422802602009181\n",
      "train loss:0.8967348812108428\n",
      "train loss:0.8723422094043956\n",
      "train loss:0.9658933981353462\n",
      "train loss:0.8268600259953186\n",
      "train loss:0.749151151940886\n",
      "train loss:0.925781671465094\n",
      "train loss:0.917360442441651\n",
      "train loss:0.8265875027968892\n",
      "train loss:0.9285294393729809\n",
      "train loss:0.9639366582753592\n",
      "train loss:0.8639418061197247\n",
      "train loss:0.774448038555699\n",
      "train loss:0.8352758504395507\n",
      "train loss:0.9710621261224245\n",
      "train loss:0.8053767833984112\n",
      "train loss:0.9647499997615929\n",
      "train loss:0.9883444970720707\n",
      "train loss:1.0667236205957626\n",
      "train loss:0.6469873721682998\n",
      "train loss:0.7039051924944104\n",
      "train loss:0.8397423793652622\n",
      "train loss:0.8251854661466175\n",
      "train loss:0.9471723394561077\n",
      "train loss:0.8413527714479133\n",
      "train loss:0.7743196485335762\n",
      "train loss:0.8878739688156007\n",
      "train loss:0.9446040355684883\n",
      "train loss:0.944726185026282\n",
      "train loss:0.8435749202426912\n",
      "train loss:0.9078059424232059\n",
      "train loss:0.7324072384216975\n",
      "train loss:0.9418112348892693\n",
      "train loss:0.7756976264065565\n",
      "train loss:0.9741371631111118\n",
      "train loss:1.0106783387342038\n",
      "train loss:0.8335918793318298\n",
      "train loss:0.8857186017879813\n",
      "train loss:0.8390610068688441\n",
      "train loss:0.7827036499359862\n",
      "train loss:0.9103398724593762\n",
      "train loss:0.9382092570939341\n",
      "train loss:0.9553978008678505\n",
      "train loss:0.8572425496952707\n",
      "train loss:0.8444381424323214\n",
      "train loss:0.9482308809393695\n",
      "train loss:0.7721628725242828\n",
      "train loss:0.8135058269364991\n",
      "train loss:0.9681749849639292\n",
      "train loss:0.7235576581937522\n",
      "train loss:0.828471344776344\n",
      "train loss:0.9114189202820853\n",
      "train loss:0.8122227899577836\n",
      "train loss:1.0008514843745693\n",
      "train loss:0.9049408622051112\n",
      "train loss:0.8889046943978184\n",
      "train loss:0.837847176188103\n",
      "train loss:0.9952149577981514\n",
      "train loss:0.8163873127916697\n",
      "train loss:0.8435402977449636\n",
      "train loss:0.8502382139976212\n",
      "train loss:0.8695066681312822\n",
      "train loss:0.9184101694188772\n",
      "train loss:0.9238604079144273\n",
      "train loss:0.925360809435539\n",
      "train loss:0.9755713604255996\n",
      "train loss:0.873086471828473\n",
      "train loss:0.7666448560696421\n",
      "train loss:0.8623563152520417\n",
      "train loss:0.9816474224851807\n",
      "train loss:0.902352111921516\n",
      "train loss:0.9261959489658943\n",
      "train loss:0.8600180629013561\n",
      "train loss:0.9506095065992747\n",
      "train loss:0.7870872665760354\n",
      "train loss:1.006164064151521\n",
      "train loss:0.719405905172334\n",
      "train loss:0.9391690700774821\n",
      "train loss:0.8679668762441652\n",
      "train loss:0.7777888683963262\n",
      "train loss:1.0303404097086053\n",
      "train loss:0.7467217307204059\n",
      "train loss:0.7063853010725692\n",
      "train loss:0.842967631084435\n",
      "train loss:0.9237790874320712\n",
      "train loss:0.8259544467089086\n",
      "train loss:0.8734708148252001\n",
      "train loss:0.9569175891658043\n",
      "train loss:0.8085796140888647\n",
      "train loss:0.8309826429300116\n",
      "train loss:0.7146442034021373\n",
      "train loss:0.844260554125245\n",
      "train loss:0.840444598611182\n",
      "train loss:0.7970052998361484\n",
      "train loss:0.9337883444211376\n",
      "train loss:0.7548481450735243\n",
      "train loss:0.9932184280530921\n",
      "train loss:0.9617856984029338\n",
      "train loss:0.8423532728590573\n",
      "train loss:0.6392261318944461\n",
      "train loss:0.7717200692919374\n",
      "train loss:0.8882257195228092\n",
      "train loss:0.9865747905116151\n",
      "train loss:0.7845243509096893\n",
      "train loss:0.7795166851199495\n",
      "train loss:0.9202434054070823\n",
      "train loss:0.9804529998294025\n",
      "train loss:0.7489642457853982\n",
      "train loss:0.7550757744706295\n",
      "train loss:0.8413217769793002\n",
      "train loss:1.0268052171438824\n",
      "train loss:0.9529056726522576\n",
      "train loss:0.8214855470100066\n",
      "train loss:0.8689855674401035\n",
      "train loss:0.8506990811757099\n",
      "train loss:0.8756525046222621\n",
      "train loss:0.8627414021315205\n",
      "train loss:0.9579133415719454\n",
      "train loss:0.9558172640649495\n",
      "train loss:0.9135195257604272\n",
      "train loss:0.9497996468985156\n",
      "train loss:0.8195671502378711\n",
      "train loss:0.951299767357564\n",
      "train loss:0.9485244478874166\n",
      "train loss:0.8557119527740941\n",
      "train loss:0.8494849020440962\n",
      "train loss:0.8193360009993946\n",
      "train loss:0.8246270590519496\n",
      "train loss:0.9707895327701594\n",
      "train loss:0.9738616830841909\n",
      "train loss:0.9232648187387915\n",
      "train loss:0.8811050935181107\n",
      "train loss:1.0216056437211118\n",
      "train loss:0.7986329114484648\n",
      "train loss:0.8790874875500534\n",
      "train loss:0.833029935018623\n",
      "train loss:0.8476895284736584\n",
      "train loss:0.8584858203206922\n",
      "train loss:0.7651176833013941\n",
      "train loss:1.0986711248708685\n",
      "train loss:0.7885265672959025\n",
      "train loss:0.9302977322988012\n",
      "train loss:0.9015299964541312\n",
      "train loss:0.9651776924842653\n",
      "train loss:0.8916331967422493\n",
      "train loss:0.8008807551181669\n",
      "train loss:0.8929967037890116\n",
      "train loss:0.8640556518416296\n",
      "train loss:0.8211712857877805\n",
      "train loss:0.8260302406637006\n",
      "train loss:0.8632926210438956\n",
      "train loss:0.9016000889728073\n",
      "train loss:0.8441951819877302\n",
      "train loss:0.9305042489225513\n",
      "train loss:1.0539379940551716\n",
      "train loss:0.9862152469881673\n",
      "train loss:0.9030822430656373\n",
      "train loss:0.8843170822788593\n",
      "train loss:0.9035518198303489\n",
      "train loss:0.9724961008246008\n",
      "train loss:0.7954427461037245\n",
      "train loss:0.9660973298633874\n",
      "train loss:1.0106935326061626\n",
      "train loss:0.8826901487349488\n",
      "train loss:0.7896777072239394\n",
      "train loss:0.8243255863630553\n",
      "=== epoch:14, train acc:0.997, test acc:0.994 ===\n",
      "train loss:0.9543762807873535\n",
      "train loss:0.9818404020229505\n",
      "train loss:0.8992530276996336\n",
      "train loss:0.959523906307549\n",
      "train loss:0.8309855227921613\n",
      "train loss:0.8347832874494575\n",
      "train loss:0.8712183924955361\n",
      "train loss:0.9145719826339529\n",
      "train loss:0.8692650850210438\n",
      "train loss:0.9953772797809082\n",
      "train loss:1.0390298471495043\n",
      "train loss:0.7922092705344216\n",
      "train loss:0.992481132126696\n",
      "train loss:0.8137149025550915\n",
      "train loss:0.9190446647876902\n",
      "train loss:0.8988897342827596\n",
      "train loss:1.0355846818354282\n",
      "train loss:0.9074610805455037\n",
      "train loss:0.9089742231659631\n",
      "train loss:0.8036494987905526\n",
      "train loss:0.7247423826869859\n",
      "train loss:0.8609315844367057\n",
      "train loss:0.8354486391753091\n",
      "train loss:0.8590524924340142\n",
      "train loss:0.8058223444641502\n",
      "train loss:0.8613369563031192\n",
      "train loss:0.869124985521885\n",
      "train loss:0.9090330933065625\n",
      "train loss:0.7622396652436152\n",
      "train loss:0.749177716755346\n",
      "train loss:1.0250618050918254\n",
      "train loss:0.9065086773213821\n",
      "train loss:0.8011884339936687\n",
      "train loss:0.8397750629622243\n",
      "train loss:0.9045765237679414\n",
      "train loss:0.8710020783931334\n",
      "train loss:0.8091288637008712\n",
      "train loss:0.8063913019904458\n",
      "train loss:0.967982197618382\n",
      "train loss:0.9977021426713037\n",
      "train loss:0.7435981653952362\n",
      "train loss:0.9626917962278283\n",
      "train loss:0.8302861567737523\n",
      "train loss:0.9859981794613994\n",
      "train loss:0.8263666717598135\n",
      "train loss:0.9440146628281046\n",
      "train loss:0.9523573668267497\n",
      "train loss:0.9244158720903493\n",
      "train loss:0.9324732775892491\n",
      "train loss:0.943840124259419\n",
      "train loss:0.8449293051550931\n",
      "train loss:0.9189101247535038\n",
      "train loss:0.8182974098802966\n",
      "train loss:1.0811626709330922\n",
      "train loss:0.8139483560673483\n",
      "train loss:0.8590139622537148\n",
      "train loss:0.8034478782893336\n",
      "train loss:0.8194370082433621\n",
      "train loss:0.9342777609604943\n",
      "train loss:0.8479696334561985\n",
      "train loss:0.744309530488327\n",
      "train loss:0.8552959591568513\n",
      "train loss:0.7693776502457839\n",
      "train loss:0.9550341549761271\n",
      "train loss:0.864401877651502\n",
      "train loss:0.9447586969948449\n",
      "train loss:0.9281641361670058\n",
      "train loss:0.8081674707962924\n",
      "train loss:0.6872447997787217\n",
      "train loss:0.9741200627601464\n",
      "train loss:0.9483479887119622\n",
      "train loss:0.8109783769198811\n",
      "train loss:0.746506529500838\n",
      "train loss:0.9593225311210347\n",
      "train loss:0.8646053784033176\n",
      "train loss:0.6385737760514413\n",
      "train loss:0.8663331893389004\n",
      "train loss:0.8538222564873104\n",
      "train loss:0.8720676927727709\n",
      "train loss:0.8746894132915632\n",
      "train loss:0.8076054566205473\n",
      "train loss:0.9339076467578568\n",
      "train loss:0.954133994821028\n",
      "train loss:0.8140435517009575\n",
      "train loss:0.8485463693459587\n",
      "train loss:0.828691958509784\n",
      "train loss:0.8548769956892164\n",
      "train loss:1.054263273572609\n",
      "train loss:0.9046549607862793\n",
      "train loss:1.0059034847704498\n",
      "train loss:0.8589305771269028\n",
      "train loss:0.7458935269436527\n",
      "train loss:0.8554838153898041\n",
      "train loss:0.9127598671332753\n",
      "train loss:0.812338993083862\n",
      "train loss:0.7900670634997075\n",
      "train loss:0.7697206635701589\n",
      "train loss:0.8714531264353153\n",
      "train loss:1.007233050044432\n",
      "train loss:0.9823804704774456\n",
      "train loss:0.8944192737651626\n",
      "train loss:0.9722929965857716\n",
      "train loss:0.7039503699351104\n",
      "train loss:0.7976458149621162\n",
      "train loss:0.9536906991232779\n",
      "train loss:0.9708133377531248\n",
      "train loss:0.8234000190705612\n",
      "train loss:0.8603313216355365\n",
      "train loss:0.7426377556258978\n",
      "train loss:0.9881650573079439\n",
      "train loss:0.9060068399354877\n",
      "train loss:0.8370313078760832\n",
      "train loss:0.8595395252176522\n",
      "train loss:0.8037612539348796\n",
      "train loss:0.8646794436696342\n",
      "train loss:1.0184091249511829\n",
      "train loss:0.837330492177037\n",
      "train loss:0.8713237391443246\n",
      "train loss:0.6260977988405761\n",
      "train loss:0.8210567605540686\n",
      "train loss:0.8671255165949426\n",
      "train loss:0.9358067253608792\n",
      "train loss:0.8682600194750064\n",
      "train loss:1.0062726283499608\n",
      "train loss:0.9056585377911496\n",
      "train loss:0.930017453479929\n",
      "train loss:0.8722250552998981\n",
      "train loss:0.9593599825544206\n",
      "train loss:0.8691916411956909\n",
      "train loss:0.8507383262064525\n",
      "train loss:0.8879235494443958\n",
      "train loss:0.8673596530985915\n",
      "train loss:0.9548624526904461\n",
      "train loss:0.8220182325958949\n",
      "train loss:0.9929204615347967\n",
      "train loss:0.8351316021875123\n",
      "train loss:0.8883112487797763\n",
      "train loss:0.8660847106841785\n",
      "train loss:0.9180760898076603\n",
      "train loss:0.9613591718037574\n",
      "train loss:0.8483850770013498\n",
      "train loss:0.8304997090199164\n",
      "train loss:0.8243081005425696\n",
      "train loss:0.978712945566447\n",
      "train loss:0.6305021829750239\n",
      "train loss:0.858083371709729\n",
      "train loss:0.7302682660398732\n",
      "train loss:0.8289418341219833\n",
      "train loss:0.8315933901705778\n",
      "train loss:0.8407063110947057\n",
      "train loss:0.8438995822651685\n",
      "train loss:0.760668797188703\n",
      "train loss:0.8904133695039695\n",
      "train loss:0.8442848838500321\n",
      "train loss:0.7026276282312238\n",
      "train loss:0.765101246086817\n",
      "train loss:0.7845622598650728\n",
      "train loss:0.887936469884473\n",
      "train loss:0.7958561265126676\n",
      "train loss:0.8225588256501358\n",
      "train loss:0.9088066940612011\n",
      "train loss:0.8503836201118153\n",
      "train loss:0.6536724688526089\n",
      "train loss:0.7238835264313392\n",
      "train loss:0.836140705863533\n",
      "train loss:0.7623582785830472\n",
      "train loss:0.8228900503032012\n",
      "train loss:0.922722578211324\n",
      "train loss:0.7038976134222733\n",
      "train loss:0.9411433661769497\n",
      "train loss:0.8683573383738538\n",
      "train loss:0.7257102313570521\n",
      "train loss:0.8052043330096142\n",
      "train loss:0.7273636022557488\n",
      "train loss:0.8778234220151557\n",
      "train loss:0.8471291292767724\n",
      "train loss:0.7645601749512909\n",
      "train loss:0.9527266286746827\n",
      "train loss:0.8210133155683631\n",
      "train loss:0.813417372429827\n",
      "train loss:0.8731856126098774\n",
      "train loss:0.991063087824091\n",
      "train loss:0.9977207598413987\n",
      "train loss:0.8895535726533247\n",
      "train loss:0.9269146256644258\n",
      "train loss:0.9058439746875218\n",
      "train loss:0.8630759947153217\n",
      "train loss:0.8703029160446684\n",
      "train loss:1.0244662376018518\n",
      "train loss:0.8175244782960182\n",
      "train loss:0.9273324782532487\n",
      "train loss:0.6964933500677758\n",
      "train loss:0.6838818608529283\n",
      "train loss:0.8091350060217721\n",
      "train loss:0.8075431741739689\n",
      "train loss:0.9205599082206491\n",
      "train loss:0.8624748112508097\n",
      "train loss:0.8080989914721803\n",
      "train loss:0.7997770950630657\n",
      "train loss:0.817613599328581\n",
      "train loss:1.0514191023603898\n",
      "train loss:0.8629410752996667\n",
      "train loss:0.8938607689840561\n",
      "train loss:0.9339200051078106\n",
      "train loss:1.0220180177145257\n",
      "train loss:0.787987969997671\n",
      "train loss:0.9065993273923432\n",
      "train loss:0.849168963679904\n",
      "train loss:0.8868289380940061\n",
      "train loss:0.9390475573827745\n",
      "train loss:0.8886498410445389\n",
      "train loss:0.7624908078787265\n",
      "train loss:0.9202471489724878\n",
      "train loss:0.9603098543788944\n",
      "train loss:0.7945737865130877\n",
      "train loss:0.9213191176698315\n",
      "train loss:0.8270617584195219\n",
      "train loss:0.8374914515705558\n",
      "train loss:0.8165427202275414\n",
      "train loss:0.8690377904280456\n",
      "train loss:0.7145366994848102\n",
      "train loss:0.8689156521793459\n",
      "train loss:0.7991085699287572\n",
      "train loss:1.0145816294227346\n",
      "train loss:0.79442281335235\n",
      "train loss:0.8512993008061823\n",
      "train loss:0.8435554267541933\n",
      "train loss:0.799428881396165\n",
      "train loss:0.8650082249635922\n",
      "train loss:0.8068251822073552\n",
      "train loss:0.8811616883914917\n",
      "train loss:0.8515205204434372\n",
      "train loss:0.8971469823738109\n",
      "train loss:0.8672321514156891\n",
      "train loss:0.8201752360750645\n",
      "train loss:0.8182030504671417\n",
      "train loss:1.0101783340464054\n",
      "train loss:0.9183650189231937\n",
      "train loss:0.7070419202800392\n",
      "train loss:0.7906948670641825\n",
      "train loss:0.870621124503443\n",
      "train loss:0.8880651558427926\n",
      "train loss:0.9541658871033922\n",
      "train loss:0.9215955254405306\n",
      "train loss:0.8027106924697172\n",
      "train loss:0.9864231151763826\n",
      "train loss:0.8835488262422808\n",
      "train loss:0.8792603704618126\n",
      "train loss:0.8560030093604414\n",
      "train loss:0.9476180153528623\n",
      "train loss:0.7881830607222091\n",
      "train loss:0.9494899563075236\n",
      "train loss:1.0174181445739074\n",
      "train loss:0.6809308710045365\n",
      "train loss:0.8778477623631105\n",
      "train loss:0.8492994156771918\n",
      "train loss:0.8693491867101408\n",
      "train loss:0.8756093972488932\n",
      "train loss:0.8382356055926112\n",
      "train loss:0.9287241988533042\n",
      "train loss:0.9242160756083554\n",
      "train loss:0.9589327256715059\n",
      "train loss:0.7181028158049381\n",
      "train loss:0.9002244023336327\n",
      "train loss:0.7918980853250376\n",
      "train loss:0.9367389420101939\n",
      "train loss:0.8662463961303334\n",
      "train loss:0.8108902476643111\n",
      "train loss:0.9858268642260901\n",
      "train loss:0.6611050520741543\n",
      "train loss:0.7626427691822325\n",
      "train loss:0.757521340336699\n",
      "train loss:0.8141549485985411\n",
      "train loss:0.8661620543920328\n",
      "train loss:0.8317200205275229\n",
      "train loss:0.9741238410710134\n",
      "train loss:0.6724645540182679\n",
      "train loss:0.8856751244549703\n",
      "train loss:1.082449735152711\n",
      "train loss:0.683630694825437\n",
      "train loss:0.7932718028803301\n",
      "train loss:0.9476654381706269\n",
      "train loss:0.7471640634854246\n",
      "train loss:1.005926777104638\n",
      "train loss:0.8367762746016217\n",
      "train loss:0.9546867108636483\n",
      "train loss:0.8208438873936728\n",
      "train loss:0.9593709541307132\n",
      "train loss:0.9825886022932535\n",
      "train loss:0.7633949681286661\n",
      "train loss:0.7188320582551665\n",
      "train loss:0.7853327224546186\n",
      "train loss:0.7995061514548598\n",
      "train loss:0.7517483998403598\n",
      "train loss:0.9283783116319647\n",
      "train loss:0.762784601014349\n",
      "train loss:0.8072573868557407\n",
      "train loss:0.9022901893666707\n",
      "train loss:1.0027493080319736\n",
      "train loss:0.8506356132259052\n",
      "train loss:0.9298199040616723\n",
      "train loss:0.7837962933767806\n",
      "train loss:0.9381053417753041\n",
      "train loss:0.7915731440841877\n",
      "train loss:0.9374272548658975\n",
      "train loss:0.7923122939291994\n",
      "train loss:0.8356167037117591\n",
      "train loss:0.8525542833416938\n",
      "train loss:0.8901787767330773\n",
      "train loss:0.9134168233314561\n",
      "train loss:1.023803994528837\n",
      "train loss:0.8688924511053974\n",
      "train loss:0.8243961976065514\n",
      "train loss:0.8658603665194342\n",
      "train loss:0.8617931512175108\n",
      "train loss:0.7323064782638187\n",
      "train loss:0.934809738142448\n",
      "train loss:1.1347183477730456\n",
      "train loss:0.8060958400891934\n",
      "train loss:0.9517577763047217\n",
      "train loss:0.736370063963564\n",
      "train loss:0.8189400235658273\n",
      "train loss:0.5985093625088104\n",
      "train loss:0.9964907016615997\n",
      "train loss:0.8198492108523462\n",
      "train loss:0.7783169953877348\n",
      "train loss:0.9197094717808088\n",
      "train loss:0.8199316044392647\n",
      "train loss:0.8882988106856894\n",
      "train loss:1.0210304595252027\n",
      "train loss:0.8731869147297739\n",
      "train loss:0.7202147818191849\n",
      "train loss:0.7981929145353894\n",
      "train loss:0.784340614788649\n",
      "train loss:0.9319271923932554\n",
      "train loss:0.8111679650272466\n",
      "train loss:0.9151700719975372\n",
      "train loss:0.7696213623251213\n",
      "train loss:0.8166564740632952\n",
      "train loss:0.8952358794863358\n",
      "train loss:0.9219083614460297\n",
      "train loss:0.7604147212110993\n",
      "train loss:0.8689028841492304\n",
      "train loss:0.8668421568412634\n",
      "train loss:0.7851950225943835\n",
      "train loss:0.9503111435325075\n",
      "train loss:0.8617231767569202\n",
      "train loss:0.8871774457657877\n",
      "train loss:0.8523221446835219\n",
      "train loss:0.8606285029566939\n",
      "train loss:0.9159112185689202\n",
      "train loss:0.7717306489824247\n",
      "train loss:0.8724300339936265\n",
      "train loss:1.0087938800010618\n",
      "train loss:0.8963078825092243\n",
      "train loss:1.0437370254605451\n",
      "train loss:0.8108811561853153\n",
      "train loss:0.867756398052911\n",
      "train loss:0.8875393813888917\n",
      "train loss:0.8463379929019943\n",
      "train loss:0.851009067076879\n",
      "train loss:0.8035505689836611\n",
      "train loss:0.8891744284145925\n",
      "train loss:0.8654370630622377\n",
      "train loss:0.8431345276443872\n",
      "train loss:0.8459881955357754\n",
      "train loss:0.746251902067783\n",
      "train loss:0.8772965783115092\n",
      "train loss:0.7309616755334595\n",
      "train loss:1.0035982297229158\n",
      "train loss:0.9279208266159463\n",
      "train loss:0.8491109386228106\n",
      "train loss:0.8661263149075412\n",
      "train loss:0.7647756241061989\n",
      "train loss:0.825822708892309\n",
      "train loss:1.0307319262432744\n",
      "train loss:1.011964837482775\n",
      "train loss:0.8245786387202546\n",
      "train loss:0.603892564373576\n",
      "train loss:0.7389741436633259\n",
      "train loss:0.840076901296901\n",
      "train loss:1.012159010385045\n",
      "train loss:0.8884928762434575\n",
      "train loss:0.8774978483097712\n",
      "train loss:0.833733977990357\n",
      "train loss:0.6642590553231166\n",
      "train loss:0.7168255136194523\n",
      "train loss:0.9262548080483123\n",
      "train loss:0.8137491089094313\n",
      "train loss:0.866472065016068\n",
      "train loss:0.8913954458872115\n",
      "train loss:0.912427603213768\n",
      "train loss:0.8641942673020486\n",
      "train loss:0.7471070793596829\n",
      "train loss:0.8881761031582437\n",
      "train loss:1.0077398088008365\n",
      "train loss:0.7744198746440868\n",
      "train loss:0.830383642214018\n",
      "train loss:1.0016959809474366\n",
      "train loss:1.0615201731823065\n",
      "train loss:0.7890775906953251\n",
      "train loss:1.0228508734381871\n",
      "train loss:0.9331143637273103\n",
      "train loss:0.7439770935090882\n",
      "train loss:0.8360470639184253\n",
      "train loss:0.9118724682949743\n",
      "train loss:0.9228085098725693\n",
      "train loss:0.6980482182839062\n",
      "train loss:0.9484533241651105\n",
      "train loss:1.120813816493667\n",
      "train loss:0.9230698328606181\n",
      "train loss:0.8419050641595054\n",
      "train loss:0.8036327807255096\n",
      "train loss:1.0566568301244048\n",
      "train loss:0.8772318137541215\n",
      "train loss:0.9667469960384966\n",
      "train loss:0.8760856841449942\n",
      "train loss:0.9020835581631559\n",
      "train loss:0.8760205524906847\n",
      "train loss:0.8076256733500705\n",
      "train loss:0.8621621573426491\n",
      "train loss:0.8019145973558176\n",
      "train loss:0.735468230464879\n",
      "train loss:0.7646483908889375\n",
      "train loss:0.8565054989628392\n",
      "train loss:0.8921103932112857\n",
      "train loss:0.792864500963342\n",
      "train loss:0.828805821113048\n",
      "train loss:0.9128604567987479\n",
      "train loss:0.9984919787206601\n",
      "train loss:0.6418009859553936\n",
      "train loss:0.9495993354854565\n",
      "train loss:0.8398954603163012\n",
      "train loss:0.8879744608285047\n",
      "train loss:0.932925622384719\n",
      "train loss:0.8269057152602506\n",
      "train loss:0.9048725723801972\n",
      "train loss:0.9128843342457319\n",
      "train loss:0.666095442762849\n",
      "train loss:0.8851679041585031\n",
      "train loss:1.0240049680915093\n",
      "train loss:0.9081182082429009\n",
      "train loss:1.0225926073212597\n",
      "train loss:1.0555895783726692\n",
      "train loss:0.7163875730327273\n",
      "train loss:0.8774814631899721\n",
      "train loss:0.8729702674712275\n",
      "train loss:0.7421407973754817\n",
      "train loss:0.7613690069641272\n",
      "train loss:0.8393187882295265\n",
      "train loss:0.8760515281586756\n",
      "train loss:0.7419237935276871\n",
      "train loss:0.9334508874209115\n",
      "train loss:0.7858531255249847\n",
      "train loss:1.0402046060113\n",
      "train loss:0.8464485633726357\n",
      "train loss:0.834199220844203\n",
      "train loss:0.8496950575210757\n",
      "train loss:0.8374611045829704\n",
      "train loss:0.9366482444610225\n",
      "train loss:0.739500029395251\n",
      "train loss:0.9577576578944867\n",
      "train loss:0.7646403674746911\n",
      "train loss:0.8133134375365885\n",
      "train loss:0.7770235604477594\n",
      "train loss:0.7057004151457825\n",
      "train loss:0.8541424396095109\n",
      "train loss:0.7594020429221153\n",
      "train loss:0.7852105509940357\n",
      "train loss:0.7606590669386081\n",
      "train loss:0.825292194864306\n",
      "train loss:0.9452350746715382\n",
      "train loss:0.8348011980737823\n",
      "train loss:0.7468326770150271\n",
      "train loss:0.7016797982162334\n",
      "train loss:0.6487452796306559\n",
      "train loss:0.9244805274904532\n",
      "train loss:0.9407839060091266\n",
      "train loss:0.9429409768471203\n",
      "train loss:0.8693139575805832\n",
      "train loss:0.8756624958160476\n",
      "train loss:0.9120828100040492\n",
      "train loss:0.6889255155906905\n",
      "train loss:0.9076239998143376\n",
      "train loss:0.9495108986709141\n",
      "train loss:0.8406515559921128\n",
      "train loss:0.9070166340129987\n",
      "train loss:0.8864462283757688\n",
      "train loss:0.9422407795635627\n",
      "train loss:1.0229546153372775\n",
      "train loss:0.8467548550683089\n",
      "train loss:0.8646420227057336\n",
      "train loss:0.9540755772948387\n",
      "train loss:1.0473691903455513\n",
      "train loss:0.996054387643642\n",
      "train loss:0.7552224295856207\n",
      "train loss:0.7962646053349844\n",
      "train loss:0.8808145508914645\n",
      "train loss:0.8924393969865706\n",
      "train loss:0.9418583875455967\n",
      "train loss:0.8417890512701857\n",
      "train loss:0.8028581897270918\n",
      "train loss:1.05034084897306\n",
      "train loss:0.87372618547055\n",
      "train loss:0.857820655837125\n",
      "train loss:0.8961888201196763\n",
      "train loss:0.7685959558628904\n",
      "train loss:0.8976281854883205\n",
      "train loss:0.6899187570060202\n",
      "train loss:0.8819119740002871\n",
      "train loss:0.9260783692672618\n",
      "train loss:0.8668412742529799\n",
      "train loss:1.116389307451631\n",
      "train loss:0.7989652689370527\n",
      "train loss:0.9097018475833031\n",
      "train loss:0.9195750059706453\n",
      "train loss:0.8472650765277041\n",
      "train loss:0.7197565880636044\n",
      "train loss:0.9509617097448796\n",
      "train loss:1.0077748261244495\n",
      "train loss:0.8389911505668658\n",
      "train loss:0.8592915786543298\n",
      "train loss:0.8100666846619927\n",
      "train loss:0.9353689536861826\n",
      "train loss:0.8793091610059913\n",
      "train loss:0.8130282296986286\n",
      "train loss:0.8203020753389031\n",
      "train loss:0.7194560152165197\n",
      "train loss:0.8173513369952623\n",
      "train loss:0.9452009994341672\n",
      "train loss:0.8744447566840191\n",
      "train loss:0.9104264173306462\n",
      "train loss:0.8988355732726976\n",
      "train loss:0.8817806942591533\n",
      "train loss:0.7005952228350536\n",
      "train loss:0.7348385269733132\n",
      "train loss:0.9156229005784425\n",
      "train loss:0.9472704435735411\n",
      "train loss:0.9184237595109908\n",
      "train loss:0.8377614812598222\n",
      "train loss:0.9439580397086113\n",
      "train loss:0.7907954434643021\n",
      "train loss:0.8225845919797464\n",
      "train loss:0.8529347121323572\n",
      "train loss:0.962448524527581\n",
      "train loss:0.9159823820250917\n",
      "train loss:0.7971669440394307\n",
      "train loss:1.0667840479935067\n",
      "train loss:0.8632240666355971\n",
      "train loss:1.0120163591761098\n",
      "train loss:0.8776812897922167\n",
      "train loss:0.759604058270553\n",
      "train loss:0.7527503060801688\n",
      "train loss:0.833320092921872\n",
      "train loss:0.7896699292569465\n",
      "train loss:0.7787008087026875\n",
      "train loss:0.8318319620067962\n",
      "train loss:0.9613578269546198\n",
      "train loss:0.9741280632568095\n",
      "train loss:0.8472949022903076\n",
      "train loss:0.6714803016318427\n",
      "train loss:0.8051628920310135\n",
      "train loss:0.898208747372345\n",
      "train loss:0.8681402752253401\n",
      "train loss:0.9423543097528052\n",
      "train loss:0.7309522157398669\n",
      "train loss:0.9721447861904291\n",
      "train loss:0.8593470174809508\n",
      "train loss:0.9372523776455195\n",
      "train loss:0.9314074302791951\n",
      "train loss:0.8658762274864561\n",
      "train loss:0.8017352145556593\n",
      "train loss:0.8717623350755881\n",
      "train loss:0.9559792246192059\n",
      "train loss:0.6826353483612781\n",
      "train loss:0.8285165551969453\n",
      "train loss:0.8552572524530672\n",
      "train loss:0.9211594462855058\n",
      "train loss:0.9362711302625012\n",
      "train loss:0.7419618833150184\n",
      "train loss:0.8605848100124092\n",
      "train loss:0.9242805262699314\n",
      "train loss:0.7515906508168322\n",
      "train loss:0.923531938095966\n",
      "train loss:0.898813184846839\n",
      "train loss:0.8635326300061776\n",
      "train loss:0.7876963995571054\n",
      "train loss:0.927328721230284\n",
      "train loss:0.8628363618805202\n",
      "train loss:0.83575234772895\n",
      "train loss:0.7062341485067918\n",
      "train loss:0.9425583093589103\n",
      "train loss:0.7601338304705876\n",
      "train loss:0.8620786221702434\n",
      "train loss:0.6254522169328742\n",
      "train loss:0.845536639226824\n",
      "train loss:0.8482734712153566\n",
      "train loss:0.9591750879560677\n",
      "train loss:0.9131129516787037\n",
      "train loss:0.87220411101607\n",
      "=== epoch:15, train acc:0.998, test acc:0.994 ===\n",
      "train loss:0.8079452724997571\n",
      "train loss:0.8691565186032577\n",
      "train loss:0.7646453322815355\n",
      "train loss:0.8091461389356632\n",
      "train loss:0.9655928266649889\n",
      "train loss:0.7384552125297762\n",
      "train loss:0.8796427321343616\n",
      "train loss:0.8769341586082728\n",
      "train loss:0.9045099758460444\n",
      "train loss:0.9658492320322157\n",
      "train loss:0.8847286745194916\n",
      "train loss:0.8792133074266055\n",
      "train loss:0.6868521848525198\n",
      "train loss:0.7753841430435997\n",
      "train loss:0.9554903887257642\n",
      "train loss:0.7430104806572422\n",
      "train loss:0.96116428525163\n",
      "train loss:0.7845076050817471\n",
      "train loss:0.8775518083692421\n",
      "train loss:0.7171739246202334\n",
      "train loss:0.855814232843785\n",
      "train loss:0.8724865126752677\n",
      "train loss:0.7751308282199415\n",
      "train loss:0.8535606873649441\n",
      "train loss:0.8423055729115115\n",
      "train loss:0.8797420152305709\n",
      "train loss:0.849453737848156\n",
      "train loss:0.9396994856491374\n",
      "train loss:0.9418615040381542\n",
      "train loss:0.8555943009823941\n",
      "train loss:1.0182845876310997\n",
      "train loss:0.7403137971817573\n",
      "train loss:0.991615137674009\n",
      "train loss:0.9509186489621905\n",
      "train loss:0.7769676450468004\n",
      "train loss:0.9229355895501776\n",
      "train loss:0.8418039866059249\n",
      "train loss:1.0800505165628946\n",
      "train loss:0.7481426836775945\n",
      "train loss:0.8557587835860733\n",
      "train loss:0.6247015504097889\n",
      "train loss:0.8651921248443577\n",
      "train loss:0.7747650388422437\n",
      "train loss:0.6332958612182326\n",
      "train loss:0.8493907086500411\n",
      "train loss:0.9634571563192312\n",
      "train loss:0.7888417655006724\n",
      "train loss:0.757559069549547\n",
      "train loss:0.7787173798294507\n",
      "train loss:0.7866400366037861\n",
      "train loss:0.7644638635936567\n",
      "train loss:0.7047860736120394\n",
      "train loss:0.9053378371353037\n",
      "train loss:1.0327991910120318\n",
      "train loss:0.7095207864013635\n",
      "train loss:0.8451557859558839\n",
      "train loss:0.7796484961869281\n",
      "train loss:0.7028221470671104\n",
      "train loss:0.9380960912800792\n",
      "train loss:0.77202713955457\n",
      "train loss:0.8011768905994132\n",
      "train loss:0.952561262752525\n",
      "train loss:0.9587985257628651\n",
      "train loss:0.7789706882659488\n",
      "train loss:0.9524529760776486\n",
      "train loss:0.7058411744884071\n",
      "train loss:0.9118228727558763\n",
      "train loss:0.8074784803156124\n",
      "train loss:0.8888037845864676\n",
      "train loss:0.8336084489363182\n",
      "train loss:0.6635448005453013\n",
      "train loss:0.9428022511235885\n",
      "train loss:0.8124137550856217\n",
      "train loss:0.929954571077204\n",
      "train loss:0.7871376405836428\n",
      "train loss:0.9685758652892962\n",
      "train loss:0.956126095535108\n",
      "train loss:0.7041792579161406\n",
      "train loss:0.878145606617197\n",
      "train loss:0.9390848114237825\n",
      "train loss:0.8845434805368234\n",
      "train loss:0.779887063153809\n",
      "train loss:0.8237015863178502\n",
      "train loss:0.8415170093740038\n",
      "train loss:0.87539223089535\n",
      "train loss:0.8137624212905878\n",
      "train loss:0.8625206573253208\n",
      "train loss:0.8471451862698894\n",
      "train loss:0.9391486968109575\n",
      "train loss:0.8391590999963623\n",
      "train loss:0.8689027643882931\n",
      "train loss:0.8477343938618529\n",
      "train loss:0.8672497751264652\n",
      "train loss:0.9570628459451155\n",
      "train loss:0.7457163075011273\n",
      "train loss:1.0245513582935488\n",
      "train loss:0.8020190795600831\n",
      "train loss:0.8439604622932851\n",
      "train loss:0.8575404936760707\n",
      "train loss:0.8691889630968903\n",
      "train loss:0.8152381981394902\n",
      "train loss:1.0305110942472115\n",
      "train loss:0.9064759516442495\n",
      "train loss:0.8054969355277325\n",
      "train loss:0.7530333856494856\n",
      "train loss:0.9351721833831174\n",
      "train loss:0.9080547726331996\n",
      "train loss:0.7170801196213559\n",
      "train loss:0.8823204005841977\n",
      "train loss:0.7050753227097519\n",
      "train loss:0.8401386614074622\n",
      "train loss:1.0717631006773347\n",
      "train loss:0.9352872015817016\n",
      "train loss:0.9229609510428931\n",
      "train loss:0.9275311305757622\n",
      "train loss:0.8468607868450974\n",
      "train loss:0.8742987102869845\n",
      "train loss:0.8787596838292722\n",
      "train loss:0.7688433511356552\n",
      "train loss:0.7560649044840781\n",
      "train loss:0.964657399492461\n",
      "train loss:0.7829443751529875\n",
      "train loss:0.9438283791368198\n",
      "train loss:0.9754946657555018\n",
      "train loss:0.8651447011353764\n",
      "train loss:0.668375768069469\n",
      "train loss:0.882291000177614\n",
      "train loss:0.7980060635599533\n",
      "train loss:0.7787424858254388\n",
      "train loss:0.8768831304193941\n",
      "train loss:0.7682777663909646\n",
      "train loss:0.7261791669006736\n",
      "train loss:0.902049447440321\n",
      "train loss:0.8637359519326219\n",
      "train loss:0.6479087591569342\n",
      "train loss:0.7598250892574596\n",
      "train loss:0.7929580477801718\n",
      "train loss:0.9030409650397062\n",
      "train loss:0.9851904212924303\n",
      "train loss:0.9290477424418921\n",
      "train loss:0.8319955982928079\n",
      "train loss:0.8788637662124809\n",
      "train loss:0.9705601347074267\n",
      "train loss:0.8947563854928485\n",
      "train loss:0.9234974205994668\n",
      "train loss:1.0031689256332317\n",
      "train loss:0.7960422581631995\n",
      "train loss:0.9602352414443632\n",
      "train loss:0.7590791800233333\n",
      "train loss:0.7958278558666815\n",
      "train loss:0.8428957146006035\n",
      "train loss:0.8161221636741728\n",
      "train loss:0.9542067237889023\n",
      "train loss:0.9055249312210087\n",
      "train loss:0.7630407579065817\n",
      "train loss:1.0682919679776253\n",
      "train loss:0.8780521177584971\n",
      "train loss:0.8947728346594284\n",
      "train loss:1.124235999397343\n",
      "train loss:0.9510171837635575\n",
      "train loss:0.8285443106472508\n",
      "train loss:0.8079358283696452\n",
      "train loss:0.8442866373608199\n",
      "train loss:0.9638505765061147\n",
      "train loss:0.8713876827285683\n",
      "train loss:0.7467560862902982\n",
      "train loss:0.9902077888883397\n",
      "train loss:0.8043834902687736\n",
      "train loss:0.9270139348294668\n",
      "train loss:1.1350739762684308\n",
      "train loss:0.8298926824831659\n",
      "train loss:0.838449233267069\n",
      "train loss:0.8300388303930264\n",
      "train loss:0.9389148634010458\n",
      "train loss:0.9594501010945024\n",
      "train loss:0.9101016467602385\n",
      "train loss:1.0108220086609752\n",
      "train loss:0.9346399660440272\n",
      "train loss:0.8825685871012838\n",
      "train loss:0.8153283568515169\n",
      "train loss:0.8148414605592889\n",
      "train loss:0.7973533270748713\n",
      "train loss:1.0776930135560903\n",
      "train loss:0.7968796163967161\n",
      "train loss:0.9215081509563686\n",
      "train loss:0.9901377651189337\n",
      "train loss:0.9309863267450571\n",
      "train loss:0.7736442468260505\n",
      "train loss:1.0046981913941515\n",
      "train loss:0.9231532990909834\n",
      "train loss:0.9590622275587958\n",
      "train loss:1.0463993234259517\n",
      "train loss:0.7960007553651064\n",
      "train loss:0.9353488384524832\n",
      "train loss:0.930411193912762\n",
      "train loss:0.8649119463689897\n",
      "train loss:0.75821137128686\n",
      "train loss:0.9238263209124541\n",
      "train loss:0.8501220949565517\n",
      "train loss:0.9477942030206736\n",
      "train loss:0.9361903222472752\n",
      "train loss:0.9519821490062526\n",
      "train loss:0.6366988682161377\n",
      "train loss:0.9064766018175079\n",
      "train loss:0.8738279960698818\n",
      "train loss:0.9079200760107381\n",
      "train loss:0.8194962280600214\n",
      "train loss:0.8103394011554477\n",
      "train loss:0.8099398518396136\n",
      "train loss:0.8874015606948388\n",
      "train loss:0.8814469068330029\n",
      "train loss:0.780823408458003\n",
      "train loss:0.8832805182459681\n",
      "train loss:0.960354689650636\n",
      "train loss:0.8081804826210246\n",
      "train loss:0.806706433975715\n",
      "train loss:0.9557395048858284\n",
      "train loss:0.8254532677509522\n",
      "train loss:1.0252116617010218\n",
      "train loss:0.8058256119839458\n",
      "train loss:0.9787776021087443\n",
      "train loss:0.8460526433872059\n",
      "train loss:0.7610793995877125\n",
      "train loss:0.8189554741487471\n",
      "train loss:0.924006258718025\n",
      "train loss:0.9180185815508337\n",
      "train loss:0.709872479790205\n",
      "train loss:0.7077187587448139\n",
      "train loss:0.6604967125946254\n",
      "train loss:0.9543782768128007\n",
      "train loss:0.8933507765518626\n",
      "train loss:0.94746458131829\n",
      "train loss:0.7106729856586016\n",
      "train loss:0.766809140234296\n",
      "train loss:0.8529429379633884\n",
      "train loss:0.9869996689976486\n",
      "train loss:0.9354798077350153\n",
      "train loss:0.6802900167772795\n",
      "train loss:0.6817036285394422\n",
      "train loss:0.9376406716172216\n",
      "train loss:0.7601086699014232\n",
      "train loss:0.9125051114643767\n",
      "train loss:0.8546143844388354\n",
      "train loss:0.9240386323513318\n",
      "train loss:0.7629617592791393\n",
      "train loss:0.8141360855014648\n",
      "train loss:0.9799297660545566\n",
      "train loss:0.9107959902926084\n",
      "train loss:0.8796775976288491\n",
      "train loss:0.9374859789333746\n",
      "train loss:0.9400267410036652\n",
      "train loss:0.7814710430917424\n",
      "train loss:0.9466294774714191\n",
      "train loss:0.8385464581088082\n",
      "train loss:0.7837629881272684\n",
      "train loss:0.8551914552898827\n",
      "train loss:0.8269674856066572\n",
      "train loss:0.7762612589771531\n",
      "train loss:0.7889901916391954\n",
      "train loss:1.022263657195743\n",
      "train loss:0.8157947068184903\n",
      "train loss:0.807300672044228\n",
      "train loss:0.937771673657209\n",
      "train loss:1.107580060863186\n",
      "train loss:0.9516519832385155\n",
      "train loss:1.0957731733001455\n",
      "train loss:0.8172976947985311\n",
      "train loss:0.8917053682466936\n",
      "train loss:0.8051700785404418\n",
      "train loss:0.900682845664616\n",
      "train loss:0.8410583620080619\n",
      "train loss:1.1110920376145814\n",
      "train loss:0.8061815212435719\n",
      "train loss:0.8606043930132937\n",
      "train loss:0.7618008001558272\n",
      "train loss:0.9527645995610163\n",
      "train loss:0.8255735606613176\n",
      "train loss:0.9407943094805727\n",
      "train loss:0.8181485522086912\n",
      "train loss:1.0599973877205857\n",
      "train loss:0.8852791676996055\n",
      "train loss:0.8201237903168068\n",
      "train loss:0.9591889667478272\n",
      "train loss:0.7793666258444334\n",
      "train loss:1.0018995805477322\n",
      "train loss:0.9596167207350925\n",
      "train loss:0.8758211157421689\n",
      "train loss:0.9155364432608448\n",
      "train loss:0.9305536997267866\n",
      "train loss:0.7308335737672667\n",
      "train loss:0.961109707373811\n",
      "train loss:1.042170352038132\n",
      "train loss:0.8230650829889966\n",
      "train loss:0.9168715725131966\n",
      "train loss:0.8165042370285986\n",
      "train loss:0.8776638013020527\n",
      "train loss:0.8153187399161824\n",
      "train loss:0.98888915257006\n",
      "train loss:0.9219627432239388\n",
      "train loss:0.7157959982121942\n",
      "train loss:0.698589347347852\n",
      "train loss:0.7838221790909111\n",
      "train loss:0.895143532556465\n",
      "train loss:0.8898876684624057\n",
      "train loss:0.9671513354990708\n",
      "train loss:0.7819081789714548\n",
      "train loss:0.7678753531281259\n",
      "train loss:0.7369674050738074\n",
      "train loss:0.890739212667438\n",
      "train loss:0.9702109310335625\n",
      "train loss:0.7397127025003593\n",
      "train loss:0.8709202056973457\n",
      "train loss:0.8481590137092675\n",
      "train loss:0.9181061277648135\n",
      "train loss:0.7890335564380293\n",
      "train loss:0.7382992218601698\n",
      "train loss:0.7922306209482478\n",
      "train loss:0.9559093113727641\n",
      "train loss:0.902145015208953\n",
      "train loss:0.7409044013793056\n",
      "train loss:0.9944604356043288\n",
      "train loss:0.8348103242391092\n",
      "train loss:0.6297771050440504\n",
      "train loss:0.9139650404712064\n",
      "train loss:0.9610204358119031\n",
      "train loss:0.654202334982014\n",
      "train loss:1.0276937450931865\n",
      "train loss:0.8464473490726001\n",
      "train loss:0.8731389383239001\n",
      "train loss:0.838589638842458\n",
      "train loss:1.0044818466440288\n",
      "train loss:1.0610784802410516\n",
      "train loss:0.928650696505088\n",
      "train loss:1.0103783801370232\n",
      "train loss:1.0290671388025323\n",
      "train loss:0.8877067906068844\n",
      "train loss:0.8002591995095274\n",
      "train loss:0.7105033722982239\n",
      "train loss:0.854713314797032\n",
      "train loss:0.8964493356044138\n",
      "train loss:0.9832542095314164\n",
      "train loss:0.8220890273632914\n",
      "train loss:0.8085726963020599\n",
      "train loss:0.9908990130023018\n",
      "train loss:1.0014306491111373\n",
      "train loss:0.7547657254671626\n",
      "train loss:0.8545917408903937\n",
      "train loss:1.0008258742597504\n",
      "train loss:0.8275100960673655\n",
      "train loss:0.7238440035850592\n",
      "train loss:0.7778304310432645\n",
      "train loss:0.8644784805617963\n",
      "train loss:0.9256238886394007\n",
      "train loss:0.8286910944864044\n",
      "train loss:0.8085461816048821\n",
      "train loss:0.807651505397033\n",
      "train loss:0.8481696206335577\n",
      "train loss:0.9450564112821707\n",
      "train loss:0.8917175316826844\n",
      "train loss:0.754422026277658\n",
      "train loss:0.8153453003121207\n",
      "train loss:0.7532736305310914\n",
      "train loss:0.712690825537861\n",
      "train loss:0.959290123259651\n",
      "train loss:1.042686286471634\n",
      "train loss:0.9317620005017395\n",
      "train loss:0.7625258641284794\n",
      "train loss:0.7844417088372826\n",
      "train loss:0.9527303522556552\n",
      "train loss:0.9443312723089673\n",
      "train loss:0.9169835787570577\n",
      "train loss:0.8682501777626905\n",
      "train loss:0.8693219957391437\n",
      "train loss:1.031056525534416\n",
      "train loss:0.7546356973467978\n",
      "train loss:0.9926718124981788\n",
      "train loss:0.8899769527773094\n",
      "train loss:0.8556457509513673\n",
      "train loss:0.8638000092362839\n",
      "train loss:0.8646331128513854\n",
      "train loss:0.9693022666129221\n",
      "train loss:0.8824090326849184\n",
      "train loss:0.8661526301199217\n",
      "train loss:0.9459491613722076\n",
      "train loss:0.9457631602599075\n",
      "train loss:0.813630371158396\n",
      "train loss:0.8800281854800189\n",
      "train loss:0.8945156163661159\n",
      "train loss:0.8363203687890975\n",
      "train loss:0.93438129836649\n",
      "train loss:0.9501059306276249\n",
      "train loss:0.9986092411805698\n",
      "train loss:0.837475096802004\n",
      "train loss:0.9600935000998025\n",
      "train loss:1.068751242233046\n",
      "train loss:0.8224345106025962\n",
      "train loss:0.8378131660063675\n",
      "train loss:0.8235073697886491\n",
      "train loss:0.8717649233196123\n",
      "train loss:0.8819447854902209\n",
      "train loss:0.8081562823429868\n",
      "train loss:0.9379301941860464\n",
      "train loss:1.0299142688669145\n",
      "train loss:0.5939576843548209\n",
      "train loss:0.9267517681035216\n",
      "train loss:0.9550322579700891\n",
      "train loss:0.7298994615448621\n",
      "train loss:0.8836002419804792\n",
      "train loss:0.8363107463597929\n",
      "train loss:0.9100390380477076\n",
      "train loss:0.9222374028545025\n",
      "train loss:0.8988185736102831\n",
      "train loss:0.8194372229906025\n",
      "train loss:0.7246320560484172\n",
      "train loss:0.7459464401330211\n",
      "train loss:0.8837412005111367\n",
      "train loss:0.8117499709311292\n",
      "train loss:0.8905104463097538\n",
      "train loss:0.8745547236492142\n",
      "train loss:0.981714517143627\n",
      "train loss:0.8352234608350906\n",
      "train loss:1.0022367427633727\n",
      "train loss:0.8991927741899967\n",
      "train loss:0.9034437523905728\n",
      "train loss:0.8930305612861089\n",
      "train loss:0.8230880732792589\n",
      "train loss:0.6833926041577256\n",
      "train loss:0.8568860025309927\n",
      "train loss:0.8164404664538342\n",
      "train loss:0.874328117861693\n",
      "train loss:0.7578707625481459\n",
      "train loss:0.8452780836427045\n",
      "train loss:0.6609156855664273\n",
      "train loss:0.8374707868963844\n",
      "train loss:0.85857669690913\n",
      "train loss:0.7768454358412362\n",
      "train loss:0.8651620767222693\n",
      "train loss:0.8135198660018068\n",
      "train loss:0.8369589189123429\n",
      "train loss:0.8260538784502763\n",
      "train loss:0.8906554091936316\n",
      "train loss:0.9301999960437864\n",
      "train loss:0.8775107154669315\n",
      "train loss:0.7893028095572557\n",
      "train loss:0.8646086012340972\n",
      "train loss:0.8424278273831662\n",
      "train loss:0.8127353291806405\n",
      "train loss:0.9717298405832838\n",
      "train loss:0.8383144006503013\n",
      "train loss:0.7009754516781049\n",
      "train loss:0.9155338989358874\n",
      "train loss:0.7806862392892205\n",
      "train loss:0.7530825196529437\n",
      "train loss:1.038016349628205\n",
      "train loss:0.8389063423843999\n",
      "train loss:0.9500949315731141\n",
      "train loss:0.9380381224644503\n",
      "train loss:1.028487371479525\n",
      "train loss:0.8643456359782636\n",
      "train loss:0.8476843925969283\n",
      "train loss:1.0165040564387606\n",
      "train loss:1.1250362165043761\n",
      "train loss:0.9719314607120674\n",
      "train loss:0.7897080942293371\n",
      "train loss:0.8059621063718716\n",
      "train loss:0.821540610955144\n",
      "train loss:0.6652653190668011\n",
      "train loss:0.8398614271448485\n",
      "train loss:0.6953423435085183\n",
      "train loss:0.8561443400706951\n",
      "train loss:0.8654708722253551\n",
      "train loss:0.9381377360075706\n",
      "train loss:0.8257716114750403\n",
      "train loss:0.738898826872527\n",
      "train loss:1.059059583774915\n",
      "train loss:0.9490875873787209\n",
      "train loss:0.823839380169425\n",
      "train loss:0.8330328937544813\n",
      "train loss:0.9523575063847827\n",
      "train loss:0.8785231648952722\n",
      "train loss:0.8882237879349821\n",
      "train loss:0.9384699554862749\n",
      "train loss:0.9438739816777338\n",
      "train loss:0.8367718138860322\n",
      "train loss:1.0293262575964846\n",
      "train loss:0.7965750851254235\n",
      "train loss:0.7439094454930674\n",
      "train loss:0.8432762132607319\n",
      "train loss:0.8582370679624285\n",
      "train loss:0.90287764167283\n",
      "train loss:0.692808495517761\n",
      "train loss:0.8745166403373577\n",
      "train loss:0.9096527436671145\n",
      "train loss:0.84396784852053\n",
      "train loss:0.881129752151913\n",
      "train loss:0.9526999735550943\n",
      "train loss:0.7925015655429655\n",
      "train loss:0.8226122561607958\n",
      "train loss:0.7997507928838009\n",
      "train loss:0.7557600569498574\n",
      "train loss:0.8201050813082378\n",
      "train loss:0.8920758337356348\n",
      "train loss:0.7511846750158255\n",
      "train loss:1.0042914890584023\n",
      "train loss:0.8964760734800582\n",
      "train loss:0.7991895089602266\n",
      "train loss:0.8331259569506991\n",
      "train loss:0.8400207723174168\n",
      "train loss:0.8621364844676047\n",
      "train loss:0.7041701090693349\n",
      "train loss:0.9453308660112957\n",
      "train loss:0.8944606387400651\n",
      "train loss:0.8667039878519399\n",
      "train loss:0.6063786768564092\n",
      "train loss:0.9751893968866048\n",
      "train loss:0.898827125587026\n",
      "train loss:0.9464421391804094\n",
      "train loss:0.9311935968929512\n",
      "train loss:0.9322459651934932\n",
      "train loss:0.7631158004563625\n",
      "train loss:0.9651503283893387\n",
      "train loss:1.0024267536373512\n",
      "train loss:0.8371635138264446\n",
      "train loss:0.8675300262458725\n",
      "train loss:0.8689951607567414\n",
      "train loss:0.9227017424272747\n",
      "train loss:0.9175969073619222\n",
      "train loss:0.8475089531666719\n",
      "train loss:0.9129920193656262\n",
      "train loss:0.7781323470734182\n",
      "train loss:0.6240598573342732\n",
      "train loss:0.9474487607880359\n",
      "train loss:0.8306259321586771\n",
      "train loss:0.7051600734767385\n",
      "train loss:0.7629106029484448\n",
      "train loss:1.0442734241428082\n",
      "train loss:0.7617424170403404\n",
      "train loss:0.8332710142693073\n",
      "train loss:0.74928478660627\n",
      "train loss:0.8754202809238615\n",
      "train loss:0.8014849844714196\n",
      "train loss:0.9145483873093516\n",
      "train loss:0.738078760523268\n",
      "train loss:0.8368663682717054\n",
      "train loss:0.891689598063746\n",
      "train loss:0.8408115189131117\n",
      "train loss:0.7867606712586518\n",
      "train loss:0.8940923834846919\n",
      "train loss:0.9284253594542325\n",
      "train loss:0.8594604719468557\n",
      "train loss:0.7174662922819387\n",
      "train loss:0.8847969701984029\n",
      "train loss:0.8085410892452078\n",
      "train loss:0.8195495477319302\n",
      "train loss:0.9210085710392183\n",
      "train loss:0.8512195291817102\n",
      "train loss:0.8908480696823434\n",
      "train loss:0.9425848310369862\n",
      "train loss:0.751590811850081\n",
      "train loss:0.7451207131016537\n",
      "train loss:0.9696127238580352\n",
      "train loss:0.732127432333758\n",
      "train loss:0.8666085940673672\n",
      "train loss:0.8538035667924301\n",
      "train loss:0.7822136923851849\n",
      "train loss:1.1012691090528566\n",
      "train loss:0.9050210462776828\n",
      "train loss:0.8680617265262862\n",
      "train loss:0.8261711051335413\n",
      "train loss:0.7916662997030527\n",
      "train loss:0.7394886591052255\n",
      "train loss:0.8195407100874768\n",
      "train loss:0.8420096348798971\n",
      "train loss:0.9811058218191288\n",
      "train loss:0.9635303733177879\n",
      "train loss:0.9008707507543298\n",
      "train loss:0.8720519491066177\n",
      "train loss:0.9967970917697575\n",
      "train loss:1.0945469101162328\n",
      "train loss:0.970025394776755\n",
      "train loss:0.7740364062030638\n",
      "train loss:0.9448899930525246\n",
      "train loss:0.9151688144450195\n",
      "train loss:0.9207479293228166\n",
      "train loss:0.8139875347692491\n",
      "train loss:0.8945280092866098\n",
      "train loss:0.8123400651369183\n",
      "train loss:0.8190242112573296\n",
      "train loss:0.850541740088276\n",
      "train loss:0.8868184079254416\n",
      "train loss:0.7905886719402779\n",
      "train loss:0.8282979390327574\n",
      "train loss:1.1122860805582526\n",
      "train loss:0.7623318131770934\n",
      "train loss:0.8221533637223161\n",
      "train loss:0.7294709692479426\n",
      "train loss:0.9840632984759595\n",
      "train loss:0.8978817442483211\n",
      "train loss:0.9108585526039051\n",
      "train loss:0.8633386810503937\n",
      "=== epoch:16, train acc:0.996, test acc:0.991 ===\n",
      "train loss:0.8707774410539367\n",
      "train loss:0.9366565369146513\n",
      "train loss:0.7557573209546825\n",
      "train loss:0.7476430642782411\n",
      "train loss:0.9126377775561543\n",
      "train loss:0.8385485512092911\n",
      "train loss:0.9351931832667216\n",
      "train loss:0.8440733748434797\n",
      "train loss:0.7483711815377923\n",
      "train loss:0.9949335202826579\n",
      "train loss:0.8798987929248108\n",
      "train loss:1.0450644985638795\n",
      "train loss:0.9204329074562767\n",
      "train loss:0.8011366075422941\n",
      "train loss:0.8760431539211389\n",
      "train loss:0.8126296139678182\n",
      "train loss:0.826218297772641\n",
      "train loss:0.8636902093400473\n",
      "train loss:1.0108151891755148\n",
      "train loss:0.838385652669842\n",
      "train loss:1.0162802256103767\n",
      "train loss:0.7908525993451936\n",
      "train loss:0.805926520116633\n",
      "train loss:0.8315025516261764\n",
      "train loss:0.8978505924462499\n",
      "train loss:0.8996492213713633\n",
      "train loss:0.8267484557637501\n",
      "train loss:0.9205032935239903\n",
      "train loss:0.8909277800850809\n",
      "train loss:0.8140737913032742\n",
      "train loss:0.9925972173606513\n",
      "train loss:0.8381126002203294\n",
      "train loss:0.8574370956772127\n",
      "train loss:0.8592763140462225\n",
      "train loss:0.9030059505108102\n",
      "train loss:0.7946712357181183\n",
      "train loss:0.8852235947584132\n",
      "train loss:0.7491040764258127\n",
      "train loss:0.9431917501071543\n",
      "train loss:1.0131902604417258\n",
      "train loss:1.0151291766982842\n",
      "train loss:0.6938078932494885\n",
      "train loss:0.8997218253095933\n",
      "train loss:0.8158886678240687\n",
      "train loss:0.8374203380775888\n",
      "train loss:0.9967043548895178\n",
      "train loss:0.8777862818372495\n",
      "train loss:0.926303418740742\n",
      "train loss:0.922153387828476\n",
      "train loss:0.847459401081941\n",
      "train loss:0.9352821776334771\n",
      "train loss:0.8763045738504545\n",
      "train loss:0.7724649084955457\n",
      "train loss:0.9475363216991175\n",
      "train loss:1.0728560127462092\n",
      "train loss:0.966233832634582\n",
      "train loss:0.9161846016149175\n",
      "train loss:0.8262005314232976\n",
      "train loss:0.9025110451656702\n",
      "train loss:0.8990957863653196\n",
      "train loss:1.02607690443467\n",
      "train loss:0.8065717051184662\n",
      "train loss:0.8517687636981793\n",
      "train loss:0.8211017433610642\n",
      "train loss:0.9118554907722529\n",
      "train loss:0.9662815271468793\n",
      "train loss:0.7582555620874448\n",
      "train loss:0.9289247095481997\n",
      "train loss:1.030403123765144\n",
      "train loss:1.0137427546547446\n",
      "train loss:0.7991668419287369\n",
      "train loss:0.893262991562951\n",
      "train loss:0.868461011760853\n",
      "train loss:0.7496356270969982\n",
      "train loss:0.9083970052599029\n",
      "train loss:0.91057946351233\n",
      "train loss:0.7566521094335171\n",
      "train loss:0.8277885628687458\n",
      "train loss:0.9504200881614213\n",
      "train loss:0.6298381348753963\n",
      "train loss:0.7875404889120161\n",
      "train loss:0.8076049535302262\n",
      "train loss:0.9614712155612272\n",
      "train loss:0.7999080494404183\n",
      "train loss:0.9356625780758843\n",
      "train loss:0.9545637314694702\n",
      "train loss:0.8806601625141119\n",
      "train loss:0.8966789946051884\n",
      "train loss:0.9046770880738265\n",
      "train loss:0.9422822159610986\n",
      "train loss:0.7914407934467208\n",
      "train loss:0.7015731391692259\n",
      "train loss:0.8299595499704172\n",
      "train loss:0.7940753418706156\n",
      "train loss:0.7192971032758269\n",
      "train loss:0.764372753202618\n",
      "train loss:0.9432745260883237\n",
      "train loss:0.704515344805464\n",
      "train loss:0.7858437640512244\n",
      "train loss:0.7896423568369495\n",
      "train loss:0.8405751178845384\n",
      "train loss:0.852950760921362\n",
      "train loss:1.1005375609254613\n",
      "train loss:0.9156080609374834\n",
      "train loss:0.7901470567582582\n",
      "train loss:0.7432532799839726\n",
      "train loss:0.8131355413697802\n",
      "train loss:0.8783316123494324\n",
      "train loss:1.007333785863766\n",
      "train loss:0.965099408891778\n",
      "train loss:0.8203820108822012\n",
      "train loss:0.8509061403840095\n",
      "train loss:0.7556726721486154\n",
      "train loss:0.9362861019280819\n",
      "train loss:0.9302401455134635\n",
      "train loss:0.8958635992886019\n",
      "train loss:0.8801893753437601\n",
      "train loss:0.853527394523132\n",
      "train loss:0.9752954510733577\n",
      "train loss:0.9067503260488214\n",
      "train loss:0.9494459553239187\n",
      "train loss:0.7554761865355886\n",
      "train loss:0.815356570198392\n",
      "train loss:0.9970871114331588\n",
      "train loss:0.8833072328306675\n",
      "train loss:0.8369371759078866\n",
      "train loss:0.8657194990668391\n",
      "train loss:0.9112329047662651\n",
      "train loss:0.6582777164535628\n",
      "train loss:0.8558537955959287\n",
      "train loss:0.9252616802467517\n",
      "train loss:0.7979336305257348\n",
      "train loss:0.8307771330246863\n",
      "train loss:0.919064873265164\n",
      "train loss:1.0148004126317756\n",
      "train loss:0.8402242381595901\n",
      "train loss:0.8646593653843695\n",
      "train loss:0.9713613996398626\n",
      "train loss:0.8270341943178514\n",
      "train loss:0.8408972129618433\n",
      "train loss:0.8242423427463957\n",
      "train loss:1.1168914539628263\n",
      "train loss:0.6970143290859315\n",
      "train loss:0.8851089396608772\n",
      "train loss:0.8695149670339071\n",
      "train loss:0.7416105806855303\n",
      "train loss:0.8736992631829594\n",
      "train loss:0.927636548665303\n",
      "train loss:0.929661294723842\n",
      "train loss:0.8984248035694276\n",
      "train loss:0.8576719424690665\n",
      "train loss:0.7942231196728653\n",
      "train loss:0.8113959027667825\n",
      "train loss:0.8173491184713394\n",
      "train loss:0.7540285125356528\n",
      "train loss:0.6562888125270799\n",
      "train loss:0.9361690717795921\n",
      "train loss:0.6357544063538156\n",
      "train loss:0.8249596270751325\n",
      "train loss:0.915922190894634\n",
      "train loss:0.8830508289354454\n",
      "train loss:0.708698987982674\n",
      "train loss:0.8456966493521451\n",
      "train loss:0.9332469487333616\n",
      "train loss:0.7692923560446743\n",
      "train loss:0.9245244284094306\n",
      "train loss:0.6934723373742885\n",
      "train loss:0.8324651847900383\n",
      "train loss:0.9726668901210949\n",
      "train loss:0.7915736320442887\n",
      "train loss:0.8783338254712512\n",
      "train loss:0.9212551000442589\n",
      "train loss:0.774767559901267\n",
      "train loss:0.8391833929388716\n",
      "train loss:0.9442186388559054\n",
      "train loss:0.8195583107451493\n",
      "train loss:0.7576050143693936\n",
      "train loss:0.861323095355326\n",
      "train loss:0.9406930024940291\n",
      "train loss:0.869153545052423\n",
      "train loss:0.7306187020636753\n",
      "train loss:0.9293713347087792\n",
      "train loss:0.9141438623655683\n",
      "train loss:0.8072860083126244\n",
      "train loss:1.0503617813474617\n",
      "train loss:1.001731584327634\n",
      "train loss:1.0079803145034172\n",
      "train loss:0.8376476078856635\n",
      "train loss:1.071626807772299\n",
      "train loss:0.6561146610612668\n",
      "train loss:0.852598502355404\n",
      "train loss:0.8049627771591371\n",
      "train loss:0.9072546717858885\n",
      "train loss:0.8589041544848499\n",
      "train loss:0.8799379016737601\n",
      "train loss:1.0001448259656283\n",
      "train loss:0.8412641579647742\n",
      "train loss:0.8686846281953865\n",
      "train loss:0.9460158351066491\n",
      "train loss:1.090064380487406\n",
      "train loss:0.9261304605015199\n",
      "train loss:0.9127362161752075\n",
      "train loss:0.8646602590871956\n",
      "train loss:0.9842970885250506\n",
      "train loss:0.840308649875905\n",
      "train loss:0.8015693654338762\n",
      "train loss:0.8346478060309758\n",
      "train loss:0.9248682811077691\n",
      "train loss:0.901898885493535\n",
      "train loss:0.8988781421787055\n",
      "train loss:0.8869793034568174\n",
      "train loss:0.8671627780046339\n",
      "train loss:0.7989262198777608\n",
      "train loss:0.7678835490471327\n",
      "train loss:0.7101532732432078\n",
      "train loss:0.9103556699535252\n",
      "train loss:0.9164567716335434\n",
      "train loss:0.8987803896443448\n",
      "train loss:1.0445550922099702\n",
      "train loss:0.844800725102645\n",
      "train loss:1.0243824639037664\n",
      "train loss:0.9073177144024105\n",
      "train loss:0.7610931135908195\n",
      "train loss:0.8648711084406819\n",
      "train loss:0.8720844511699208\n",
      "train loss:0.9243265959181619\n",
      "train loss:0.81420245048779\n",
      "train loss:0.70249313845917\n",
      "train loss:0.7855765512895446\n",
      "train loss:0.9726088666202807\n",
      "train loss:0.7807400159193566\n",
      "train loss:0.8260487481848827\n",
      "train loss:0.8510271035286139\n",
      "train loss:0.8815780922798385\n",
      "train loss:0.867093377039483\n",
      "train loss:0.9224803577959055\n",
      "train loss:0.9103385004607734\n",
      "train loss:0.7964692504564398\n",
      "train loss:0.8530218526796418\n",
      "train loss:0.8698975127447304\n",
      "train loss:0.7812899577212156\n",
      "train loss:0.9474748105024172\n",
      "train loss:0.896828417989788\n",
      "train loss:0.8056285678465369\n",
      "train loss:0.8578875584830387\n",
      "train loss:0.8363503593272155\n",
      "train loss:0.9134185021160114\n",
      "train loss:0.8057961521918223\n",
      "train loss:0.8120582628217838\n",
      "train loss:0.782466873337915\n",
      "train loss:0.7986068535888875\n",
      "train loss:0.7289573379340643\n",
      "train loss:0.980858953291044\n",
      "train loss:0.9495069118478245\n",
      "train loss:0.9046547191552661\n",
      "train loss:0.8460410747304665\n",
      "train loss:0.9365064546092589\n",
      "train loss:0.8762268477523599\n",
      "train loss:0.9643701141450538\n",
      "train loss:0.9561441752473874\n",
      "train loss:0.8404295855530295\n",
      "train loss:0.9205393599299454\n",
      "train loss:0.9685709725304268\n",
      "train loss:0.6710981325007268\n",
      "train loss:0.7980972984892201\n",
      "train loss:0.9473387185018993\n",
      "train loss:0.6816705372196075\n",
      "train loss:0.8179241502910182\n",
      "train loss:0.9344554409083429\n",
      "train loss:0.7770150434037035\n",
      "train loss:0.8436357616730504\n",
      "train loss:0.8207992222069322\n",
      "train loss:0.9210560022780783\n",
      "train loss:0.7898154827325682\n",
      "train loss:0.7259918258065613\n",
      "train loss:0.8523858066726391\n",
      "train loss:0.8862757481017269\n",
      "train loss:0.8225728634830766\n",
      "train loss:0.7855857245583122\n",
      "train loss:1.06987586073058\n",
      "train loss:0.8316890210424691\n",
      "train loss:0.814800519576778\n",
      "train loss:0.7073624095748866\n",
      "train loss:0.9149911441843754\n",
      "train loss:0.8008014751237362\n",
      "train loss:0.769128840050099\n",
      "train loss:0.8173135762922508\n",
      "train loss:1.0427185087952096\n",
      "train loss:0.9530316516552937\n",
      "train loss:0.7288964564403192\n",
      "train loss:0.825665434652723\n",
      "train loss:0.9997786705564289\n",
      "train loss:0.8420529918187255\n",
      "train loss:0.8186637882649217\n",
      "train loss:0.8673465619526527\n",
      "train loss:0.9115431484935373\n",
      "train loss:0.6555250524570119\n",
      "train loss:0.8968773812595167\n",
      "train loss:0.8837894812582135\n",
      "train loss:0.819878154888799\n",
      "train loss:0.8842363517169685\n",
      "train loss:0.7359892082043838\n",
      "train loss:0.8870718138529423\n",
      "train loss:1.0369418546872147\n",
      "train loss:0.9282430649358274\n",
      "train loss:0.731139630741511\n",
      "train loss:0.8345121994923653\n",
      "train loss:0.8812018652681444\n",
      "train loss:0.8719981909984976\n",
      "train loss:0.7719774167231859\n",
      "train loss:0.9710034234994788\n",
      "train loss:0.7320730469516008\n",
      "train loss:0.6147319617987489\n",
      "train loss:0.8411231325834615\n",
      "train loss:0.7847480091952735\n",
      "train loss:0.6578859387736251\n",
      "train loss:0.9157818191909959\n",
      "train loss:0.8196288794900072\n",
      "train loss:0.9384465173872966\n",
      "train loss:0.850330892741182\n",
      "train loss:0.8615574980907688\n",
      "train loss:0.8525135078260219\n",
      "train loss:0.8441181214814789\n",
      "train loss:0.7851055935293645\n",
      "train loss:0.8650786876364173\n",
      "train loss:0.8644741427068056\n",
      "train loss:0.7307010206251217\n",
      "train loss:0.8429356082578175\n",
      "train loss:0.8110574862009899\n",
      "train loss:0.8221023462588234\n",
      "train loss:0.7847344165189573\n",
      "train loss:0.6812875161536144\n",
      "train loss:0.8928274604752793\n",
      "train loss:0.8444596892288628\n",
      "train loss:0.895835344309034\n",
      "train loss:0.7431424180564998\n",
      "train loss:0.8265384876185551\n",
      "train loss:0.9207624519752656\n",
      "train loss:0.7958018602372949\n",
      "train loss:0.8803758175581803\n",
      "train loss:0.8693637216314734\n",
      "train loss:0.8274502541093366\n",
      "train loss:0.8616204427225245\n",
      "train loss:0.8146771210942131\n",
      "train loss:0.8997028196821328\n",
      "train loss:0.8522671272921086\n",
      "train loss:0.8392989869255402\n",
      "train loss:0.89715208438751\n",
      "train loss:0.884854935290648\n",
      "train loss:0.8626796145052639\n",
      "train loss:0.8388833582584917\n",
      "train loss:0.7909156209889949\n",
      "train loss:0.8749920441060836\n",
      "train loss:1.0169818241936917\n",
      "train loss:0.7239540670627013\n",
      "train loss:0.7622854368144277\n",
      "train loss:0.757977417892785\n",
      "train loss:0.8567740264141094\n",
      "train loss:0.6746987956404003\n",
      "train loss:0.9577345520033056\n",
      "train loss:0.8939374554916438\n",
      "train loss:0.9006803429977688\n",
      "train loss:0.870000981529941\n",
      "train loss:0.8793804009543308\n",
      "train loss:0.8485090184367627\n",
      "train loss:0.7829925324310306\n",
      "train loss:0.8728635619542016\n",
      "train loss:0.7405902571060082\n",
      "train loss:0.8671248509236077\n",
      "train loss:0.9478317999342193\n",
      "train loss:0.7540834423805358\n",
      "train loss:0.975379717376704\n",
      "train loss:0.7580948734438541\n",
      "train loss:0.8739234123533838\n",
      "train loss:0.8285423944655079\n",
      "train loss:0.8448092176119458\n",
      "train loss:0.8293353372402902\n",
      "train loss:1.000211864967961\n",
      "train loss:0.8631935996488074\n",
      "train loss:0.8633223395975831\n",
      "train loss:0.9139020861730037\n",
      "train loss:0.9883877342117511\n",
      "train loss:0.9439666795926303\n",
      "train loss:0.8586705351753966\n",
      "train loss:0.6802478207154777\n",
      "train loss:1.0173838991721953\n",
      "train loss:0.7951848786459594\n",
      "train loss:0.8761229144784177\n",
      "train loss:0.830601550169981\n",
      "train loss:0.8298067241534487\n",
      "train loss:0.7723187552423739\n",
      "train loss:0.9787707595927199\n",
      "train loss:0.7965881864200566\n",
      "train loss:0.699688533218927\n",
      "train loss:0.9449925255064686\n",
      "train loss:0.81007322588403\n",
      "train loss:0.8022974534688097\n",
      "train loss:0.7995544428396072\n",
      "train loss:0.8431136609074587\n",
      "train loss:0.8913492548168831\n",
      "train loss:0.802205333561824\n",
      "train loss:0.852983880389713\n",
      "train loss:1.1056518686269319\n",
      "train loss:0.8336502227987809\n",
      "train loss:0.7276994717866065\n",
      "train loss:0.8037974519147926\n",
      "train loss:0.9360558720896421\n",
      "train loss:0.7685655508558489\n",
      "train loss:0.9005735369735435\n",
      "train loss:0.7803270719567853\n",
      "train loss:0.928096061755379\n",
      "train loss:0.7637264485701897\n",
      "train loss:0.8278107528865639\n",
      "train loss:1.0800224674477301\n",
      "train loss:0.903947219299923\n",
      "train loss:0.9416017623905591\n",
      "train loss:0.7617174017724514\n",
      "train loss:0.9445309293890395\n",
      "train loss:0.828270689182625\n",
      "train loss:0.8079455049326334\n",
      "train loss:0.8567363110793914\n",
      "train loss:0.777537846820596\n",
      "train loss:0.8462377932215861\n",
      "train loss:0.8754410223371885\n",
      "train loss:0.8731662192858528\n",
      "train loss:0.9027994316100495\n",
      "train loss:0.7709493033153576\n",
      "train loss:0.8296146215107285\n",
      "train loss:0.7249670533994549\n",
      "train loss:0.7998959219032471\n",
      "train loss:0.83990342591654\n",
      "train loss:0.8519758844406714\n",
      "train loss:0.8030885458321252\n",
      "train loss:0.9155334910857842\n",
      "train loss:0.9626062223183647\n",
      "train loss:0.912280748310107\n",
      "train loss:0.7597017459227431\n",
      "train loss:0.9269726742887882\n",
      "train loss:0.847904196493265\n",
      "train loss:0.7962797658250765\n",
      "train loss:0.9549000442247781\n",
      "train loss:0.8278775259095608\n",
      "train loss:0.9093958818135656\n",
      "train loss:0.7268966113374259\n",
      "train loss:0.8715237109315737\n",
      "train loss:0.8421292731201488\n",
      "train loss:0.9865704857141098\n",
      "train loss:0.6635051354648547\n",
      "train loss:0.8813123390531662\n",
      "train loss:0.7434935140401058\n",
      "train loss:0.7829834930029468\n",
      "train loss:0.8772242112909571\n",
      "train loss:0.9209742389733246\n",
      "train loss:0.9598988303261408\n",
      "train loss:0.8223041479440109\n",
      "train loss:0.8824333044815316\n",
      "train loss:0.7709512970540463\n",
      "train loss:0.8187489056555763\n",
      "train loss:0.8193541635930544\n",
      "train loss:0.8004618917639827\n",
      "train loss:0.8332585138684684\n",
      "train loss:0.8836334734244221\n",
      "train loss:0.874155889786745\n",
      "train loss:0.7955242817036986\n",
      "train loss:1.0287357214476054\n",
      "train loss:0.8927138347521952\n",
      "train loss:0.7464758765187794\n",
      "train loss:0.8964341390916019\n",
      "train loss:0.7952543353600028\n",
      "train loss:0.842792484944112\n",
      "train loss:0.8797295934263673\n",
      "train loss:0.812743026656535\n",
      "train loss:0.862650360619401\n",
      "train loss:0.7252858927783592\n",
      "train loss:0.7855528916725809\n",
      "train loss:0.8830693390365824\n",
      "train loss:0.8511766058267134\n",
      "train loss:0.8252907657890323\n",
      "train loss:0.782595270690051\n",
      "train loss:0.8438798606353393\n",
      "train loss:0.8468666192965715\n",
      "train loss:0.8369798271204365\n",
      "train loss:0.7948973473736851\n",
      "train loss:0.740207881243517\n",
      "train loss:0.8222740539502641\n",
      "train loss:0.7649163848779815\n",
      "train loss:0.8464517606571411\n",
      "train loss:0.9117830154449313\n",
      "train loss:0.7631119086053307\n",
      "train loss:0.8765148718190079\n",
      "train loss:0.8212989363167432\n",
      "train loss:0.9002411868735776\n",
      "train loss:0.8320781029481497\n",
      "train loss:0.8104271189956315\n",
      "train loss:0.8854665699640829\n",
      "train loss:0.8138979745211582\n",
      "train loss:0.7504496930667718\n",
      "train loss:0.8097009839641989\n",
      "train loss:0.7955893200893918\n",
      "train loss:0.9669691618082982\n",
      "train loss:0.8038838187560838\n",
      "train loss:0.9535510578701448\n",
      "train loss:1.0337238198251169\n",
      "train loss:0.9884185501225654\n",
      "train loss:0.7419067507432859\n",
      "train loss:0.8738011446924502\n",
      "train loss:0.81802001111303\n",
      "train loss:0.7788095763394572\n",
      "train loss:0.9992081724808441\n",
      "train loss:0.7802530464645611\n",
      "train loss:0.8618925890673093\n",
      "train loss:0.8059974689445148\n",
      "train loss:0.7819905168589995\n",
      "train loss:0.9416265666487962\n",
      "train loss:0.8538973618938059\n",
      "train loss:0.8652916920879306\n",
      "train loss:0.829092074531161\n",
      "train loss:0.8878908858538992\n",
      "train loss:0.8505281608735714\n",
      "train loss:0.7767012148885328\n",
      "train loss:0.9143573615816836\n",
      "train loss:0.8852324683742689\n",
      "train loss:0.8142929022922406\n",
      "train loss:0.8292559216923223\n",
      "train loss:0.9068867056114241\n",
      "train loss:0.8263279610560308\n",
      "train loss:0.9074683794179366\n",
      "train loss:0.9080031151352642\n",
      "train loss:0.924594270800374\n",
      "train loss:0.8072810202425651\n",
      "train loss:0.938635735943219\n",
      "train loss:0.6769053129622055\n",
      "train loss:0.7769915968532289\n",
      "train loss:0.8595035667924\n",
      "train loss:0.7261529439144109\n",
      "train loss:0.9545079795109248\n",
      "train loss:0.8502707464210987\n",
      "train loss:0.7675902771081689\n",
      "train loss:1.0233092638524872\n",
      "train loss:0.7856210522770499\n",
      "train loss:0.7954410829420249\n",
      "train loss:0.8633766935561664\n",
      "train loss:0.7918793650924242\n",
      "train loss:0.9661918950624052\n",
      "train loss:0.9767613274059507\n",
      "train loss:0.8628258449797716\n",
      "train loss:0.7752839892998211\n",
      "train loss:1.0411024814778886\n",
      "train loss:0.8196694294001512\n",
      "train loss:1.0189940911966433\n",
      "train loss:0.9069109721871023\n",
      "train loss:0.8131338355435601\n",
      "train loss:0.8924496646240224\n",
      "train loss:0.9119569537772197\n",
      "train loss:0.7788006850745737\n",
      "train loss:0.8972536347849541\n",
      "train loss:0.7674120547589927\n",
      "train loss:0.891912590079193\n",
      "train loss:0.8000757575080675\n",
      "train loss:0.7889025189083269\n",
      "train loss:0.8899861208354085\n",
      "train loss:0.8279918617921723\n",
      "train loss:0.8850856379755825\n",
      "train loss:0.8540063122753547\n",
      "train loss:0.7672664100621792\n",
      "train loss:0.8441777432040776\n",
      "train loss:0.854167859617655\n",
      "train loss:0.9184199215059753\n",
      "train loss:0.7382867419340208\n",
      "train loss:0.7828447243090041\n",
      "train loss:0.8067892847889706\n",
      "train loss:0.9434925126853974\n",
      "train loss:0.8980750208087156\n",
      "train loss:0.8137145672493101\n",
      "train loss:1.0012524263163183\n",
      "train loss:0.722120400942338\n",
      "train loss:0.8889333951680992\n",
      "train loss:0.8937998181400271\n",
      "train loss:0.7736701956174895\n",
      "train loss:0.9150870923901797\n",
      "train loss:0.8479112485880681\n",
      "train loss:0.6507517955193157\n",
      "train loss:0.9376144620623925\n",
      "train loss:0.981082167281066\n",
      "train loss:0.811161824741449\n",
      "train loss:0.8510208223894559\n",
      "train loss:0.9764632466286577\n",
      "train loss:0.9402478371901595\n",
      "train loss:1.0082380046156905\n",
      "train loss:0.7944284936609638\n",
      "train loss:0.9900060018774133\n",
      "train loss:0.8449147458401665\n",
      "train loss:0.7026377651617065\n",
      "train loss:0.8471801475191596\n",
      "train loss:0.8607987117917696\n",
      "train loss:0.9073799736744109\n",
      "train loss:0.94425364223629\n",
      "train loss:0.955443379270103\n",
      "train loss:0.9149803502278122\n",
      "train loss:0.7973519891309357\n",
      "=== epoch:17, train acc:0.996, test acc:0.99 ===\n",
      "train loss:0.8045428005196567\n",
      "train loss:0.7846661276750945\n",
      "train loss:0.9592607777564872\n",
      "train loss:0.9133383417977714\n",
      "train loss:0.8181372304984059\n",
      "train loss:0.797156006731786\n",
      "train loss:0.8923388022903687\n",
      "train loss:0.8611754156664663\n",
      "train loss:0.691986328577673\n",
      "train loss:0.7952350777119902\n",
      "train loss:0.8712691143878398\n",
      "train loss:0.7705237825106289\n",
      "train loss:0.7791908756030943\n",
      "train loss:0.8970469303560229\n",
      "train loss:0.9385970023180701\n",
      "train loss:0.8238060420226586\n",
      "train loss:0.7130828599842985\n",
      "train loss:0.8341161339693758\n",
      "train loss:0.7821486583171335\n",
      "train loss:0.7885545620471897\n",
      "train loss:0.8907403471534774\n",
      "train loss:0.8274727030724085\n",
      "train loss:0.811462975897859\n",
      "train loss:0.8782791363392031\n",
      "train loss:0.9181589228038872\n",
      "train loss:0.8997786786358204\n",
      "train loss:0.8153858965989323\n",
      "train loss:0.9640561497187379\n",
      "train loss:0.9053479297670267\n",
      "train loss:0.8746832037575308\n",
      "train loss:0.8659337979240374\n",
      "train loss:0.9647435194347059\n",
      "train loss:0.7504325955261544\n",
      "train loss:0.7001102217778998\n",
      "train loss:0.8003116987818356\n",
      "train loss:0.7476033919451929\n",
      "train loss:1.0336446862349633\n",
      "train loss:0.9240150693133095\n",
      "train loss:0.7782291739148255\n",
      "train loss:0.7804790064122012\n",
      "train loss:0.9266456657255495\n",
      "train loss:1.0105680405735664\n",
      "train loss:1.0335480558922014\n",
      "train loss:0.8195762071369056\n",
      "train loss:0.9291880105268427\n",
      "train loss:0.8559003363140012\n",
      "train loss:0.838100787141685\n",
      "train loss:0.8999270706814337\n",
      "train loss:0.8839461816519639\n",
      "train loss:0.8836299409569053\n",
      "train loss:0.8653416096055995\n",
      "train loss:0.7443074468199594\n",
      "train loss:0.8323875566086413\n",
      "train loss:0.8775620088692325\n",
      "train loss:0.9540175135896335\n",
      "train loss:0.8702493965968143\n",
      "train loss:0.8902280017457223\n",
      "train loss:0.8177955954489415\n",
      "train loss:0.8811061027449573\n",
      "train loss:0.8681983642200076\n",
      "train loss:0.8211718771085494\n",
      "train loss:0.8204747245257278\n",
      "train loss:1.026013164245905\n",
      "train loss:0.8822592838549624\n",
      "train loss:0.8237211921792051\n",
      "train loss:0.863590220689532\n",
      "train loss:1.0039561846712493\n",
      "train loss:0.8278890879845285\n",
      "train loss:0.8099204469212031\n",
      "train loss:1.0233566682275133\n",
      "train loss:0.9276920748902662\n",
      "train loss:0.899395467147682\n",
      "train loss:0.8643330257944075\n",
      "train loss:0.8480910297460766\n",
      "train loss:0.9655865788199316\n",
      "train loss:0.7980132424981323\n",
      "train loss:0.9079693923311614\n",
      "train loss:0.9623503854252207\n",
      "train loss:0.8797523732080625\n",
      "train loss:0.8224174373847893\n",
      "train loss:0.9507012411340979\n",
      "train loss:0.8802250035091365\n",
      "train loss:0.8560138932157197\n",
      "train loss:0.9024680661118962\n",
      "train loss:1.084839890821739\n",
      "train loss:0.9166922809131364\n",
      "train loss:1.0465678600273856\n",
      "train loss:0.8692889297202571\n",
      "train loss:0.8109553384971242\n",
      "train loss:0.8740991250528474\n",
      "train loss:0.9203992083470203\n",
      "train loss:0.7211686520236122\n",
      "train loss:0.8601018088301143\n",
      "train loss:0.7706362703613132\n",
      "train loss:0.880163143795825\n",
      "train loss:0.918148323436199\n",
      "train loss:0.9719647428104001\n",
      "train loss:0.8027854274661942\n",
      "train loss:0.8591225892331014\n",
      "train loss:0.7175509691445585\n",
      "train loss:0.8784578070945035\n",
      "train loss:0.912774518308168\n",
      "train loss:0.910810293480709\n",
      "train loss:0.7259954078180588\n",
      "train loss:0.7969505481431983\n",
      "train loss:0.9057942424144383\n",
      "train loss:0.9707613160272195\n",
      "train loss:0.9718807664142116\n",
      "train loss:0.7952633327902134\n",
      "train loss:0.8734357068881711\n",
      "train loss:0.871352793711114\n",
      "train loss:0.7908350026075246\n",
      "train loss:0.8796435468749221\n",
      "train loss:0.8737742753377488\n",
      "train loss:0.8784422526968635\n",
      "train loss:0.900690914206447\n",
      "train loss:0.795550928964734\n",
      "train loss:0.8745909658320283\n",
      "train loss:1.0324500830544983\n",
      "train loss:0.8642644768916482\n",
      "train loss:0.7090331747042202\n",
      "train loss:0.9193581865717178\n",
      "train loss:0.9513201798465635\n",
      "train loss:0.7888101424489707\n",
      "train loss:0.9248952980530367\n",
      "train loss:0.8453371259697393\n",
      "train loss:0.9018649692037027\n",
      "train loss:0.8092458384533853\n",
      "train loss:0.8281167747679735\n",
      "train loss:0.9285570343366655\n",
      "train loss:0.7179750124351011\n",
      "train loss:0.8944256330016483\n",
      "train loss:0.7554126403198133\n",
      "train loss:0.8826879115466018\n",
      "train loss:0.828149017015182\n",
      "train loss:0.9362940759232583\n",
      "train loss:0.76821120630181\n",
      "train loss:0.6771803600560211\n",
      "train loss:0.9926008017257238\n",
      "train loss:0.8176232364772923\n",
      "train loss:0.8042517330353514\n",
      "train loss:0.9501332561472043\n",
      "train loss:0.9366428329488165\n",
      "train loss:0.8116413526914106\n",
      "train loss:0.852664523258145\n",
      "train loss:0.8762060434905888\n",
      "train loss:0.8310181253674815\n",
      "train loss:0.7553863729945297\n",
      "train loss:0.8448947143641127\n",
      "train loss:1.0152012222118105\n",
      "train loss:0.7315898768024713\n",
      "train loss:0.9003943299363099\n",
      "train loss:0.967716794683502\n",
      "train loss:0.7754811754804908\n",
      "train loss:0.9122770648103226\n",
      "train loss:0.7970056737749097\n",
      "train loss:0.9108229203714326\n",
      "train loss:0.8835863195129674\n",
      "train loss:1.0002183714939947\n",
      "train loss:0.8965336884939794\n",
      "train loss:0.9282965496643628\n",
      "train loss:0.8016642775881959\n",
      "train loss:0.828628753807848\n",
      "train loss:0.785624346089954\n",
      "train loss:0.753770176863311\n",
      "train loss:0.8440471629295512\n",
      "train loss:0.7496452055862729\n",
      "train loss:0.8551361346288492\n",
      "train loss:0.9669478260180991\n",
      "train loss:0.8288118049577872\n",
      "train loss:1.0215305556220238\n",
      "train loss:0.7709270984703609\n",
      "train loss:0.7527884055354522\n",
      "train loss:1.0021978660716129\n",
      "train loss:0.9204983732108001\n",
      "train loss:0.7945413924005824\n",
      "train loss:1.0217923787850882\n",
      "train loss:0.970298791816977\n",
      "train loss:0.8432503840043093\n",
      "train loss:0.7598705874580282\n",
      "train loss:0.9576422411339105\n",
      "train loss:0.8789274951722403\n",
      "train loss:0.9412402503456028\n",
      "train loss:0.6658453425423332\n",
      "train loss:0.7931826443571243\n",
      "train loss:0.9906867832126074\n",
      "train loss:0.7826947286719341\n",
      "train loss:0.8936806009502734\n",
      "train loss:0.8308896453122988\n",
      "train loss:0.7750047331909427\n",
      "train loss:0.98548443399012\n",
      "train loss:0.806347011150116\n",
      "train loss:0.9016515760765905\n",
      "train loss:0.8509736716183528\n",
      "train loss:0.9095808525995145\n",
      "train loss:0.8802059066051154\n",
      "train loss:0.7084446619941382\n",
      "train loss:0.8474357040977355\n",
      "train loss:0.7350522105951088\n",
      "train loss:1.1814041913250082\n",
      "train loss:1.0820462978318095\n",
      "train loss:0.693718047370545\n",
      "train loss:0.8357975214852401\n",
      "train loss:0.7497249895633875\n",
      "train loss:0.7849139533683561\n",
      "train loss:0.9379347775231841\n",
      "train loss:1.0261998396395675\n",
      "train loss:0.8122911932528666\n",
      "train loss:0.8932318321486806\n",
      "train loss:0.7496203090566343\n",
      "train loss:0.9287671804108529\n",
      "train loss:0.8156511301921862\n",
      "train loss:0.8098003606067791\n",
      "train loss:0.7082055487671037\n",
      "train loss:0.6750240855595676\n",
      "train loss:0.8528968826550123\n",
      "train loss:0.9507528852898504\n",
      "train loss:0.7684840601002118\n",
      "train loss:0.7684191454773095\n",
      "train loss:0.8711737161369589\n",
      "train loss:0.803256921710647\n",
      "train loss:0.8743886008055602\n",
      "train loss:0.8226446548349345\n",
      "train loss:0.7472595693814461\n",
      "train loss:0.871934038677281\n",
      "train loss:0.8323734664825363\n",
      "train loss:0.8299546164044778\n",
      "train loss:0.9395530045896368\n",
      "train loss:0.8317455499273069\n",
      "train loss:0.9692018691185161\n",
      "train loss:0.9399746486858421\n",
      "train loss:0.9573823013518578\n",
      "train loss:0.8665972039938202\n",
      "train loss:0.8612910933054533\n",
      "train loss:0.9142141682168574\n",
      "train loss:0.8972615155052678\n",
      "train loss:0.8051488686131069\n",
      "train loss:0.844903053075816\n",
      "train loss:0.8100296461081677\n",
      "train loss:0.9112001023036208\n",
      "train loss:0.8689807941592449\n",
      "train loss:1.125841096543154\n",
      "train loss:0.9350406959841964\n",
      "train loss:0.9520560276860519\n",
      "train loss:0.8337925008963224\n",
      "train loss:0.8893388328495249\n",
      "train loss:0.7601678122261191\n",
      "train loss:0.7837122761635902\n",
      "train loss:0.8792472037052839\n",
      "train loss:0.9213083567776789\n",
      "train loss:0.8991776427165097\n",
      "train loss:0.9063990980801528\n",
      "train loss:0.9601604413548109\n",
      "train loss:0.6808846516582387\n",
      "train loss:0.8232699951812161\n",
      "train loss:0.8006432881486483\n",
      "train loss:0.729564999139797\n",
      "train loss:1.079063604466928\n",
      "train loss:1.0083026697634794\n",
      "train loss:0.9969884102096885\n",
      "train loss:1.0439509890477148\n",
      "train loss:0.9335505496087763\n",
      "train loss:0.9611842585180379\n",
      "train loss:0.9473710612434929\n",
      "train loss:1.0084333343739462\n",
      "train loss:0.766011795098489\n",
      "train loss:0.7813007889354179\n",
      "train loss:0.8062808803553164\n",
      "train loss:0.6794049588917409\n",
      "train loss:0.8575858789314811\n",
      "train loss:0.8970447176956678\n",
      "train loss:1.0390381267429494\n",
      "train loss:0.9324760603363768\n",
      "train loss:0.8351032423048553\n",
      "train loss:0.9457146495301505\n",
      "train loss:1.028870447631636\n",
      "train loss:0.9423918931583506\n",
      "train loss:0.9319689196992696\n",
      "train loss:0.8127842178849928\n",
      "train loss:0.890963779671265\n",
      "train loss:0.7699001981859559\n",
      "train loss:0.8287530869396172\n",
      "train loss:0.8327878312246\n",
      "train loss:0.8891767057259682\n",
      "train loss:0.792919118539512\n",
      "train loss:0.7810940172772297\n",
      "train loss:0.8352892634132065\n",
      "train loss:0.9436413593529394\n",
      "train loss:0.7580604561429348\n",
      "train loss:0.6903304649013071\n",
      "train loss:0.902221370157719\n",
      "train loss:0.8206900804940652\n",
      "train loss:0.7275846492678026\n",
      "train loss:0.8939211440128939\n",
      "train loss:0.9095865697309254\n",
      "train loss:0.7833730621593521\n",
      "train loss:0.9835721142965457\n",
      "train loss:0.9587025246226901\n",
      "train loss:0.821930325072663\n",
      "train loss:0.9025694655190396\n",
      "train loss:0.9714632530572035\n",
      "train loss:0.9279321088822757\n",
      "train loss:0.8774942715100231\n",
      "train loss:0.826199503352358\n",
      "train loss:0.971520459556196\n",
      "train loss:0.7893633720311654\n",
      "train loss:0.7947503535734826\n",
      "train loss:0.8447949701854625\n",
      "train loss:0.9138479741012253\n",
      "train loss:0.7506326748332051\n",
      "train loss:0.9010091643970476\n",
      "train loss:0.8439408122824541\n",
      "train loss:0.8617430099126855\n",
      "train loss:0.8321321990218898\n",
      "train loss:0.9078053970540553\n",
      "train loss:0.831099946473756\n",
      "train loss:1.0578356394389659\n",
      "train loss:0.9794337215739034\n",
      "train loss:0.9176724641781872\n",
      "train loss:0.9098969216158183\n",
      "train loss:0.9600228389868306\n",
      "train loss:0.730115612277425\n",
      "train loss:1.0330204641746947\n",
      "train loss:0.8505681111851534\n",
      "train loss:0.7246295676087098\n",
      "train loss:0.7263987182804928\n",
      "train loss:0.8026425590925121\n",
      "train loss:0.898192670294127\n",
      "train loss:0.8908740588963424\n",
      "train loss:0.9847326832065254\n",
      "train loss:0.7855284655584035\n",
      "train loss:0.895242172681275\n",
      "train loss:0.8570215106372724\n",
      "train loss:1.098450802791847\n",
      "train loss:0.8424310347797658\n",
      "train loss:0.8419898941474251\n",
      "train loss:0.6561000862596847\n",
      "train loss:0.7405492381107238\n",
      "train loss:0.9575921284285001\n",
      "train loss:0.9791388024981887\n",
      "train loss:0.9010648585933323\n",
      "train loss:0.8353229399182834\n",
      "train loss:0.9439868584301742\n",
      "train loss:0.6553422175918945\n",
      "train loss:1.0301180594659811\n",
      "train loss:0.8781029086509752\n",
      "train loss:0.9078809289629478\n",
      "train loss:0.9394299149316772\n",
      "train loss:0.92031473474682\n",
      "train loss:0.6836487135509018\n",
      "train loss:0.9559379532862922\n",
      "train loss:0.8513764837927457\n",
      "train loss:0.9933293561136949\n",
      "train loss:0.9025601536068784\n",
      "train loss:0.9102236503782948\n",
      "train loss:1.060907106870784\n",
      "train loss:0.8042742500603133\n",
      "train loss:0.9433460380837478\n",
      "train loss:0.926163076521715\n",
      "train loss:0.5853077115055575\n",
      "train loss:0.8673526285863101\n",
      "train loss:1.0595048018687876\n",
      "train loss:0.8549035819710865\n",
      "train loss:1.0075541981083018\n",
      "train loss:0.9343451204101652\n",
      "train loss:0.770309378929479\n",
      "train loss:0.7788481977112574\n",
      "train loss:0.948042520445436\n",
      "train loss:0.9068126124782466\n",
      "train loss:0.9564773397399354\n",
      "train loss:0.8191850195679509\n",
      "train loss:0.8935674796381025\n",
      "train loss:0.7270996124568221\n",
      "train loss:0.7624508165276451\n",
      "train loss:0.926061542298353\n",
      "train loss:0.9894829497868507\n",
      "train loss:0.8634212967990642\n",
      "train loss:0.9059259791655271\n",
      "train loss:0.9109412670022929\n",
      "train loss:0.6932847128565715\n",
      "train loss:0.9255034859868602\n",
      "train loss:0.7417240108642459\n",
      "train loss:0.9791500929603011\n",
      "train loss:0.9158174901275637\n",
      "train loss:0.8735544656182579\n",
      "train loss:0.8634790897559005\n",
      "train loss:0.953776389195511\n",
      "train loss:0.987149280126564\n",
      "train loss:0.9294161623477797\n",
      "train loss:0.7975794276998665\n",
      "train loss:0.6520002585235892\n",
      "train loss:0.9555473526255723\n",
      "train loss:0.8384295323935708\n",
      "train loss:0.8192654585786683\n",
      "train loss:0.8470339742974179\n",
      "train loss:0.9659368518201759\n",
      "train loss:0.8311319946637623\n",
      "train loss:0.8085200538433875\n",
      "train loss:0.7863653221328392\n",
      "train loss:0.7042546943197041\n",
      "train loss:0.7125514502525241\n",
      "train loss:0.9952095000233835\n",
      "train loss:0.9363294639600731\n",
      "train loss:0.840332240179829\n",
      "train loss:0.9574132595134073\n",
      "train loss:0.7965087820151556\n",
      "train loss:0.9042866162558083\n",
      "train loss:0.8480318584413089\n",
      "train loss:0.8135994344463093\n",
      "train loss:0.8292656362367401\n",
      "train loss:0.8544503166563336\n",
      "train loss:0.7049116538824254\n",
      "train loss:1.075553151171774\n",
      "train loss:0.7471934287003132\n",
      "train loss:0.9612923336858878\n",
      "train loss:0.9567021556380859\n",
      "train loss:0.8066253006385053\n",
      "train loss:0.7921452783659472\n",
      "train loss:0.8513197278806081\n",
      "train loss:0.8595321474927764\n",
      "train loss:0.7249793459095367\n",
      "train loss:0.9228024266393594\n",
      "train loss:0.8289488289936687\n",
      "train loss:0.8097524929225325\n",
      "train loss:1.0093082096298118\n",
      "train loss:0.9809185338441796\n",
      "train loss:0.8366707367761856\n",
      "train loss:0.767679313908127\n",
      "train loss:0.7789397814165888\n",
      "train loss:0.9532124959068768\n",
      "train loss:0.8107536573290642\n",
      "train loss:1.1612880550242917\n",
      "train loss:0.9157406029685673\n",
      "train loss:0.8089496371464261\n",
      "train loss:0.8199213166291567\n",
      "train loss:0.8981455080646625\n",
      "train loss:0.7801269498851033\n",
      "train loss:1.0594385865389484\n",
      "train loss:0.8189009530607173\n",
      "train loss:0.9501016918808051\n",
      "train loss:0.9008788381165186\n",
      "train loss:0.8111955255651033\n",
      "train loss:0.8013014333208598\n",
      "train loss:0.9531771836405183\n",
      "train loss:0.8036569775219222\n",
      "train loss:0.7836463349905481\n",
      "train loss:0.6741188724426124\n",
      "train loss:0.8094415486170177\n",
      "train loss:0.8130955742049325\n",
      "train loss:0.8983869746507067\n",
      "train loss:1.0231780692747108\n",
      "train loss:0.9215831268872998\n",
      "train loss:0.8892115208639059\n",
      "train loss:0.9948046288512121\n",
      "train loss:0.8613329054818598\n",
      "train loss:0.8082716846055304\n",
      "train loss:0.8482995359978303\n",
      "train loss:0.9035125699966718\n",
      "train loss:0.8123160835100641\n",
      "train loss:0.9251914016650686\n",
      "train loss:0.9805055496340885\n",
      "train loss:0.7863858361156899\n",
      "train loss:0.7846701416274504\n",
      "train loss:0.9568185422976098\n",
      "train loss:0.6912579204280759\n",
      "train loss:0.9009396775841029\n",
      "train loss:0.9310806643806625\n",
      "train loss:0.8891652171841012\n",
      "train loss:0.6839055664361834\n",
      "train loss:0.8993546141724846\n",
      "train loss:0.811129177678549\n",
      "train loss:0.7025347218317113\n",
      "train loss:0.8171025773382695\n",
      "train loss:1.0462900883608364\n",
      "train loss:0.7982723635528813\n",
      "train loss:0.8117942094090855\n",
      "train loss:0.824126540674885\n",
      "train loss:0.720498814768439\n",
      "train loss:0.8194523193202617\n",
      "train loss:0.9487563807431786\n",
      "train loss:0.7332025077074265\n",
      "train loss:0.8242339624381857\n",
      "train loss:0.9071289933965582\n",
      "train loss:0.9305883963172579\n",
      "train loss:0.726929129138376\n",
      "train loss:0.9255900802434948\n",
      "train loss:0.7598577818075224\n",
      "train loss:0.9508201769220781\n",
      "train loss:0.7849215289714825\n",
      "train loss:0.7796526577744679\n",
      "train loss:0.9038855096156166\n",
      "train loss:0.9369440747761044\n",
      "train loss:0.830383421399532\n",
      "train loss:0.9012513697272786\n",
      "train loss:0.8904048381693506\n",
      "train loss:0.7198808385230067\n",
      "train loss:1.0589581419621066\n",
      "train loss:0.777225703148793\n",
      "train loss:0.892629150393787\n",
      "train loss:0.7172160118854839\n",
      "train loss:0.9128603544811226\n",
      "train loss:1.002083231776142\n",
      "train loss:0.9944242163024886\n",
      "train loss:0.8683114341015343\n",
      "train loss:0.9135773134834504\n",
      "train loss:0.7876612268420736\n",
      "train loss:0.8470230275981279\n",
      "train loss:1.0017278078521044\n",
      "train loss:1.029129596488505\n",
      "train loss:0.8914286231541858\n",
      "train loss:0.8599187646375553\n",
      "train loss:0.6955037827306196\n",
      "train loss:0.8081670640685299\n",
      "train loss:0.7814720672840252\n",
      "train loss:0.7928504957963883\n",
      "train loss:0.8868727559448434\n",
      "train loss:0.8206756349608202\n",
      "train loss:0.9964217217631888\n",
      "train loss:0.7163006672661809\n",
      "train loss:0.8478853979115333\n",
      "train loss:0.880796715489765\n",
      "train loss:0.617465739115024\n",
      "train loss:1.007642765200424\n",
      "train loss:0.9641465784666134\n",
      "train loss:0.9785126838213093\n",
      "train loss:0.8238182227782499\n",
      "train loss:0.8690732633081777\n",
      "train loss:0.8002336281069716\n",
      "train loss:0.8982592779860488\n",
      "train loss:0.8327127941307583\n",
      "train loss:1.0433567215881232\n",
      "train loss:0.778663458196947\n",
      "train loss:0.8645654090194137\n",
      "train loss:0.741325572362893\n",
      "train loss:0.8617678860503273\n",
      "train loss:0.9047995351894694\n",
      "train loss:0.8896453480966268\n",
      "train loss:0.9422125752322223\n",
      "train loss:0.8388833412286968\n",
      "train loss:0.7052606778034328\n",
      "train loss:0.8816266860058285\n",
      "train loss:0.9622614711917622\n",
      "train loss:0.8522319089004636\n",
      "train loss:0.7909243692922879\n",
      "train loss:0.8940684818847261\n",
      "train loss:0.9670801449039165\n",
      "train loss:0.6897744191869529\n",
      "train loss:0.7420900310227024\n",
      "train loss:0.7922825000854968\n",
      "train loss:0.7258903759037051\n",
      "train loss:0.7324369323222946\n",
      "train loss:0.9048783858315317\n",
      "train loss:0.9536898632681533\n",
      "train loss:0.9830455050908141\n",
      "train loss:0.9840433398490253\n",
      "train loss:0.8515587276587548\n",
      "train loss:0.7920237789057399\n",
      "train loss:0.9002030289712156\n",
      "train loss:0.7245120074292483\n",
      "train loss:0.7836195949388941\n",
      "train loss:0.7193491334392929\n",
      "train loss:0.8172800444901295\n",
      "train loss:0.793992938769835\n",
      "train loss:0.8283681466759708\n",
      "train loss:0.7472735500651905\n",
      "train loss:1.0411739200760584\n",
      "train loss:0.7974433248460541\n",
      "train loss:0.8126292722241554\n",
      "train loss:0.8218162469733535\n",
      "train loss:0.7305609164940234\n",
      "train loss:0.7780081894467553\n",
      "train loss:0.969639804513553\n",
      "train loss:0.8686879835582632\n",
      "train loss:0.784556906517487\n",
      "train loss:0.8114126437205367\n",
      "train loss:0.9632253124593089\n",
      "train loss:0.8266345379826086\n",
      "train loss:0.983900847394723\n",
      "train loss:0.8813529134431971\n",
      "train loss:0.7864753444073699\n",
      "train loss:0.8566173817667676\n",
      "train loss:0.9424241052930569\n",
      "train loss:0.7422957814002545\n",
      "train loss:0.7735765860086814\n",
      "train loss:0.699026842296616\n",
      "train loss:0.7745419787623186\n",
      "train loss:0.8869092742294492\n",
      "train loss:0.8588791829743423\n",
      "train loss:1.0348450869592094\n",
      "train loss:0.9416247690998537\n",
      "train loss:1.0410129439044407\n",
      "train loss:0.8240212695576257\n",
      "train loss:0.7352823408096164\n",
      "train loss:0.8060995813350345\n",
      "train loss:0.8297471309616538\n",
      "train loss:0.9398045915464007\n",
      "train loss:0.7604589969598359\n",
      "train loss:0.8482203202364214\n",
      "train loss:0.7917463078743328\n",
      "train loss:0.8290272183021666\n",
      "=== epoch:18, train acc:0.997, test acc:0.989 ===\n",
      "train loss:0.8612347962101733\n",
      "train loss:0.781284539241794\n",
      "train loss:0.7891001520444358\n",
      "train loss:0.9287763455972109\n",
      "train loss:0.9352280710648826\n",
      "train loss:1.0024061138173237\n",
      "train loss:0.9602475525863361\n",
      "train loss:0.8542035238649356\n",
      "train loss:0.9363574006925447\n",
      "train loss:0.9413460992384721\n",
      "train loss:0.8373207961193444\n",
      "train loss:0.8123559808241099\n",
      "train loss:0.990772451953777\n",
      "train loss:0.8507727352489428\n",
      "train loss:0.8509607614790918\n",
      "train loss:1.054633950988533\n",
      "train loss:0.8160795969816526\n",
      "train loss:1.0045603212826197\n",
      "train loss:0.8216540333813702\n",
      "train loss:0.8211249139314473\n",
      "train loss:0.7698327319238829\n",
      "train loss:0.9653478497267585\n",
      "train loss:0.9528642158321904\n",
      "train loss:0.8027343344236317\n",
      "train loss:0.8494379599098707\n",
      "train loss:1.0371731346936128\n",
      "train loss:0.8153801231629353\n",
      "train loss:0.8753948831136475\n",
      "train loss:0.8744440634476506\n",
      "train loss:0.7653239946450497\n",
      "train loss:0.8221823339123702\n",
      "train loss:0.8791604112707359\n",
      "train loss:0.9043727013152677\n",
      "train loss:0.9144544800345971\n",
      "train loss:0.8558209633022292\n",
      "train loss:0.9376160796528462\n",
      "train loss:0.8130669230456092\n",
      "train loss:0.8824842854885175\n",
      "train loss:0.8241140828284859\n",
      "train loss:0.8738524825620151\n",
      "train loss:0.7281909240940433\n",
      "train loss:1.0553278015626073\n",
      "train loss:0.9422456961035303\n",
      "train loss:0.992251046441995\n",
      "train loss:0.9170375714542799\n",
      "train loss:0.8822665139461651\n",
      "train loss:0.9272435253525673\n",
      "train loss:0.8620342247215761\n",
      "train loss:0.8987932364691352\n",
      "train loss:0.8121888478033797\n",
      "train loss:0.7849619072505243\n",
      "train loss:0.8096914382918331\n",
      "train loss:0.9167048503540423\n",
      "train loss:0.780734759528658\n",
      "train loss:0.7647489593236507\n",
      "train loss:0.8083686101454824\n",
      "train loss:0.8518290290317213\n",
      "train loss:0.8638233758949246\n",
      "train loss:0.8752311471993266\n",
      "train loss:0.9347377210991881\n",
      "train loss:0.776461213588074\n",
      "train loss:0.9014656828825273\n",
      "train loss:0.8070544962143377\n",
      "train loss:0.8544408563423519\n",
      "train loss:0.7327272647590114\n",
      "train loss:0.8098898075315063\n",
      "train loss:0.89335873590924\n",
      "train loss:0.932490481892448\n",
      "train loss:0.8272296529989107\n",
      "train loss:0.8610832938099291\n",
      "train loss:0.9303198007805696\n",
      "train loss:0.9139785743069705\n",
      "train loss:0.824163413960978\n",
      "train loss:0.849157135892894\n",
      "train loss:0.8763131909537484\n",
      "train loss:0.8559008094423423\n",
      "train loss:0.9380400666369166\n",
      "train loss:0.8383386101709105\n",
      "train loss:0.7798344430323801\n",
      "train loss:0.7158435358588258\n",
      "train loss:0.9381290186312691\n",
      "train loss:0.8611222904626724\n",
      "train loss:0.8841563754539146\n",
      "train loss:0.7139881710716101\n",
      "train loss:0.987911587841825\n",
      "train loss:0.8798902811576974\n",
      "train loss:0.8716090045218408\n",
      "train loss:0.8561233626646171\n",
      "train loss:0.9444968094106683\n",
      "train loss:0.8741070396311942\n",
      "train loss:0.7657099995250483\n",
      "train loss:0.7095944157839059\n",
      "train loss:0.9036471971928327\n",
      "train loss:0.762711278630935\n",
      "train loss:1.0422150846335487\n",
      "train loss:0.9588382256135627\n",
      "train loss:0.8589815878049599\n",
      "train loss:0.8922717363455733\n",
      "train loss:0.8215273425794821\n",
      "train loss:0.7368831743144287\n",
      "train loss:0.908151223034277\n",
      "train loss:0.7665742047713247\n",
      "train loss:0.835951805832409\n",
      "train loss:0.8911546748738499\n",
      "train loss:0.8063746208592174\n",
      "train loss:0.8239677681426575\n",
      "train loss:0.8462010971730856\n",
      "train loss:0.9167382713491553\n",
      "train loss:0.9609034114339962\n",
      "train loss:0.8785818688212408\n",
      "train loss:0.7504835750349506\n",
      "train loss:0.7615971946603706\n",
      "train loss:0.932395371761602\n",
      "train loss:0.7899481372373743\n",
      "train loss:0.8880787958673334\n",
      "train loss:0.846227225336751\n",
      "train loss:0.7926764102075555\n",
      "train loss:1.1300193155958873\n",
      "train loss:0.8305364785020929\n",
      "train loss:0.9281331186756983\n",
      "train loss:0.8059457208399666\n",
      "train loss:0.8457924446556068\n",
      "train loss:0.9252652909247048\n",
      "train loss:0.9666559923044727\n",
      "train loss:0.7059755955903054\n",
      "train loss:0.7854071077166335\n",
      "train loss:0.7535037906389042\n",
      "train loss:0.9884047169071186\n",
      "train loss:0.7997356242872924\n",
      "train loss:0.8530625547797811\n",
      "train loss:0.8106248721933962\n",
      "train loss:0.9122417962460351\n",
      "train loss:0.8309243649517631\n",
      "train loss:0.9548265867504857\n",
      "train loss:0.7987132374683891\n",
      "train loss:0.8984124002244712\n",
      "train loss:0.8890882841558662\n",
      "train loss:0.8244499526220821\n",
      "train loss:0.7803938480316955\n",
      "train loss:0.8714273476654375\n",
      "train loss:0.7542532479030118\n",
      "train loss:0.9307692371574501\n",
      "train loss:0.8451754488597186\n",
      "train loss:0.9523155524991238\n",
      "train loss:0.8003504602264375\n",
      "train loss:0.8830911817484681\n",
      "train loss:0.9292086911109887\n",
      "train loss:0.7978486347909646\n",
      "train loss:0.839433468303191\n",
      "train loss:0.8873688727206411\n",
      "train loss:0.9158588613260962\n",
      "train loss:0.8476034929180234\n",
      "train loss:0.927513700392432\n",
      "train loss:0.8988035403551653\n",
      "train loss:0.8706984916828518\n",
      "train loss:0.8525663620977162\n",
      "train loss:0.7761203142296356\n",
      "train loss:0.8663713605377121\n",
      "train loss:0.8600203330903766\n",
      "train loss:0.8600896388028025\n",
      "train loss:0.8445903358062974\n",
      "train loss:0.7648926406298238\n",
      "train loss:0.8178930697695622\n",
      "train loss:0.9021187042406734\n",
      "train loss:0.8285140459478161\n",
      "train loss:0.8679299004183164\n",
      "train loss:0.6659557580058363\n",
      "train loss:0.8770948072092914\n",
      "train loss:0.8817029059620566\n",
      "train loss:0.9579326754475597\n",
      "train loss:0.971374133246818\n",
      "train loss:0.7920207689492241\n",
      "train loss:0.9813926921003077\n",
      "train loss:0.8523625559221187\n",
      "train loss:0.7943533907315116\n",
      "train loss:0.997184626747401\n",
      "train loss:1.1466075788287522\n",
      "train loss:0.8199199195863741\n",
      "train loss:0.9683706432804534\n",
      "train loss:0.7734042134496868\n",
      "train loss:0.7499499769657955\n",
      "train loss:0.7178900606162278\n",
      "train loss:0.805181561884002\n",
      "train loss:0.7991752216051641\n",
      "train loss:0.7769961376697758\n",
      "train loss:0.8621212718951493\n",
      "train loss:0.9729471136300993\n",
      "train loss:0.8667142978428454\n",
      "train loss:0.6416157329835159\n",
      "train loss:0.9352404543497927\n",
      "train loss:0.8132786381452355\n",
      "train loss:0.8568689844996615\n",
      "train loss:1.019909221683748\n",
      "train loss:0.8590695791431942\n",
      "train loss:0.8306104848411934\n",
      "train loss:0.9658740431233229\n",
      "train loss:0.8669898608195424\n",
      "train loss:0.9705415120627758\n",
      "train loss:0.785389124892246\n",
      "train loss:0.871980302346546\n",
      "train loss:0.7198712843746512\n",
      "train loss:0.8237604484881098\n",
      "train loss:0.9576655339136461\n",
      "train loss:0.6678325321617723\n",
      "train loss:0.8187154494627662\n",
      "train loss:0.8562823849510649\n",
      "train loss:0.9000243136723204\n",
      "train loss:0.6687411150993796\n",
      "train loss:0.998689759593098\n",
      "train loss:0.7438485439328393\n",
      "train loss:0.8719736906700741\n",
      "train loss:0.8974647494140524\n",
      "train loss:0.8701064329268309\n",
      "train loss:1.0231468290399963\n",
      "train loss:0.8866785709728073\n",
      "train loss:0.7579127095101141\n",
      "train loss:0.8318464357752998\n",
      "train loss:0.7794461849199944\n",
      "train loss:0.9271070722574106\n",
      "train loss:0.8609624430666262\n",
      "train loss:0.9213512056629822\n",
      "train loss:0.7406205312169188\n",
      "train loss:0.9763260807339672\n",
      "train loss:0.8623158261237773\n",
      "train loss:0.9015484000165026\n",
      "train loss:0.9302489751324888\n",
      "train loss:0.9434397730823315\n",
      "train loss:0.7420713073434878\n",
      "train loss:0.804307108033234\n",
      "train loss:0.7030395647782219\n",
      "train loss:0.7604079130059369\n",
      "train loss:0.754363483997892\n",
      "train loss:1.02849526166477\n",
      "train loss:0.7748684940461409\n",
      "train loss:0.8513730707308479\n",
      "train loss:0.9040724375135741\n",
      "train loss:0.9080623800367756\n",
      "train loss:1.010038883127577\n",
      "train loss:0.7462564600928527\n",
      "train loss:0.7572863906650343\n",
      "train loss:0.6377520143983877\n",
      "train loss:0.8303917399435101\n",
      "train loss:1.017033543151316\n",
      "train loss:1.0334515145778698\n",
      "train loss:0.77285375894523\n",
      "train loss:0.7165210911538922\n",
      "train loss:0.9602684823077609\n",
      "train loss:0.992156612698787\n",
      "train loss:0.8353447080868563\n",
      "train loss:0.8130036620357276\n",
      "train loss:0.9839368085153589\n",
      "train loss:0.9106055776329762\n",
      "train loss:0.9468386280482423\n",
      "train loss:0.8977588647969832\n",
      "train loss:1.0086075959886935\n",
      "train loss:0.8207095300463861\n",
      "train loss:0.8089811750064655\n",
      "train loss:0.9031323174352767\n",
      "train loss:0.8162165225009913\n",
      "train loss:0.8505580908292972\n",
      "train loss:0.7345373534828289\n",
      "train loss:0.8563095703542651\n",
      "train loss:0.9174616561782206\n",
      "train loss:0.7826278452656757\n",
      "train loss:0.768860053371563\n",
      "train loss:0.9375451814151505\n",
      "train loss:0.7994596236640449\n",
      "train loss:0.7935017313915363\n",
      "train loss:0.6930316938524145\n",
      "train loss:0.8001643970964106\n",
      "train loss:0.8609818302968384\n",
      "train loss:0.8954416198031655\n",
      "train loss:0.889280805014619\n",
      "train loss:0.8813289075800994\n",
      "train loss:0.7428852931093141\n",
      "train loss:1.0608183428014695\n",
      "train loss:0.8879308189570544\n",
      "train loss:0.8736607769508131\n",
      "train loss:0.7291729659661855\n",
      "train loss:0.7436111415806745\n",
      "train loss:1.0239209584078537\n",
      "train loss:0.8624892626475322\n",
      "train loss:0.9011520361088832\n",
      "train loss:0.751835874425573\n",
      "train loss:0.7131865189625413\n",
      "train loss:0.857197714359115\n",
      "train loss:0.8742857478057638\n",
      "train loss:0.8098277315491492\n",
      "train loss:0.8311164388476054\n",
      "train loss:0.9003991248160677\n",
      "train loss:0.822877560859817\n",
      "train loss:0.8232388333421403\n",
      "train loss:0.8778208682980119\n",
      "train loss:0.6904432662835369\n",
      "train loss:0.919299882764065\n",
      "train loss:0.9622912610309129\n",
      "train loss:0.8243855622301487\n",
      "train loss:0.8916571983568902\n",
      "train loss:0.6982378635261539\n",
      "train loss:0.8598223064664984\n",
      "train loss:0.9113731419631642\n",
      "train loss:0.8815310666646734\n",
      "train loss:0.7740154065006333\n",
      "train loss:0.9961927972894992\n",
      "train loss:1.026999356772701\n",
      "train loss:0.761789484925906\n",
      "train loss:0.7757389639297014\n",
      "train loss:0.8911520176780061\n",
      "train loss:1.0830831318398022\n",
      "train loss:0.8163752895569831\n",
      "train loss:0.7735823400283559\n",
      "train loss:0.7353549914932432\n",
      "train loss:0.9177351644349961\n",
      "train loss:0.9754377691288435\n",
      "train loss:0.9022572584410392\n",
      "train loss:0.6906505701397653\n",
      "train loss:0.8285802341467252\n",
      "train loss:0.7809341245199751\n",
      "train loss:0.9524154085899807\n",
      "train loss:0.8650045643482684\n",
      "train loss:0.7671918002067496\n",
      "train loss:0.9533764941240804\n",
      "train loss:0.8709640106748188\n",
      "train loss:0.904349602179012\n",
      "train loss:0.8754161617331075\n",
      "train loss:0.865540023033255\n",
      "train loss:0.8624844120446941\n",
      "train loss:0.8234323387901474\n",
      "train loss:0.6083587110963324\n",
      "train loss:0.9829129368242749\n",
      "train loss:0.8383922106498989\n",
      "train loss:0.9213801896619381\n",
      "train loss:0.9457639029028386\n",
      "train loss:0.8643435869978426\n",
      "train loss:0.857028299697491\n",
      "train loss:0.860364665429053\n",
      "train loss:0.7770445748569957\n",
      "train loss:0.8486745933191655\n",
      "train loss:0.7988423566755931\n",
      "train loss:0.8517425181361589\n",
      "train loss:0.9721006744922559\n",
      "train loss:0.8918492664973201\n",
      "train loss:0.9621519092102032\n",
      "train loss:0.8682461408670673\n",
      "train loss:0.7721255997169169\n",
      "train loss:0.7918474181907706\n",
      "train loss:0.8025591537228667\n",
      "train loss:0.7750779560370344\n",
      "train loss:0.8167020988525806\n",
      "train loss:0.9773149793041616\n",
      "train loss:0.9363731759969852\n",
      "train loss:0.7738958068801653\n",
      "train loss:0.9438754424920495\n",
      "train loss:0.8394969743893802\n",
      "train loss:0.9411916644366785\n",
      "train loss:0.809946634244387\n",
      "train loss:1.0125452429439747\n",
      "train loss:0.927445691904611\n",
      "train loss:0.8385525902478582\n",
      "train loss:0.9905804084942094\n",
      "train loss:0.8880645382776191\n",
      "train loss:0.7205466942177959\n",
      "train loss:0.9186364071307122\n",
      "train loss:0.849258746550743\n",
      "train loss:1.073031416311226\n",
      "train loss:0.9147379225153329\n",
      "train loss:0.850412957566589\n",
      "train loss:0.8641830547397743\n",
      "train loss:0.9974417738292841\n",
      "train loss:1.0171616344858478\n",
      "train loss:0.9592427690138919\n",
      "train loss:0.8689798099048716\n",
      "train loss:0.7998480956780502\n",
      "train loss:0.8802383516258545\n",
      "train loss:0.8613286156603425\n",
      "train loss:0.8321290900508693\n",
      "train loss:0.6499597966332245\n",
      "train loss:0.8942998025488749\n",
      "train loss:0.7480734354489726\n",
      "train loss:1.0287397559734743\n",
      "train loss:0.7889019108032344\n",
      "train loss:0.8610130764664063\n",
      "train loss:0.9986334755611572\n",
      "train loss:0.7206182983470548\n",
      "train loss:0.7965851315980592\n",
      "train loss:1.0132309470998748\n",
      "train loss:0.8978304069536571\n",
      "train loss:0.960694520398047\n",
      "train loss:0.8024223094523966\n",
      "train loss:0.9097190115913095\n",
      "train loss:0.9421309269985249\n",
      "train loss:0.848722851735744\n",
      "train loss:0.9499315536518373\n",
      "train loss:1.035408014300772\n",
      "train loss:0.8568478884945634\n",
      "train loss:0.8639837128881602\n",
      "train loss:0.9107424541475558\n",
      "train loss:0.9675729848342932\n",
      "train loss:0.9010734776734409\n",
      "train loss:0.8235969437928486\n",
      "train loss:0.79773596902195\n",
      "train loss:0.9262541621626125\n",
      "train loss:0.820061990674934\n",
      "train loss:0.7100170250266494\n",
      "train loss:0.792274598834078\n",
      "train loss:0.9328745897356824\n",
      "train loss:0.8413811309073472\n",
      "train loss:1.0529182633133944\n",
      "train loss:0.9434657529148346\n",
      "train loss:0.6926934089883973\n",
      "train loss:0.9704460873167959\n",
      "train loss:0.8104428816369058\n",
      "train loss:0.6785871110749423\n",
      "train loss:0.8610628463041965\n",
      "train loss:0.9299087121781782\n",
      "train loss:0.969219590442359\n",
      "train loss:0.759829483557636\n",
      "train loss:0.8111197403280201\n",
      "train loss:0.844088585057617\n",
      "train loss:0.9731325053789351\n",
      "train loss:0.9757364169459066\n",
      "train loss:0.8119441031398003\n",
      "train loss:0.9665643307832583\n",
      "train loss:0.8209520079864125\n",
      "train loss:0.8487550993457523\n",
      "train loss:0.7507974505038542\n",
      "train loss:0.7865130604543852\n",
      "train loss:0.861726952385564\n",
      "train loss:0.8935248228557043\n",
      "train loss:0.8454943607333256\n",
      "train loss:0.9361662327536743\n",
      "train loss:0.8602838925326101\n",
      "train loss:0.7625136830535822\n",
      "train loss:0.956117038948081\n",
      "train loss:0.8693041506312755\n",
      "train loss:0.7804517416571843\n",
      "train loss:0.7569391573786888\n",
      "train loss:0.8898165395947868\n",
      "train loss:0.8698923202861928\n",
      "train loss:0.9163160470606252\n",
      "train loss:0.8442362798824472\n",
      "train loss:0.8247104915061964\n",
      "train loss:0.9819855711191711\n",
      "train loss:0.6973639033637059\n",
      "train loss:0.8616705599684475\n",
      "train loss:0.8455685907415824\n",
      "train loss:0.8156997112174719\n",
      "train loss:0.8360582980757691\n",
      "train loss:1.0502028717829526\n",
      "train loss:0.7192218930141406\n",
      "train loss:0.8051491093030638\n",
      "train loss:0.8468576483711588\n",
      "train loss:0.8751195803225167\n",
      "train loss:0.7775721697149747\n",
      "train loss:0.8982901209757465\n",
      "train loss:0.8377139037449162\n",
      "train loss:0.7739316773128416\n",
      "train loss:0.9235576514458734\n",
      "train loss:0.6923493625093442\n",
      "train loss:0.7973910453425949\n",
      "train loss:0.8642270070919181\n",
      "train loss:0.9596487013801575\n",
      "train loss:0.8237767857475984\n",
      "train loss:0.9268365125483232\n",
      "train loss:1.0046500624833394\n",
      "train loss:0.8521732333391236\n",
      "train loss:1.0468335669027653\n",
      "train loss:0.6802328329192774\n",
      "train loss:0.974344476156369\n",
      "train loss:1.0616670555025662\n",
      "train loss:0.8212375763115466\n",
      "train loss:0.9361905740322701\n",
      "train loss:0.9067705929955531\n",
      "train loss:1.0346915406719723\n",
      "train loss:0.8581832231953476\n",
      "train loss:0.9518329292907091\n",
      "train loss:0.8128558736259506\n",
      "train loss:1.0323517336470538\n",
      "train loss:0.9039941378852763\n",
      "train loss:0.8266115623767527\n",
      "train loss:0.8742757774875365\n",
      "train loss:0.9067362983677932\n",
      "train loss:0.786726540739537\n",
      "train loss:0.8409640452222635\n",
      "train loss:0.8481385891487512\n",
      "train loss:0.8706950515029377\n",
      "train loss:0.8304036042729198\n",
      "train loss:0.8630965276466462\n",
      "train loss:0.7585627319687803\n",
      "train loss:0.9830206103428002\n",
      "train loss:0.9263857091216479\n",
      "train loss:0.8168917956916257\n",
      "train loss:0.9955120423091038\n",
      "train loss:0.8362333441409823\n",
      "train loss:0.9369664616013581\n",
      "train loss:0.6932462331966346\n",
      "train loss:0.8948834719893132\n",
      "train loss:0.7834882043608582\n",
      "train loss:0.8667246545574194\n",
      "train loss:0.7557155315736823\n",
      "train loss:0.756112866922861\n",
      "train loss:0.7910911822790128\n",
      "train loss:1.0746117640080786\n",
      "train loss:0.9446928000768591\n",
      "train loss:0.7944683813817431\n",
      "train loss:0.9102938820567222\n",
      "train loss:0.8875204306331571\n",
      "train loss:0.8816443724623295\n",
      "train loss:0.9389153532030341\n",
      "train loss:0.8377839442267161\n",
      "train loss:0.8489581113999864\n",
      "train loss:0.8016477005160698\n",
      "train loss:0.759445536396641\n",
      "train loss:0.8298552254411823\n",
      "train loss:0.7413869969266361\n",
      "train loss:0.8402853515784449\n",
      "train loss:0.774715739456191\n",
      "train loss:0.7381667505495884\n",
      "train loss:0.7817777655234961\n",
      "train loss:0.7402402121689221\n",
      "train loss:1.0357895604088392\n",
      "train loss:0.8016447614665629\n",
      "train loss:1.0099015802359057\n",
      "train loss:0.8586676669252958\n",
      "train loss:0.99962179781522\n",
      "train loss:0.8806616991876901\n",
      "train loss:0.7925839267776479\n",
      "train loss:0.9732949283844918\n",
      "train loss:0.7793951930888916\n",
      "train loss:0.8131085523692596\n",
      "train loss:0.8880154832799492\n",
      "train loss:0.7739958312779133\n",
      "train loss:0.8448028288079159\n",
      "train loss:0.7461732313294683\n",
      "train loss:0.8673530144697306\n",
      "train loss:0.8300013589482771\n",
      "train loss:0.8583399432678472\n",
      "train loss:0.9184464270066794\n",
      "train loss:0.7810461086161037\n",
      "train loss:0.9098379397702814\n",
      "train loss:0.9415596802030243\n",
      "train loss:0.7994183592138002\n",
      "train loss:0.906675008725843\n",
      "train loss:0.8201990831662153\n",
      "train loss:0.9113111350358826\n",
      "train loss:0.7146869032828822\n",
      "train loss:0.8815524832794975\n",
      "train loss:0.7801133713242198\n",
      "train loss:0.9041126032122163\n",
      "train loss:0.801758619723049\n",
      "train loss:0.8491899046512024\n",
      "train loss:0.7109826360684735\n",
      "train loss:0.9762878316369188\n",
      "train loss:0.9961622004455964\n",
      "train loss:0.9595652468159201\n",
      "train loss:0.8557300115539478\n",
      "train loss:0.9742731624980777\n",
      "train loss:1.0404178635282058\n",
      "train loss:0.8498412851511976\n",
      "train loss:0.7239107436839515\n",
      "train loss:0.8275848026518033\n",
      "train loss:0.8106908695250538\n",
      "train loss:0.83660778483957\n",
      "train loss:0.7970503110829796\n",
      "train loss:0.9631458231234248\n",
      "train loss:0.8151061717331856\n",
      "train loss:0.9387926014518254\n",
      "train loss:0.6941795728921136\n",
      "train loss:0.7760210901580981\n",
      "train loss:0.8152440826856414\n",
      "train loss:0.7958130569480696\n",
      "train loss:0.9833155319740244\n",
      "train loss:0.9171443026546151\n",
      "train loss:0.8412776679430186\n",
      "train loss:0.9181143512647497\n",
      "train loss:0.9041080398359673\n",
      "train loss:0.8166271390565825\n",
      "train loss:0.8094147540168507\n",
      "train loss:0.8175531912355548\n",
      "train loss:0.7477082001849995\n",
      "train loss:0.8272318150013132\n",
      "train loss:0.8013215446505835\n",
      "train loss:0.832171784206914\n",
      "train loss:0.771332470525257\n",
      "train loss:0.8450960190679464\n",
      "train loss:0.9635116801466554\n",
      "train loss:0.8571157015127459\n",
      "train loss:0.8628401589024598\n",
      "train loss:0.8363808182070157\n",
      "train loss:0.8768891928042732\n",
      "train loss:0.7962338639472506\n",
      "train loss:0.877873925726953\n",
      "train loss:1.0360433954690011\n",
      "train loss:0.869991315176445\n",
      "train loss:0.9643498958927352\n",
      "train loss:0.7171926785089152\n",
      "train loss:0.8430951927338077\n",
      "train loss:0.8711037139332823\n",
      "train loss:0.9706597027214534\n",
      "train loss:0.9284602550418384\n",
      "=== epoch:19, train acc:0.997, test acc:0.989 ===\n",
      "train loss:0.9231756687230502\n",
      "train loss:0.9645239946082108\n",
      "train loss:0.9776719917479808\n",
      "train loss:0.7439664691709386\n",
      "train loss:0.7513949385866313\n",
      "train loss:0.913371795001416\n",
      "train loss:0.8276679449025974\n",
      "train loss:0.8714208875563157\n",
      "train loss:0.9635527218596522\n",
      "train loss:0.781771220367069\n",
      "train loss:0.8491635105097299\n",
      "train loss:0.771606943383837\n",
      "train loss:0.8890544471616286\n",
      "train loss:0.8191152193170202\n",
      "train loss:0.8411693584757649\n",
      "train loss:0.8296304134071114\n",
      "train loss:1.1072578660513903\n",
      "train loss:0.723027657382304\n",
      "train loss:0.874321100853097\n",
      "train loss:1.0019233804086702\n",
      "train loss:0.9903937849886717\n",
      "train loss:0.7896989112086967\n",
      "train loss:0.8750903401662693\n",
      "train loss:0.7559879170622783\n",
      "train loss:0.831319194787274\n",
      "train loss:0.8969357077726005\n",
      "train loss:0.8753568688925644\n",
      "train loss:0.7913263163793876\n",
      "train loss:1.022158717895351\n",
      "train loss:0.8964204700143554\n",
      "train loss:0.8387808772749591\n",
      "train loss:0.8744478947731689\n",
      "train loss:0.9848818442273667\n",
      "train loss:0.8825693919154493\n",
      "train loss:0.880981899371538\n",
      "train loss:0.8282450772834258\n",
      "train loss:0.9099224553999357\n",
      "train loss:0.8284510809797689\n",
      "train loss:0.9307782636685127\n",
      "train loss:0.828081041274827\n",
      "train loss:0.8498651208578035\n",
      "train loss:0.7808326824327814\n",
      "train loss:0.8985140283895015\n",
      "train loss:0.6904579189241078\n",
      "train loss:0.7700949184965137\n",
      "train loss:0.9363612811530667\n",
      "train loss:0.8079478260236884\n",
      "train loss:0.678717848014222\n",
      "train loss:0.7225349279241092\n",
      "train loss:0.8199437916770459\n",
      "train loss:0.8429783764806379\n",
      "train loss:0.7016559119454776\n",
      "train loss:0.9247475498398642\n",
      "train loss:0.8711524964752292\n",
      "train loss:0.7993980586678081\n",
      "train loss:0.8498500294823309\n",
      "train loss:0.8561996866147321\n",
      "train loss:0.7860723926980416\n",
      "train loss:0.8619864726766793\n",
      "train loss:0.9448182459458937\n",
      "train loss:0.6469697628718434\n",
      "train loss:0.8362795852777046\n",
      "train loss:0.9055179176031934\n",
      "train loss:1.000521092598307\n",
      "train loss:1.021054986182307\n",
      "train loss:0.8168803752536192\n",
      "train loss:0.8601807608849739\n",
      "train loss:0.9881347024279773\n",
      "train loss:0.9427902779652619\n",
      "train loss:0.8453163170627651\n",
      "train loss:0.8774960042166933\n",
      "train loss:0.9250785112864708\n",
      "train loss:0.7767821810077306\n",
      "train loss:0.8266807040691602\n",
      "train loss:0.9138984229484582\n",
      "train loss:0.9892451868521874\n",
      "train loss:0.9587523028818009\n",
      "train loss:0.9908597624567923\n",
      "train loss:0.7478832625827475\n",
      "train loss:0.8477884688000265\n",
      "train loss:0.9967240766215132\n",
      "train loss:0.8296652010279744\n",
      "train loss:0.8612593104995884\n",
      "train loss:0.8657239529516809\n",
      "train loss:0.8966719221229816\n",
      "train loss:0.8588594958400962\n",
      "train loss:0.7428319260384675\n",
      "train loss:0.9252446643283442\n",
      "train loss:0.893436915751439\n",
      "train loss:0.6709338351716139\n",
      "train loss:0.940015245703631\n",
      "train loss:0.8030078177733341\n",
      "train loss:0.740278488398056\n",
      "train loss:1.0817999059965602\n",
      "train loss:0.82723272813002\n",
      "train loss:0.7905423644057278\n",
      "train loss:0.6863207892251276\n",
      "train loss:0.9506168563416668\n",
      "train loss:0.8621085587335132\n",
      "train loss:0.7190648259618573\n",
      "train loss:0.8680876282237056\n",
      "train loss:0.935323414483971\n",
      "train loss:0.8276104542026538\n",
      "train loss:0.8581659367419135\n",
      "train loss:0.9529272816302458\n",
      "train loss:0.8644372627427921\n",
      "train loss:0.786478682823033\n",
      "train loss:0.7842207952594635\n",
      "train loss:0.9623513499050474\n",
      "train loss:0.92066846043726\n",
      "train loss:0.8482230686271113\n",
      "train loss:0.6942507853795452\n",
      "train loss:0.8965531207326046\n",
      "train loss:0.8662067650942453\n",
      "train loss:1.132914574653992\n",
      "train loss:0.9165131871296357\n",
      "train loss:0.8671052618574765\n",
      "train loss:0.8904385211130065\n",
      "train loss:0.8917504324081236\n",
      "train loss:0.827185860605993\n",
      "train loss:0.8040830186460225\n",
      "train loss:0.8144729189466734\n",
      "train loss:0.8897568530405329\n",
      "train loss:0.7764919361772246\n",
      "train loss:0.7975272160304512\n",
      "train loss:0.8142065631063764\n",
      "train loss:0.8964515510646084\n",
      "train loss:0.9097244023040914\n",
      "train loss:0.8654170661426355\n",
      "train loss:0.6295665879553362\n",
      "train loss:0.9002818568279676\n",
      "train loss:0.8264848009305459\n",
      "train loss:0.8370008884918008\n",
      "train loss:0.8603411864770422\n",
      "train loss:0.7487235731972306\n",
      "train loss:0.9753521346940279\n",
      "train loss:0.971413330724335\n",
      "train loss:0.9688350238633864\n",
      "train loss:0.7683661495009269\n",
      "train loss:0.8420281133141901\n",
      "train loss:0.7066592608804624\n",
      "train loss:0.9029192770427429\n",
      "train loss:0.7933267567595912\n",
      "train loss:0.9748677729275527\n",
      "train loss:1.0154978843353195\n",
      "train loss:0.7537179846067539\n",
      "train loss:0.8552796920026872\n",
      "train loss:0.8847357036954129\n",
      "train loss:0.7972234314523758\n",
      "train loss:0.8524100801084825\n",
      "train loss:0.6396336129572628\n",
      "train loss:0.8405035740911133\n",
      "train loss:1.0176338268810243\n",
      "train loss:0.9026897023705418\n",
      "train loss:0.8391874312049111\n",
      "train loss:0.9836131419783699\n",
      "train loss:0.9547632337781906\n",
      "train loss:0.8419797116416382\n",
      "train loss:0.8083643970773727\n",
      "train loss:0.9724345295760796\n",
      "train loss:0.7318995737189339\n",
      "train loss:0.8395695022714139\n",
      "train loss:0.7590854498713473\n",
      "train loss:0.9712795908060582\n",
      "train loss:0.7247912862832621\n",
      "train loss:0.821556323746837\n",
      "train loss:0.8583433475700722\n",
      "train loss:0.9047476070937169\n",
      "train loss:0.9235923980045261\n",
      "train loss:0.8782275574846404\n",
      "train loss:0.8901767333727644\n",
      "train loss:0.904735740483024\n",
      "train loss:0.886961834044991\n",
      "train loss:1.0052089270784428\n",
      "train loss:1.0197681098099851\n",
      "train loss:0.8377060724853049\n",
      "train loss:0.8258208533568028\n",
      "train loss:0.8803982165874311\n",
      "train loss:0.9246155221963654\n",
      "train loss:0.9002529326173335\n",
      "train loss:0.8954933687002764\n",
      "train loss:0.8165884840608938\n",
      "train loss:0.8080310386619931\n",
      "train loss:0.7641518437805906\n",
      "train loss:0.878971239383455\n",
      "train loss:0.9996127849526546\n",
      "train loss:0.5966659967770824\n",
      "train loss:0.9183786708889586\n",
      "train loss:0.8221529069825719\n",
      "train loss:0.7736836043797578\n",
      "train loss:0.877140295415731\n",
      "train loss:0.7775502661571612\n",
      "train loss:0.8421397307884488\n",
      "train loss:0.8040024853797152\n",
      "train loss:0.7879537151243557\n",
      "train loss:0.9784638783403523\n",
      "train loss:0.9852205309720845\n",
      "train loss:0.7706710075359777\n",
      "train loss:0.8220723130934539\n",
      "train loss:0.7448271091012921\n",
      "train loss:0.9088182953670326\n",
      "train loss:0.9674377195631773\n",
      "train loss:0.8209702953006932\n",
      "train loss:0.8976187360729262\n",
      "train loss:1.1098298563086946\n",
      "train loss:0.7696047185173492\n",
      "train loss:0.8014119991327222\n",
      "train loss:0.6993631579108691\n",
      "train loss:0.7017577795552488\n",
      "train loss:0.8820799740477682\n",
      "train loss:0.8738171025459229\n",
      "train loss:0.9971280336353422\n",
      "train loss:0.9485436353011691\n",
      "train loss:0.8422873822258601\n",
      "train loss:0.8380418861971561\n",
      "train loss:0.9162341308221019\n",
      "train loss:0.842618485960023\n",
      "train loss:1.0009645890020384\n",
      "train loss:0.841165954840583\n",
      "train loss:0.9769264175383386\n",
      "train loss:0.9216673491980356\n",
      "train loss:0.8445472148775214\n",
      "train loss:0.9214930360211823\n",
      "train loss:0.7275755639601339\n",
      "train loss:0.7593168507679057\n",
      "train loss:0.8774279056357637\n",
      "train loss:0.796836083291883\n",
      "train loss:0.8465418270730537\n",
      "train loss:0.9281921456797697\n",
      "train loss:0.7569575495544822\n",
      "train loss:0.7287119811082176\n",
      "train loss:0.8537951191261476\n",
      "train loss:0.8878560264517351\n",
      "train loss:0.8631214265871597\n",
      "train loss:0.8549181245969969\n",
      "train loss:0.8318708206036933\n",
      "train loss:0.9115336473495732\n",
      "train loss:0.9021174747859123\n",
      "train loss:0.8496346793528873\n",
      "train loss:0.8516292739103513\n",
      "train loss:0.7281272750328688\n",
      "train loss:0.9534043352350633\n",
      "train loss:1.013966622923032\n",
      "train loss:0.9062675253644605\n",
      "train loss:0.8128897333675467\n",
      "train loss:0.8018768348722758\n",
      "train loss:0.896274602226356\n",
      "train loss:0.7353550609519452\n",
      "train loss:0.9745923465153116\n",
      "train loss:0.9089615135902072\n",
      "train loss:0.8911502010654431\n",
      "train loss:0.9535939578482435\n",
      "train loss:0.9891367378479649\n",
      "train loss:0.8730366880357182\n",
      "train loss:0.8585980378079623\n",
      "train loss:0.7964477896273933\n",
      "train loss:0.985307641021205\n",
      "train loss:0.9110201306334734\n",
      "train loss:1.0202571348508973\n",
      "train loss:0.7469538878352999\n",
      "train loss:0.9544686770608322\n",
      "train loss:0.9741446408106346\n",
      "train loss:0.8186928660108299\n",
      "train loss:0.8972903566268658\n",
      "train loss:0.8869674473390973\n",
      "train loss:0.8207752027157207\n",
      "train loss:1.000243441100722\n",
      "train loss:0.8696000195717943\n",
      "train loss:0.846943501525731\n",
      "train loss:0.9180953930548706\n",
      "train loss:0.8479475540227931\n",
      "train loss:0.8592223872634875\n",
      "train loss:0.7908107230009405\n",
      "train loss:0.9109602330644738\n",
      "train loss:0.7582275683055013\n",
      "train loss:0.8661389982730907\n",
      "train loss:0.8587430689597536\n",
      "train loss:0.9431977698734378\n",
      "train loss:0.8973113655648908\n",
      "train loss:0.8253446726482632\n",
      "train loss:1.1016004583371155\n",
      "train loss:0.8927570363672794\n",
      "train loss:0.741317429087799\n",
      "train loss:0.6507945741006894\n",
      "train loss:0.9003143005225082\n",
      "train loss:0.85157302804683\n",
      "train loss:0.752990636817666\n",
      "train loss:0.6041649070307491\n",
      "train loss:0.8083299344755629\n",
      "train loss:0.7260910652095981\n",
      "train loss:0.8844483747914582\n",
      "train loss:0.9071297341972486\n",
      "train loss:0.8781346219307005\n",
      "train loss:0.9805597876056139\n",
      "train loss:0.780802318784056\n",
      "train loss:0.7906523629284345\n",
      "train loss:0.8423957608815082\n",
      "train loss:0.7974098147186404\n",
      "train loss:0.7959237479549094\n",
      "train loss:0.8822638673462316\n",
      "train loss:0.8670116297213863\n",
      "train loss:0.8167844320668278\n",
      "train loss:0.9308539593221293\n",
      "train loss:0.7833571586569791\n",
      "train loss:0.7785546559349418\n",
      "train loss:0.911568951199252\n",
      "train loss:0.818233946648887\n",
      "train loss:0.8189400661396447\n",
      "train loss:0.9224413482169893\n",
      "train loss:0.7392950232330042\n",
      "train loss:0.9677626145759177\n",
      "train loss:0.7728959622087135\n",
      "train loss:0.9509181967440571\n",
      "train loss:0.7554810170957801\n",
      "train loss:0.900221242498416\n",
      "train loss:0.9375201943175753\n",
      "train loss:0.7855289383080154\n",
      "train loss:0.6420386022454782\n",
      "train loss:0.8316990040096985\n",
      "train loss:0.8386033741119283\n",
      "train loss:0.7909041661122749\n",
      "train loss:0.879181281447008\n",
      "train loss:0.917511335575411\n",
      "train loss:0.7808845273135745\n",
      "train loss:0.7390667509183583\n",
      "train loss:0.8559011564960466\n",
      "train loss:0.9631053289903615\n",
      "train loss:0.7113055710223806\n",
      "train loss:0.7914468811422626\n",
      "train loss:0.8109577191687708\n",
      "train loss:0.7193480142980466\n",
      "train loss:0.6780115248626304\n",
      "train loss:0.8773302953664871\n",
      "train loss:0.8819892942509345\n",
      "train loss:0.8177239411322113\n",
      "train loss:0.8290755349151532\n",
      "train loss:0.9003570638749453\n",
      "train loss:0.8151089976429522\n",
      "train loss:0.7870616239266154\n",
      "train loss:0.8781386756948738\n",
      "train loss:0.8132927295636833\n",
      "train loss:0.8219539557155948\n",
      "train loss:1.0852252489755891\n",
      "train loss:0.9501141357198967\n",
      "train loss:0.675452515075311\n",
      "train loss:0.8202752519734176\n",
      "train loss:0.9308423252823559\n",
      "train loss:0.9146963266104534\n",
      "train loss:0.7455735900206004\n",
      "train loss:0.7153837879575317\n",
      "train loss:0.8881600948257135\n",
      "train loss:0.9260075214345964\n",
      "train loss:0.9046092073869874\n",
      "train loss:0.6349420274697084\n",
      "train loss:0.9672653197761575\n",
      "train loss:0.8818867489169955\n",
      "train loss:0.9588597492178583\n",
      "train loss:0.8923067311477618\n",
      "train loss:0.8824143722808908\n",
      "train loss:0.8419011411128339\n",
      "train loss:0.6080478716056882\n",
      "train loss:0.6536736023503233\n",
      "train loss:0.8780914453215531\n",
      "train loss:0.9194131330570393\n",
      "train loss:0.8555707641188279\n",
      "train loss:0.7997292617772535\n",
      "train loss:0.7428003362985346\n",
      "train loss:0.8686533892026844\n",
      "train loss:0.918016288490076\n",
      "train loss:0.8890992509860365\n",
      "train loss:0.90720323439211\n",
      "train loss:0.8603482723656236\n",
      "train loss:0.8476296179290459\n",
      "train loss:0.7685447321269134\n",
      "train loss:0.8151286970290282\n",
      "train loss:0.9097326612312154\n",
      "train loss:0.7744465409942607\n",
      "train loss:0.8358673928056929\n",
      "train loss:0.7973252985389696\n",
      "train loss:0.7476759799179553\n",
      "train loss:0.7780552171131412\n",
      "train loss:0.6857437314643046\n",
      "train loss:0.8265067736248429\n",
      "train loss:0.9530690928141817\n",
      "train loss:0.8632979551204929\n",
      "train loss:0.8518814474596188\n",
      "train loss:0.8112910468696151\n",
      "train loss:0.7523190000213148\n",
      "train loss:0.9304632647602641\n",
      "train loss:0.9627699843570703\n",
      "train loss:0.6893293846505251\n",
      "train loss:0.9357324615361711\n",
      "train loss:0.9868610834402959\n",
      "train loss:0.8643254686142638\n",
      "train loss:0.8382225501843682\n",
      "train loss:1.0459801231840138\n",
      "train loss:0.9567489143962092\n",
      "train loss:0.999808779024842\n",
      "train loss:0.9349422659023816\n",
      "train loss:0.7724439677931855\n",
      "train loss:0.9897876599078753\n",
      "train loss:0.8052166235414893\n",
      "train loss:0.8829461332457785\n",
      "train loss:0.7268520405084853\n",
      "train loss:1.0116066197024078\n",
      "train loss:0.7399409509486925\n",
      "train loss:0.8260074484940134\n",
      "train loss:0.937356057756498\n",
      "train loss:0.8786089008033633\n",
      "train loss:0.8543016807659629\n",
      "train loss:0.8839394442773816\n",
      "train loss:0.7904168797418627\n",
      "train loss:0.8901137887506329\n",
      "train loss:0.8107222245678993\n",
      "train loss:0.665617857986129\n",
      "train loss:0.8423283981955896\n",
      "train loss:0.7522915231950995\n",
      "train loss:0.9337690758725408\n",
      "train loss:0.8680933396502367\n",
      "train loss:0.8092520717613729\n",
      "train loss:0.8046306241087643\n",
      "train loss:0.9042016679062947\n",
      "train loss:0.7586621296949231\n",
      "train loss:0.78850477601965\n",
      "train loss:0.8578842301238957\n",
      "train loss:0.6611557302312554\n",
      "train loss:0.7822409334313742\n",
      "train loss:0.9321365810086492\n",
      "train loss:0.8759230372367058\n",
      "train loss:0.786517189296395\n",
      "train loss:0.7398365197565543\n",
      "train loss:0.8931551780223631\n",
      "train loss:0.8169687656031849\n",
      "train loss:0.9046275784508079\n",
      "train loss:0.9042258198484039\n",
      "train loss:0.8952953985264762\n",
      "train loss:1.0253918766731447\n",
      "train loss:0.8546485703780291\n",
      "train loss:1.065165437284274\n",
      "train loss:0.8016461784949073\n",
      "train loss:1.107172344899116\n",
      "train loss:0.765428742165196\n",
      "train loss:0.886297645854611\n",
      "train loss:0.7609928668813076\n",
      "train loss:0.7644871965600396\n",
      "train loss:0.7755551271220611\n",
      "train loss:0.8761326664711335\n",
      "train loss:0.8861179443271098\n",
      "train loss:0.8147063066384397\n",
      "train loss:0.9277407940329715\n",
      "train loss:0.942686642309538\n",
      "train loss:0.821223539587404\n",
      "train loss:0.878639979717205\n",
      "train loss:0.9472720565934705\n",
      "train loss:0.9739999815024121\n",
      "train loss:0.8204774062184029\n",
      "train loss:1.006218758742696\n",
      "train loss:0.9762912984221191\n",
      "train loss:0.8293404656659075\n",
      "train loss:0.927491153294513\n",
      "train loss:1.0883410322837932\n",
      "train loss:0.9763535279660924\n",
      "train loss:0.7254011685261301\n",
      "train loss:0.9474828191355517\n",
      "train loss:0.7589677054119777\n",
      "train loss:0.8190152080819307\n",
      "train loss:0.8179699499602981\n",
      "train loss:0.7601757680302133\n",
      "train loss:0.7538196515324422\n",
      "train loss:0.9843364891442369\n",
      "train loss:1.061069151136956\n",
      "train loss:0.7049143377751801\n",
      "train loss:0.8418650099735595\n",
      "train loss:0.8109328401402558\n",
      "train loss:0.7906720339250188\n",
      "train loss:0.8210936902157384\n",
      "train loss:0.7916943550988402\n",
      "train loss:0.9296930253378755\n",
      "train loss:0.8647281212702796\n",
      "train loss:0.8760491277010515\n",
      "train loss:0.9339569920539461\n",
      "train loss:0.7086042478856228\n",
      "train loss:0.9511070978559379\n",
      "train loss:0.9535026795278942\n",
      "train loss:0.918046009591796\n",
      "train loss:0.711918475876597\n",
      "train loss:0.8955675535555869\n",
      "train loss:0.7220919543757486\n",
      "train loss:0.7465434028934397\n",
      "train loss:0.872365376160861\n",
      "train loss:0.8361019262667138\n",
      "train loss:0.8513303818990926\n",
      "train loss:0.9702180005625647\n",
      "train loss:0.8645857822404294\n",
      "train loss:0.853188202631345\n",
      "train loss:0.8880155906149291\n",
      "train loss:0.9006329311163342\n",
      "train loss:0.8538842581948002\n",
      "train loss:0.87494511921624\n",
      "train loss:0.846992917241953\n",
      "train loss:0.8951429401422862\n",
      "train loss:0.7094087600476654\n",
      "train loss:0.9359173371905493\n",
      "train loss:0.935300205417713\n",
      "train loss:0.7839808159720502\n",
      "train loss:0.8268426956076077\n",
      "train loss:0.8645109733036134\n",
      "train loss:0.9777437275306453\n",
      "train loss:0.9452373622368688\n",
      "train loss:0.9046652104054068\n",
      "train loss:0.8578343737277215\n",
      "train loss:0.8073285937394934\n",
      "train loss:0.7473839422859438\n",
      "train loss:0.806109706028516\n",
      "train loss:0.7690842779171764\n",
      "train loss:0.8006552655368228\n",
      "train loss:0.9221318985631938\n",
      "train loss:0.9826654948439629\n",
      "train loss:0.6496850086869266\n",
      "train loss:0.878196451122839\n",
      "train loss:0.7431796163979711\n",
      "train loss:0.6487060284249366\n",
      "train loss:0.6400557604707767\n",
      "train loss:0.9269841755999083\n",
      "train loss:0.9234790489509751\n",
      "train loss:0.958472479810348\n",
      "train loss:0.9092580185047039\n",
      "train loss:0.846630393932755\n",
      "train loss:0.8258314980836502\n",
      "train loss:0.8512465782421517\n",
      "train loss:0.9866440350403333\n",
      "train loss:0.7284246817063275\n",
      "train loss:0.8223662352131506\n",
      "train loss:0.8141341173613977\n",
      "train loss:0.7998221743077992\n",
      "train loss:0.9666907262215695\n",
      "train loss:0.936138777881014\n",
      "train loss:1.0328259967182214\n",
      "train loss:0.9745685837324655\n",
      "train loss:0.872827826684003\n",
      "train loss:0.8808493129743487\n",
      "train loss:0.8179567311608564\n",
      "train loss:0.870085023969589\n",
      "train loss:0.9172700926317211\n",
      "train loss:0.9490434864163927\n",
      "train loss:0.9094445755921153\n",
      "train loss:0.8307265255284447\n",
      "train loss:0.8163102444683967\n",
      "train loss:0.9075080798653841\n",
      "train loss:0.7160159807709949\n",
      "train loss:0.879398007980414\n",
      "train loss:0.8887220637472844\n",
      "train loss:0.9342461876457555\n",
      "train loss:0.7433763231249099\n",
      "train loss:0.8790859609772993\n",
      "train loss:0.887614227313779\n",
      "train loss:0.880985939804281\n",
      "train loss:0.866307056106687\n",
      "train loss:0.968829284419664\n",
      "train loss:0.9973578578234938\n",
      "train loss:0.7688410319802577\n",
      "train loss:0.7158741771095198\n",
      "train loss:0.900901900564417\n",
      "train loss:0.8869064480463483\n",
      "train loss:0.7995091730984194\n",
      "train loss:0.7584158994090092\n",
      "train loss:1.0058053566955134\n",
      "train loss:0.866610948015434\n",
      "train loss:0.9336011888002019\n",
      "train loss:0.9075193464533615\n",
      "train loss:0.7742139787726003\n",
      "train loss:0.785702869751281\n",
      "train loss:0.766923719820146\n",
      "train loss:0.9078488884465624\n",
      "train loss:0.8693708292302956\n",
      "train loss:0.7442542499397297\n",
      "train loss:0.7534465249425609\n",
      "train loss:0.794786743931323\n",
      "train loss:0.9066067430041234\n",
      "train loss:0.8727580859881624\n",
      "train loss:0.92256980730378\n",
      "train loss:0.8507152272954372\n",
      "train loss:0.7652436873215906\n",
      "train loss:0.7712142895701101\n",
      "train loss:1.0227330819030704\n",
      "train loss:0.9709128385375152\n",
      "train loss:1.077474408946861\n",
      "train loss:0.7556936312722045\n",
      "train loss:0.8852775433656245\n",
      "train loss:0.778395918500817\n",
      "train loss:0.9460847049379214\n",
      "train loss:0.8675446665899544\n",
      "train loss:0.9083088470955448\n",
      "train loss:0.8996702902967066\n",
      "train loss:0.9509713409744751\n",
      "train loss:0.8260977862204814\n",
      "train loss:0.990992361305214\n",
      "train loss:0.7979380452060382\n",
      "train loss:0.8541406525023615\n",
      "train loss:0.8954494404018222\n",
      "=== epoch:20, train acc:0.998, test acc:0.99 ===\n",
      "train loss:0.941226806043547\n",
      "train loss:0.9426689332708486\n",
      "train loss:0.8526526239196934\n",
      "train loss:0.87314749585768\n",
      "train loss:0.8995003081929894\n",
      "train loss:0.7520176038239641\n",
      "train loss:0.9072819527516229\n",
      "train loss:0.8785503040573164\n",
      "train loss:0.8890382024986911\n",
      "train loss:0.8288907753950006\n",
      "train loss:0.8199515999758011\n",
      "train loss:0.8775718304922553\n",
      "train loss:0.8900448184568736\n",
      "train loss:0.8255937627930103\n",
      "train loss:0.9541939059586386\n",
      "train loss:0.7945089504593503\n",
      "train loss:0.7972710717955959\n",
      "train loss:0.9065239160302826\n",
      "train loss:0.9081001090260227\n",
      "train loss:0.7869000613067145\n",
      "train loss:0.7578228831746351\n",
      "train loss:0.8430145130884307\n",
      "train loss:0.917476999429217\n",
      "train loss:0.8197369074917253\n",
      "train loss:0.9074482553748622\n",
      "train loss:0.9650557834632132\n",
      "train loss:1.0398236595246515\n",
      "train loss:0.9504305618742225\n",
      "train loss:0.8792494199627277\n",
      "train loss:0.7367319212457553\n",
      "train loss:0.8140124286958854\n",
      "train loss:0.9262356792218251\n",
      "train loss:0.8106667652001666\n",
      "train loss:0.8492711265576809\n",
      "train loss:0.8546310868239619\n",
      "train loss:0.913869881706613\n",
      "train loss:0.8559830300171075\n",
      "train loss:0.7196365723649548\n",
      "train loss:0.8301369930309075\n",
      "train loss:0.9458740064421276\n",
      "train loss:0.8709570253190074\n",
      "train loss:0.7530730267180225\n",
      "train loss:0.7876532336870712\n",
      "train loss:0.9989254315027941\n",
      "train loss:0.7725277565252137\n",
      "train loss:0.8786303788170636\n",
      "train loss:0.8049547484257208\n",
      "train loss:0.8667483030212877\n",
      "train loss:0.8964364772868746\n",
      "train loss:0.7321896189599336\n",
      "train loss:0.8848248416027737\n",
      "train loss:0.8417489125921473\n",
      "train loss:0.9302427534067279\n",
      "train loss:0.8917277840843575\n",
      "train loss:0.8997673722799331\n",
      "train loss:0.8410810421092365\n",
      "train loss:0.9129602043436349\n",
      "train loss:0.8993297677669158\n",
      "train loss:0.849617390819877\n",
      "train loss:0.8066623972782406\n",
      "train loss:0.8381174255627428\n",
      "train loss:0.8882588341509663\n",
      "train loss:0.7417758198303747\n",
      "train loss:0.8209347792795363\n",
      "train loss:0.805010482885961\n",
      "train loss:0.8996517620038884\n",
      "train loss:0.8550952021128717\n",
      "train loss:0.676227651532915\n",
      "train loss:0.8053132477709842\n",
      "train loss:0.9731524342601432\n",
      "train loss:0.9736018691478527\n",
      "train loss:0.8905990480568682\n",
      "train loss:0.765501794221844\n",
      "train loss:0.7501531482258721\n",
      "train loss:0.7493809100683225\n",
      "train loss:0.8220950912964257\n",
      "train loss:0.9415194633493336\n",
      "train loss:0.8304697777707724\n",
      "train loss:0.8569570651804038\n",
      "train loss:0.8256664483353819\n",
      "train loss:0.7955156390267736\n",
      "train loss:0.9771169840054393\n",
      "train loss:0.8311524321789642\n",
      "train loss:0.9052878680005706\n",
      "train loss:0.7992829433868319\n",
      "train loss:0.7265695060577952\n",
      "train loss:0.6346151410656928\n",
      "train loss:0.9857803782029718\n",
      "train loss:0.8092470698567307\n",
      "train loss:0.7677959587674748\n",
      "train loss:0.8316189084818768\n",
      "train loss:0.9230624859717258\n",
      "train loss:0.8496121562592767\n",
      "train loss:0.9342366369904085\n",
      "train loss:0.8487832993966122\n",
      "train loss:0.6535913680631148\n",
      "train loss:0.9087832530416406\n",
      "train loss:0.9298315396818374\n",
      "train loss:0.9503448997379944\n",
      "train loss:0.8698754242579916\n",
      "train loss:0.7785707271135689\n",
      "train loss:0.828448308770654\n",
      "train loss:0.8222640342114171\n",
      "train loss:0.934825691801596\n",
      "train loss:0.6957458354560092\n",
      "train loss:0.9023719635398868\n",
      "train loss:0.873134541860967\n",
      "train loss:0.8125904280848544\n",
      "train loss:0.8970203419649689\n",
      "train loss:0.9744946628393096\n",
      "train loss:0.7547561501224016\n",
      "train loss:0.9452112896083037\n",
      "train loss:0.996035952091173\n",
      "train loss:1.0787374089142359\n",
      "train loss:0.8016431921879387\n",
      "train loss:0.6013061887470346\n",
      "train loss:0.8128979404556393\n",
      "train loss:0.9404088660337538\n",
      "train loss:0.7302525688911468\n",
      "train loss:0.8609573757374908\n",
      "train loss:1.0346822369774598\n",
      "train loss:0.7785003132565653\n",
      "train loss:0.7916890705377202\n",
      "train loss:0.8990490515874923\n",
      "train loss:0.870746777995057\n",
      "train loss:0.7618346731218704\n",
      "train loss:0.9607250172369253\n",
      "train loss:0.8213378482633991\n",
      "train loss:1.0368862485907984\n",
      "train loss:0.8294495571623232\n",
      "train loss:0.8646402342888829\n",
      "train loss:0.7196414090343575\n",
      "train loss:0.8109063965364552\n",
      "train loss:0.8888123750731017\n",
      "train loss:0.8781788718950648\n",
      "train loss:0.8544571018481032\n",
      "train loss:0.841974135949694\n",
      "train loss:0.7349424582233166\n",
      "train loss:0.6652101256357957\n",
      "train loss:0.867396391417294\n",
      "train loss:0.9334617343477544\n",
      "train loss:0.8012067836970909\n",
      "train loss:0.7683713928370071\n",
      "train loss:0.9095505794868938\n",
      "train loss:0.8969512829918463\n",
      "train loss:0.8807953121905295\n",
      "train loss:0.809844689881716\n",
      "train loss:0.9844961955708185\n",
      "train loss:0.941890238468403\n",
      "train loss:0.9002131111909862\n",
      "train loss:0.8418500644042705\n",
      "train loss:0.7560936427894036\n",
      "train loss:0.946064474326501\n",
      "train loss:0.8764102021124898\n",
      "train loss:0.9200047091937974\n",
      "train loss:0.9027480621520412\n",
      "train loss:0.7883732166242866\n",
      "train loss:0.7979392734975089\n",
      "train loss:0.7327027626796351\n",
      "train loss:0.910732214033213\n",
      "train loss:0.8690899264820031\n",
      "train loss:0.8057375933392616\n",
      "train loss:0.8323776580316656\n",
      "train loss:0.7965666939405299\n",
      "train loss:0.934943043840738\n",
      "train loss:0.9185125290074335\n",
      "train loss:0.8842996556731899\n",
      "train loss:0.9239125852883973\n",
      "train loss:0.93032938578195\n",
      "train loss:0.8730417884790117\n",
      "train loss:0.8229546516206616\n",
      "train loss:0.8675425294718331\n",
      "train loss:0.8598190998071861\n",
      "train loss:0.9308601731668423\n",
      "train loss:0.8737636319789517\n",
      "train loss:0.8838941778523748\n",
      "train loss:0.8812177139759424\n",
      "train loss:0.7308647654368349\n",
      "train loss:0.8386442759904631\n",
      "train loss:0.8115099088669104\n",
      "train loss:0.8416233551997899\n",
      "train loss:0.7984194236487572\n",
      "train loss:0.9336184702891951\n",
      "train loss:0.9724103266683402\n",
      "train loss:0.8093474807134915\n",
      "train loss:0.842163208326602\n",
      "train loss:0.8002064354161922\n",
      "train loss:0.9053415864615505\n",
      "train loss:0.8669886223062587\n",
      "train loss:0.8918065478025129\n",
      "train loss:0.6819851000061307\n",
      "train loss:0.8138855372550917\n",
      "train loss:0.8824774503099116\n",
      "train loss:0.9987794325054069\n",
      "train loss:1.0178199396023384\n",
      "train loss:0.9378256001149501\n",
      "train loss:0.8445908857981108\n",
      "train loss:0.8415485857490174\n",
      "train loss:0.8468159761373214\n",
      "train loss:0.8306710565746422\n",
      "train loss:0.7665151862776766\n",
      "train loss:0.8232586985884112\n",
      "train loss:0.7750221014525447\n",
      "train loss:0.8613909128951319\n",
      "train loss:0.803141010113709\n",
      "train loss:0.8661272482454235\n",
      "train loss:0.8618232545033151\n",
      "train loss:0.8558810663582461\n",
      "train loss:0.7246919707682897\n",
      "train loss:0.8819029301736588\n",
      "train loss:0.8106352335165431\n",
      "train loss:0.7875460203079389\n",
      "train loss:0.898493924345324\n",
      "train loss:0.8467866224266151\n",
      "train loss:0.9398383594469502\n",
      "train loss:0.8838246892774029\n",
      "train loss:0.661414552537333\n",
      "train loss:0.8533762362053642\n",
      "train loss:0.8986980481349732\n",
      "train loss:0.8300015633817845\n",
      "train loss:0.8055073248779909\n",
      "train loss:0.7889959802567488\n",
      "train loss:0.8845371562906809\n",
      "train loss:0.8408976982424676\n",
      "train loss:0.740062947786024\n",
      "train loss:0.7478658199630914\n",
      "train loss:0.9952403911839174\n",
      "train loss:0.9111536857939967\n",
      "train loss:0.8025827339871517\n",
      "train loss:0.8055151978103813\n",
      "train loss:0.8171473146976947\n",
      "train loss:0.8347066973422719\n",
      "train loss:0.8148447011677675\n",
      "train loss:0.8550602666980874\n",
      "train loss:0.8231132647574644\n",
      "train loss:0.7031382716141925\n",
      "train loss:0.8552998397784196\n",
      "train loss:0.8392190665823233\n",
      "train loss:0.7304612917727951\n",
      "train loss:0.9510298672600943\n",
      "train loss:0.9743965205780435\n",
      "train loss:1.0159184323418524\n",
      "train loss:0.91113979866753\n",
      "train loss:1.0566622510035344\n",
      "train loss:0.7132261728953294\n",
      "train loss:0.8557783565518114\n",
      "train loss:0.8506795197885125\n",
      "train loss:0.9384253204073107\n",
      "train loss:0.8994208370957948\n",
      "train loss:1.1453088239722222\n",
      "train loss:0.853321114531264\n",
      "train loss:0.8296363581194011\n",
      "train loss:1.004431683531266\n",
      "train loss:0.8371213067655742\n",
      "train loss:0.8312785471652377\n",
      "train loss:0.7674489313058364\n",
      "train loss:0.8750021985161313\n",
      "train loss:0.8366382354077977\n",
      "train loss:0.7442973867302622\n",
      "train loss:1.0083627734669935\n",
      "train loss:0.7855199276972716\n",
      "train loss:0.7596261340455339\n",
      "train loss:0.7054344842538706\n",
      "train loss:0.9130322953966423\n",
      "train loss:0.8776909180645777\n",
      "train loss:0.6927983054364749\n",
      "train loss:0.8942422750841632\n",
      "train loss:0.7776690028464276\n",
      "train loss:0.6927247157516584\n",
      "train loss:0.9050856416988559\n",
      "train loss:0.9564898576628\n",
      "train loss:0.8652484103729488\n",
      "train loss:0.8191984291997666\n",
      "train loss:0.9735439236811171\n",
      "train loss:0.9826452648723617\n",
      "train loss:0.9180893626168681\n",
      "train loss:0.8484251173757339\n",
      "train loss:0.8327308713523798\n",
      "train loss:0.8655011537186305\n",
      "train loss:0.7483327474302593\n",
      "train loss:0.8028933730558444\n",
      "train loss:0.7646832340749465\n",
      "train loss:1.0057738013603181\n",
      "train loss:0.8886856057289424\n",
      "train loss:0.8308855351232808\n",
      "train loss:0.8397096705103348\n",
      "train loss:0.7966769735108288\n",
      "train loss:0.8696658072117986\n",
      "train loss:0.780369009811691\n",
      "train loss:0.6652458788484417\n",
      "train loss:0.7419771993148926\n",
      "train loss:0.9434083270821731\n",
      "train loss:0.8057597387027464\n",
      "train loss:0.7550417242441044\n",
      "train loss:0.816591594534894\n",
      "train loss:0.7059013326769863\n",
      "train loss:0.9430229923021929\n",
      "train loss:0.8852661208609552\n",
      "train loss:0.821986667971973\n",
      "train loss:0.9082999849590859\n",
      "train loss:0.8749499369783544\n",
      "train loss:0.7217486600485296\n",
      "train loss:0.8153375521855273\n",
      "train loss:0.8265294184513431\n",
      "train loss:0.9026569296035031\n",
      "train loss:0.884689565422252\n",
      "train loss:0.6839872654614405\n",
      "train loss:0.8172093499148407\n",
      "train loss:0.812209864322884\n",
      "train loss:0.8560292371862361\n",
      "train loss:0.8888523250273087\n",
      "train loss:0.76960976626635\n",
      "train loss:0.9302696540880793\n",
      "train loss:0.8249487623741638\n",
      "train loss:0.9050780582202494\n",
      "train loss:0.9271009173820005\n",
      "train loss:0.8994668329275265\n",
      "train loss:0.8036165095108724\n",
      "train loss:0.9969042287440015\n",
      "train loss:0.7724761627414877\n",
      "train loss:0.8281873416576065\n",
      "train loss:0.9406814435740304\n",
      "train loss:0.807958062013089\n",
      "train loss:0.8305519243765813\n",
      "train loss:0.927607800047785\n",
      "train loss:0.8722342157467314\n",
      "train loss:0.8483841149564576\n",
      "train loss:0.9034073322755372\n",
      "train loss:0.7009239633866536\n",
      "train loss:0.7560430999990767\n",
      "train loss:1.0007267054359874\n",
      "train loss:0.985028887050418\n",
      "train loss:0.8356586507752455\n",
      "train loss:0.9291565037456111\n",
      "train loss:1.0079627660306472\n",
      "train loss:0.9109578073199845\n",
      "train loss:0.80189181885656\n",
      "train loss:0.8636368519188052\n",
      "train loss:0.8442721692759106\n",
      "train loss:0.7706843989456931\n",
      "train loss:0.8028538967298651\n",
      "train loss:0.9152541067710703\n",
      "train loss:0.8229834187498628\n",
      "train loss:0.8904850773431839\n",
      "train loss:0.692712038944531\n",
      "train loss:0.8680288532996611\n",
      "train loss:0.6989943969363965\n",
      "train loss:0.8293936322002559\n",
      "train loss:0.7711426353027951\n",
      "train loss:1.0138561831639719\n",
      "train loss:0.8996155331713961\n",
      "train loss:0.8142295513343509\n",
      "train loss:0.7606440325372845\n",
      "train loss:0.8308723346800869\n",
      "train loss:1.0151927453759555\n",
      "train loss:0.8856662518271483\n",
      "train loss:0.7484608510585482\n",
      "train loss:0.950517602530671\n",
      "train loss:0.7418121891744077\n",
      "train loss:0.907895042619116\n",
      "train loss:0.8616057652929703\n",
      "train loss:0.9009184140393282\n",
      "train loss:1.0047019991193025\n",
      "train loss:0.9199747122614323\n",
      "train loss:1.038169707206544\n",
      "train loss:0.6722749023659894\n",
      "train loss:0.9185161720660179\n",
      "train loss:0.7769245303806772\n",
      "train loss:0.877344882352103\n",
      "train loss:0.6512092876801229\n",
      "train loss:0.9719351736283326\n",
      "train loss:0.8681478352683416\n",
      "train loss:0.9060571229510631\n",
      "train loss:0.9213629541519193\n",
      "train loss:0.8781281949284309\n",
      "train loss:1.0613667143650023\n",
      "train loss:0.8465456502334803\n",
      "train loss:0.8604729259718211\n",
      "train loss:0.7831814600111034\n",
      "train loss:0.7830868180727656\n",
      "train loss:0.7592391269807125\n",
      "train loss:0.8298232728724451\n",
      "train loss:0.8114911272792716\n",
      "train loss:1.0064967131013582\n",
      "train loss:0.8705296313723392\n",
      "train loss:0.8200704810120236\n",
      "train loss:0.8258290253026311\n",
      "train loss:0.6806300553226434\n",
      "train loss:0.8279967790064421\n",
      "train loss:0.9062199872670098\n",
      "train loss:0.7947555394289529\n",
      "train loss:0.8833544215961662\n",
      "train loss:0.905248251093168\n",
      "train loss:0.8447864108897474\n",
      "train loss:0.8663435878240534\n",
      "train loss:0.9199975399861667\n",
      "train loss:0.9864109837456642\n",
      "train loss:0.7942781049120086\n",
      "train loss:0.8556787958287572\n",
      "train loss:0.7971905759042461\n",
      "train loss:1.0714200222549215\n",
      "train loss:0.7331627715483432\n",
      "train loss:0.920639485240549\n",
      "train loss:0.8449526280553015\n",
      "train loss:0.9987217668291755\n",
      "train loss:0.8672933799807354\n",
      "train loss:0.6207657086547641\n",
      "train loss:0.7575083706349943\n",
      "train loss:0.8867237085510307\n",
      "train loss:0.8061530292936205\n",
      "train loss:0.9133807525292832\n",
      "train loss:0.6841561325344416\n",
      "train loss:0.9594639324759298\n",
      "train loss:0.8527604442732666\n",
      "train loss:0.8102537152884701\n",
      "train loss:0.7327669130860501\n",
      "train loss:0.9216161848135\n",
      "train loss:0.9015227480424366\n",
      "train loss:0.8027318663119608\n",
      "train loss:0.9225090949065069\n",
      "train loss:0.7300569231603578\n",
      "train loss:0.8312432949103571\n",
      "train loss:0.8898435497332368\n",
      "train loss:0.8513741787419272\n",
      "train loss:0.9759754178556801\n",
      "train loss:0.7470250368167379\n",
      "train loss:0.7817873058429078\n",
      "train loss:0.8021637197763779\n",
      "train loss:0.9155852613411585\n",
      "train loss:0.9054365865823663\n",
      "train loss:0.9053594336448227\n",
      "train loss:0.757512379592304\n",
      "train loss:0.8695089942319449\n",
      "train loss:0.9266318010667363\n",
      "train loss:0.6943766403924275\n",
      "train loss:0.9717346503354461\n",
      "train loss:0.7904588025293431\n",
      "train loss:0.8029499380759159\n",
      "train loss:0.8173270690747181\n",
      "train loss:0.8418047915108064\n",
      "train loss:0.8005486993244929\n",
      "train loss:0.8691138529955666\n",
      "train loss:0.8585424027133169\n",
      "train loss:0.759474353744085\n",
      "train loss:0.6977286256644487\n",
      "train loss:0.8225619423724467\n",
      "train loss:0.9650315789657503\n",
      "train loss:0.7656881537292831\n",
      "train loss:0.9144129842597998\n",
      "train loss:0.9964600534548866\n",
      "train loss:0.8518183876860604\n",
      "train loss:0.79438899594896\n",
      "train loss:0.932046026723343\n",
      "train loss:0.5846777657743394\n",
      "train loss:0.91400223026206\n",
      "train loss:0.8164118997304248\n",
      "train loss:0.9784370501811221\n",
      "train loss:0.865930517976415\n",
      "train loss:0.833173523834079\n",
      "train loss:0.900272654263957\n",
      "train loss:0.7278857508941001\n",
      "train loss:1.0447358456744793\n",
      "train loss:0.8569613636424842\n",
      "train loss:0.9028955352276735\n",
      "train loss:0.9497552567263334\n",
      "train loss:0.8701394471753264\n",
      "train loss:0.9292967817749109\n",
      "train loss:0.828485606869593\n",
      "train loss:0.8851824327758335\n",
      "train loss:0.7620964959625298\n",
      "train loss:0.8304184027746787\n",
      "train loss:0.7326473952585211\n",
      "train loss:0.8546193169894597\n",
      "train loss:0.7730590437484832\n",
      "train loss:0.8822844619083366\n",
      "train loss:0.7112790940874367\n",
      "train loss:0.8440460757013932\n",
      "train loss:0.7635312747284528\n",
      "train loss:0.7578681886033511\n",
      "train loss:0.8063523633701111\n",
      "train loss:0.943133913796563\n",
      "train loss:0.7253808214225866\n",
      "train loss:0.7547462293605389\n",
      "train loss:0.8708921276597921\n",
      "train loss:0.8557105085829393\n",
      "train loss:0.967048913912489\n",
      "train loss:0.797484133929694\n",
      "train loss:0.7882495065939312\n",
      "train loss:0.5773503496626337\n",
      "train loss:0.8409217083438792\n",
      "train loss:0.8129365363544904\n",
      "train loss:0.9539224058995208\n",
      "train loss:0.9040922954253442\n",
      "train loss:0.8100096720350599\n",
      "train loss:0.7559279161589442\n",
      "train loss:0.963962534499192\n",
      "train loss:0.8131064927713086\n",
      "train loss:0.8471338171358737\n",
      "train loss:0.9996205879463079\n",
      "train loss:0.5401672917209492\n",
      "train loss:0.7380869980371655\n",
      "train loss:0.8569558898462397\n",
      "train loss:0.9265898750998319\n",
      "train loss:0.9076691564915245\n",
      "train loss:0.6943942787543336\n",
      "train loss:0.8507727971051273\n",
      "train loss:0.8799416896311307\n",
      "train loss:0.9382304365605443\n",
      "train loss:0.8158066740360996\n",
      "train loss:0.9520590113822885\n",
      "train loss:0.9523453241222113\n",
      "train loss:0.8647208882855246\n",
      "train loss:0.7628914339603948\n",
      "train loss:0.870100888401336\n",
      "train loss:0.8332598234003668\n",
      "train loss:0.9841356546636851\n",
      "train loss:1.0144701481193819\n",
      "train loss:0.8035446944921888\n",
      "train loss:0.945195848362842\n",
      "train loss:0.8081906156383393\n",
      "train loss:0.7829460801140367\n",
      "train loss:0.8998829325312986\n",
      "train loss:0.9359639320799868\n",
      "train loss:0.9250993875320312\n",
      "train loss:0.7504681227224935\n",
      "train loss:1.0435597766197786\n",
      "train loss:0.898160765451586\n",
      "train loss:0.9913568996149906\n",
      "train loss:0.8131493356146953\n",
      "train loss:0.873735159447119\n",
      "train loss:0.8615331984891218\n",
      "train loss:0.830511074974449\n",
      "train loss:1.0939149715088141\n",
      "train loss:0.9141613509642914\n",
      "train loss:0.9271333166171694\n",
      "train loss:0.9199548583831461\n",
      "train loss:1.0731943691887929\n",
      "train loss:0.7595376023008433\n",
      "train loss:0.6468789083694598\n",
      "train loss:0.9041298444801333\n",
      "train loss:0.8765652281465974\n",
      "train loss:0.790054582016449\n",
      "train loss:0.7760709281274409\n",
      "train loss:1.0296271634195002\n",
      "train loss:0.9556350829876327\n",
      "train loss:0.6299357585899296\n",
      "train loss:0.9676093481837418\n",
      "train loss:0.8339335252037714\n",
      "train loss:0.7648743745221657\n",
      "train loss:0.8296914886578325\n",
      "train loss:0.9128966920070128\n",
      "train loss:0.8343667893081331\n",
      "train loss:0.7980083699389985\n",
      "train loss:0.7371316944847273\n",
      "train loss:0.9772912697439752\n",
      "train loss:0.9525213178337449\n",
      "train loss:0.744798807355614\n",
      "train loss:0.8349352267410441\n",
      "train loss:0.9235988814540819\n",
      "train loss:0.7216898794565606\n",
      "train loss:0.8490055426271962\n",
      "train loss:0.8433876937717129\n",
      "train loss:0.890922523484417\n",
      "train loss:0.9511751563842655\n",
      "train loss:0.8634148593397317\n",
      "train loss:0.8283644906022003\n",
      "train loss:0.8706821355804378\n",
      "train loss:0.7749125112663695\n",
      "train loss:0.8048236821970391\n",
      "train loss:0.7758039896459935\n",
      "train loss:0.8424270332794157\n",
      "train loss:0.895774934696542\n",
      "train loss:0.8593232292279606\n",
      "train loss:0.8012921038015076\n",
      "train loss:0.7681610834151372\n",
      "train loss:0.8397509467287437\n",
      "train loss:0.9361823743181984\n",
      "train loss:0.7723127737708647\n",
      "train loss:0.7860183340996864\n",
      "train loss:0.9323416271010807\n",
      "train loss:0.8146252836999831\n",
      "train loss:0.7212025089238289\n",
      "train loss:0.6887082243477524\n",
      "train loss:0.8759840900235223\n",
      "train loss:0.7579268493761324\n",
      "train loss:0.886427211436194\n",
      "train loss:1.02332766301398\n",
      "train loss:0.9386691132375874\n",
      "train loss:0.9321615694748497\n",
      "train loss:0.9614905942143669\n",
      "train loss:0.9290056468372562\n",
      "train loss:0.7893096214141468\n",
      "train loss:0.9282944766635772\n",
      "train loss:0.9941744644095872\n",
      "train loss:0.8158514673798045\n",
      "train loss:0.9150576592895737\n",
      "train loss:0.7700984351147099\n",
      "train loss:1.0639867715433438\n",
      "train loss:0.8478193747648105\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.9926\n",
      "Saved Network Parameters!\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)  \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from deep_convnet import DeepConvNet\n",
    "from common.trainer import Trainer\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "network = DeepConvNet()  \n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=20, mini_batch_size=100,\n",
    "                  optimizer='Adam', optimizer_param={'lr':0.001},\n",
    "                  evaluate_sample_num_per_epoch=1000)\n",
    "trainer.train()\n",
    "\n",
    "# 매개변수 보관\n",
    "network.save_params(\"deep_convnet_params.pkl\")\n",
    "print(\"Saved Network Parameters!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83338cb2-7378-4905-a914-409ca02aee47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caluculate accuracy (float64) ... \n",
      "0.9926\n",
      "caluculate accuracy (float16) ... \n",
      "0.9926\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from deep_convnet import DeepConvNet\n",
    "from dataset.mnist import load_mnist\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "network = DeepConvNet()\n",
    "network.load_params(\"deep_convnet_params.pkl\")\n",
    "\n",
    "sampled = 10000 # 고속화를 위한 표본추출\n",
    "x_test = x_test[:sampled]\n",
    "t_test = t_test[:sampled]\n",
    "\n",
    "print(\"caluculate accuracy (float64) ... \")\n",
    "print(network.accuracy(x_test, t_test))\n",
    "\n",
    "# float16(반정밀도)로 형변환\n",
    "x_test = x_test.astype(np.float16)\n",
    "for param in network.params.values():\n",
    "    param[...] = param.astype(np.float16)\n",
    "\n",
    "print(\"caluculate accuracy (float16) ... \")\n",
    "print(network.accuracy(x_test, t_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfce25fc-c622-4417-9708-e813fdf13ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating test accuracy ... \n",
      "test accuracy:0.9926\n",
      "======= misclassified result =======\n",
      "{view index: (label, inference), ...}\n",
      "{1: (4, 9), 2: (6, 5), 3: (6, 0), 4: (4, 9), 5: (3, 5), 6: (8, 2), 7: (6, 4), 8: (2, 1), 9: (1, 7), 10: (7, 4), 11: (3, 5), 12: (3, 5), 13: (8, 9), 14: (6, 5), 15: (9, 4), 16: (7, 1), 17: (1, 6), 18: (6, 0), 19: (2, 7), 20: (9, 4)}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from deep_convnet import DeepConvNet\n",
    "from dataset.mnist import load_mnist\n",
    "\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "network = DeepConvNet()\n",
    "network.load_params(\"deep_convnet_params.pkl\")\n",
    "\n",
    "print(\"calculating test accuracy ... \")\n",
    "#sampled = 1000\n",
    "#x_test = x_test[:sampled]\n",
    "#t_test = t_test[:sampled]\n",
    "\n",
    "classified_ids = []\n",
    "\n",
    "acc = 0.0\n",
    "batch_size = 100\n",
    "\n",
    "for i in range(int(x_test.shape[0] / batch_size)):\n",
    "    tx = x_test[i*batch_size:(i+1)*batch_size]\n",
    "    tt = t_test[i*batch_size:(i+1)*batch_size]\n",
    "    y = network.predict(tx, train_flg=False)\n",
    "    y = np.argmax(y, axis=1)\n",
    "    classified_ids.append(y)\n",
    "    acc += np.sum(y == tt)\n",
    "    \n",
    "acc = acc / x_test.shape[0]\n",
    "print(\"test accuracy:\" + str(acc))\n",
    "\n",
    "classified_ids = np.array(classified_ids)\n",
    "classified_ids = classified_ids.flatten()\n",
    " \n",
    "max_view = 20\n",
    "current_view = 1\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.2, wspace=0.2)\n",
    "\n",
    "mis_pairs = {}\n",
    "for i, val in enumerate(classified_ids == t_test):\n",
    "    if not val:\n",
    "        ax = fig.add_subplot(4, 5, current_view, xticks=[], yticks=[])\n",
    "        ax.imshow(x_test[i].reshape(28, 28), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "        mis_pairs[current_view] = (t_test[i], classified_ids[i])\n",
    "            \n",
    "        current_view += 1\n",
    "        if current_view > max_view:\n",
    "            break\n",
    "\n",
    "print(\"======= misclassified result =======\")\n",
    "print(\"{view index: (label, inference), ...}\")\n",
    "print(mis_pairs)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7c1dfa-ebe3-45ee-86cb-29c7f8d1e01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "from dataset.mnist import load_mnist\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=False, flatten=False)\n",
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2b91b1-32a5-4b04-bf89-6afe40f13be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, flatten=False)\n",
    "x_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b5eb44-0e46-4e8f-9c4e-9dc3a0ec9851",
   "metadata": {},
   "source": [
    "    if normalize:\n",
    "        for key in ('train_img', 'test_img'):\n",
    "            dataset[key] = dataset[key].astype(np.float32)\n",
    "            dataset[key] /= 255.0\n",
    "            -> 이거 전체에 대해 나누는거야 전체 elment-wise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7cd328-edb6-48cb-871a-df4e0fdbe42f",
   "metadata": {},
   "source": [
    "    def _change_one_hot_label(X):\n",
    "        T = np.zeros((X.size, 10))\n",
    "        for idx, row in enumerate(T):\n",
    "            row[X[idx]] = 1\n",
    "            \n",
    "        return T    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3741a6-b6f4-4be6-8f61-0a9c6c7e7a45",
   "metadata": {},
   "source": [
    "    if not flatten:\r\n",
    "         for key in ('train_img', 'test_img'):\r\n",
    "            dataset[key] = dataset[key].reshape(-1, 1, 28, 28)\r\n",
    "\r\n",
    "    return (dataset['train_img'], dataset['train_label']), (dataset['test_img'], dataset['test_label']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a673b90-d020-491d-81c9-8d834b263cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import pickle\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from common.layers. import *\n",
    "\n",
    "class DeepConvNet:\n",
    "    \"\"\" 정확도 99% 이상의 고정밀 합성곱 신경망CNN\n",
    "    (채널 수 더 늘어나고, 중간 데이터 공간 크기 줄여나감)\n",
    "    \n",
    "    conv - relu - conv - relu - pool -\n",
    "    conv - relu - conv - relu - pool -\n",
    "    conv - relu - conv - relu - pool - \n",
    "    affine - relu - dropout - affine - dropout - softmax\n",
    "\n",
    "    He 초깃값 & ReLU & Adam optimizer & dropout\n",
    "    필터 3x3 (small)\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=(1, 28, 28),\n",
    "                 # 채널 수 점 점 늘어남\n",
    "                 conv_param_1 = {'filter_num':16, 'filter_size':3, 'pad':1, 'stride':1}, \n",
    "                 conv_param_2 = {'filter_num':16, 'filter_size':3, 'pad':1, 'stride':1},\n",
    "                 conv_param_3 = {'filter_num':32, 'filter_size':3, 'pad':1, 'stride':1},\n",
    "                 conv_param_4 = {'filter_num':32, 'filter_size':3, 'pad':1, 'stride':1},\n",
    "                 conv_param_6 = {'filter_num':64, 'filter_size':3, 'pad':1, 'stride':1},\n",
    "                 conv_param_7 = {'filter_num':64, 'filter_size':3, 'pad':1, 'stride':1},\n",
    "                 hidden_size=50, output_size=10):\n",
    "        \n",
    "        # 1. 가중치filter 초기화====================================================================\n",
    "        # 각 층의 뉴런 하나당 앞 층의 몇 개 뉴런과 연결되는가 (N)\n",
    "        pre_node_nums = np.array([1*3*3, 16*3*3, 16*3*3, 32*3*3, 32*3*3, 64*3*3, 64*3*3, hidden_size])\n",
    "        weight_init_scales = np.sqrt(2.0 / pre_node_nums) # He 초깃값 (ReLu 사용시 권장)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327a5bbf-c090-4fbb-9af6-4a09054326f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
