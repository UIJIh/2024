{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "89155e73-3795-4566-8af9-3a27ab4fef25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found article before or on 2024.03.29, stopping...\n"
     ]
    }
   ],
   "source": [
    "# 1. 총선\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "\n",
    "def generate_url(page_number):\n",
    "    p_value = (page_number - 1) * 10 + 1\n",
    "    return base_url.format(p_value)\n",
    "    \n",
    "query_1 = []\n",
    "end_flg = 0\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(10000):\n",
    "    if end_flg:\n",
    "        break     \n",
    "    base_url = \"https://www.donga.com/news/search?p={}&query=총선&check_news=91&sorting=1&search_date=1&v1=&v2=&more=1\"\n",
    "    url = generate_url(i+1)\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(url)    \n",
    "    time.sleep(1)  \n",
    "\n",
    "    html = driver.page_source\n",
    "    driver.quit()\n",
    "    \n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    articles = soup.find_all('h4', class_='tit')\n",
    "    dates = soup.find_all('span', class_='date')\n",
    "\n",
    "    for article, date_span in zip(articles, dates):\n",
    "        date_text = date_span.get_text(strip=True)\n",
    "        #print(date_text)\n",
    "        \n",
    "        if date_text == \"2024-03-31\" or date_text == \"2024-03-29\" or date_text == \"2024-03-28\" or date_text == \"2024-03-27\":\n",
    "            end_flg = True\n",
    "            print(f\"Found article before or on 2024.03.29, stopping...\")\n",
    "            break\n",
    "            \n",
    "        a_tag = article.find('a')\n",
    "        if a_tag:\n",
    "            link = a_tag['href']\n",
    "            title = a_tag.get_text()\n",
    "            query_1.append(title)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "8f32b518-afb4-4753-9c59-3c78c87bc155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found article before or on 2024.03.29, stopping...\n"
     ]
    }
   ],
   "source": [
    "# 2. 선거\n",
    "\n",
    "def generate_url(page_number):\n",
    "    p_value = (page_number - 1) * 10 + 1\n",
    "    return base_url.format(p_value)\n",
    "\n",
    "query_2 = []\n",
    "end_flg = 0\n",
    "\n",
    "for i in range(10000):\n",
    "    if end_flg:\n",
    "        break\n",
    "    base_url = \"https://www.donga.com/news/search?p={}&query=선거&check_news=1&more=1&sorting=1&search_date=1&v1=&v2=&range=1\"\n",
    "    url = generate_url(i+1)\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(url)\n",
    "    time.sleep(1)\n",
    "\n",
    "    html = driver.page_source\n",
    "    driver.quit()\n",
    "\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    articles = soup.find_all('h4', class_='tit')\n",
    "    dates = soup.find_all('span', class_='date')\n",
    "\n",
    "    for article, date_span in zip(articles, dates):\n",
    "        date_text = date_span.get_text(strip=True)\n",
    "        #print(date_text)\n",
    "        \n",
    "        if date_text == \"2024-03-31\" or date_text == \"2024-03-29\" or date_text == \"2024-03-28\" or date_text == \"2024-03-27\":\n",
    "            end_flg = True\n",
    "            print(f\"Found article before or on 2024.03.29, stopping...\")\n",
    "            break\n",
    "            \n",
    "        a_tag = article.find('a')\n",
    "        if a_tag:\n",
    "            link = a_tag['href']\n",
    "            title = a_tag.get_text()\n",
    "            query_2.append(title)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "7042a3bd-eb10-45e3-8d0b-9eb5d1f36732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found article before or on 2024.03.29, stopping...\n"
     ]
    }
   ],
   "source": [
    "# 3. 제22대+국회의원선거\n",
    "\n",
    "def generate_url(page_number):\n",
    "    p_value = (page_number - 1) * 10 + 1\n",
    "    return base_url.format(p_value)\n",
    "\n",
    "query_3 = []\n",
    "end_flg = 0\n",
    "\n",
    "for i in range(10000):\n",
    "    if end_flg:\n",
    "        break\n",
    "    base_url = \"https://www.donga.com/news/search?p={}&query=제22대+국회의원선거&check_news=1&more=1&sorting=1&search_date=1&v1=&v2=&range=1\"\n",
    "    url = generate_url(i+1)\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(url)\n",
    "    time.sleep(1)\n",
    "\n",
    "    html = driver.page_source\n",
    "    driver.quit()\n",
    "\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    articles = soup.find_all('h4', class_='tit')\n",
    "    dates = soup.find_all('span', class_='date')\n",
    "\n",
    "    for article, date_span in zip(articles, dates):\n",
    "        date_text = date_span.get_text(strip=True)\n",
    "        #print(date_text)\n",
    "        \n",
    "        if date_text == \"2024-03-31\" or date_text == \"2024-03-29\" or date_text == \"2024-03-28\" or date_text == \"2024-03-27\":\n",
    "            end_flg = True\n",
    "            print(f\"Found article before or on 2024.03.29, stopping...\")\n",
    "            break\n",
    "            \n",
    "        a_tag = article.find('a')\n",
    "        if a_tag:\n",
    "            link = a_tag['href']\n",
    "            title = a_tag.get_text()\n",
    "            query_3.append(title)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "71c17f59-acf3-494c-b5c1-5997be21e813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found article before or on 2024.03.29, stopping...\n"
     ]
    }
   ],
   "source": [
    "# 4. 4월%2010일%20투표\n",
    "\n",
    "def generate_url(page_number):\n",
    "    p_value = (page_number - 1) * 10 + 1\n",
    "    return base_url.format(p_value)\n",
    "\n",
    "query_4 = []\n",
    "end_flg = 0\n",
    "\n",
    "for i in range(10000):\n",
    "    if end_flg:\n",
    "        break\n",
    "    base_url = \"https://www.donga.com/news/search?p={}&query=4%EC%9B%94+10%EC%9D%BC+%ED%88%AC%ED%91%9C&check_news=91&sorting=1&search_date=1&v1=&v2=&more=1\"\n",
    "    url = generate_url(i+1)\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(url)\n",
    "    time.sleep(1)\n",
    "\n",
    "    html = driver.page_source\n",
    "    driver.quit()\n",
    "\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    articles = soup.find_all('h4', class_='tit')\n",
    "    dates = soup.find_all('span', class_='date')\n",
    "\n",
    "    for article, date_span in zip(articles, dates):\n",
    "        date_text = date_span.get_text(strip=True)\n",
    "        #print(date_text)\n",
    "        \n",
    "        if date_text == \"2024-03-31\" or date_text == \"2024-03-29\" or date_text == \"2024-03-28\" or date_text == \"2024-03-27\":\n",
    "            end_flg = True\n",
    "            print(f\"Found article before or on 2024.03.29, stopping...\")\n",
    "            break\n",
    "            \n",
    "        a_tag = article.find('a')\n",
    "        if a_tag:\n",
    "            link = a_tag['href']\n",
    "            title = a_tag.get_text()\n",
    "            query_4.append(title)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "256c42de-62a7-4385-9c5c-f14585454452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-06\n",
      "2024-03-29\n",
      "Found article before or on 2024.03.29, stopping...\n"
     ]
    }
   ],
   "source": [
    "# 5. 문장\n",
    "\n",
    "def generate_url(page_number):\n",
    "    p_value = (page_number - 1) * 10 + 1\n",
    "    return base_url.format(p_value)\n",
    "\n",
    "query_5 = []\n",
    "end_flg = 0\n",
    "\n",
    "for i in range(10000):\n",
    "    if end_flg:\n",
    "        break\n",
    "    base_url = \"https://www.donga.com/news/search?p={}&query=4%EC%9B%94+10%EC%9D%BC%EC%9D%80+%EC%A0%9C+22%EB%8C%80+%EA%B5%AD%ED%9A%8C%EC%9D%98%EC%9B%90%EC%84%A0%EA%B1%B0%EC%9D%BC%EC%9D%B4%EB%8B%A4.&check_news=91&sorting=1&search_date=1&v1=&v2=&more=1\"\n",
    "    url = generate_url(i+1)\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(url)\n",
    "    time.sleep(1)\n",
    "\n",
    "    html = driver.page_source\n",
    "    driver.quit()\n",
    "\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    articles = soup.find_all('h4', class_='tit')\n",
    "    dates = soup.find_all('span', class_='date')\n",
    "\n",
    "    for article, date_span in zip(articles, dates):\n",
    "        date_text = date_span.get_text(strip=True)\n",
    "        print(date_text)\n",
    "        \n",
    "        if date_text == \"2024-03-31\" or date_text == \"2024-03-29\" or date_text == \"2024-03-28\" or date_text == \"2024-03-27\":\n",
    "            end_flg = True\n",
    "            print(f\"Found article before or on 2024.03.29, stopping...\")\n",
    "            break\n",
    "            \n",
    "        a_tag = article.find('a')\n",
    "        if a_tag:\n",
    "            link = a_tag['href']\n",
    "            title = a_tag.get_text()\n",
    "            query_5.append(title)                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "b0134ab4-1634-4896-9cda-d9fd3043ef3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['선거가 민의를 대변하지 못했던 일제강점기의 슬픈 투표장 풍경[청계천 옆 사진관]']"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "e305ec60-1b77-412d-b56a-b51e401d8294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "436 448 58 24 1\n"
     ]
    }
   ],
   "source": [
    "print(len(query_1), len(query_2), len(query_3), len(query_4), len(query_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "0080947f-1cbd-4c55-a6e8-e9fa2aba57e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264\n",
      "296\n",
      "38\n",
      "12\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# filter labels (within a given dataset)\n",
    "dataset = pd.read_csv('Korea_DB.csv', encoding='CP949')\n",
    "ground_truths = [query_1, query_2, query_3, query_4, query_5]\n",
    "\n",
    "filtered_ground_truths = [[item for item in query if item in dataset['title'].values] for query in ground_truths]\n",
    "\n",
    "for item in filtered_ground_truths:\n",
    "    print(len(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "7596f454-ee19-4fa0-81b6-7f5a05b43ac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'선거가 민의를 대변하지 못했던 일제강점기의 슬픈 투표장 풍경[청계천 옆 사진관]' in dataset['title'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "46939c45-0158-43d7-a39e-6ca017ee6da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== result < 1 > ====================\n",
      "Precision: 0.00, Recall: 0.00\n",
      "F1 Score: 0.00\n",
      "\n",
      "==================== result < 2 > ====================\n",
      "Precision: 0.00, Recall: 0.00\n",
      "F1 Score: 0.00\n",
      "\n",
      "==================== result < 3 > ====================\n",
      "Precision: 0.00, Recall: 0.00\n",
      "F1 Score: 0.00\n",
      "\n",
      "==================== result < 4 > ====================\n",
      "Precision: 0.00, Recall: 0.00\n",
      "F1 Score: 0.00\n",
      "\n",
      "==================== result < 5 > ====================\n",
      "Precision: 0.00, Recall: 0.00\n",
      "F1 Score: 0.00\n",
      "\n",
      "Average Precision: 0.00\n",
      "Average Recall: 0.00\n",
      "Average F1 Score: 0.00\n"
     ]
    }
   ],
   "source": [
    "def calculate_precision_recall(ground_truth, model_results):\n",
    "    true_positives = ground_truth.intersection(model_results)\n",
    "    precision = len(true_positives) / len(model_results) if model_results else 0\n",
    "    recall = len(true_positives) / len(ground_truth) if ground_truth else 0\n",
    "    return precision, recall\n",
    "\n",
    "def calculate_f1_score(precision, recall):\n",
    "    if precision + recall == 0:\n",
    "        return 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    return f1_score\n",
    "\n",
    "ground_truths = [\n",
    "    set(query_1),\n",
    "    set(query_2),\n",
    "    set(query_3),\n",
    "    set(query_4),\n",
    "    set(query_5)\n",
    "]\n",
    "\n",
    "model_results_list = [\n",
    "    set([\"문서1\", \"문서3\", \"문서5\"]),\n",
    "    set([\"문서2\", \"문서3\"]),\n",
    "    set([\"문서5\", \"문서6\", \"문서7\"]),\n",
    "    set([\"문서8\", \"문서9\", \"문서10\"]),\n",
    "    set([\"문서11\", \"문서12\"])\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for i in range(5):\n",
    "    ground_truth = ground_truths[i]\n",
    "    model_results = model_results_list[i]\n",
    "\n",
    "    precision, recall = calculate_precision_recall(ground_truth, model_results)\n",
    "    f1_score = calculate_f1_score(precision, recall)\n",
    "\n",
    "    print(f\"==================== result < {i+1} > ====================\")\n",
    "    print(f\"Precision: {precision:.2f}, Recall: {recall:.2f}\")\n",
    "    print(f\"F1 Score: {f1_score:.2f}\\n\")\n",
    "    results.append((precision, recall, f1_score))\n",
    "\n",
    "# Average\n",
    "average_precision = sum([result[0] for result in results]) / len(results)\n",
    "average_recall = sum([result[1] for result in results]) / len(results)\n",
    "average_f1_score = sum([result[2] for result in results]) / len(results)\n",
    "\n",
    "print(f\"Average Precision: {average_precision:.2f}\")\n",
    "print(f\"Average Recall: {average_recall:.2f}\")\n",
    "print(f\"Average F1 Score: {average_f1_score:.2f}\")\n",
    "\n",
    "average_results = [average_precision, average_recall, average_f1_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "604b007e-61be-40e2-9e27-a3a8ed19efdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0, 0.0, 0), (0.0, 0.0, 0), (0.0, 0.0, 0), (0.0, 0.0, 0), (0.0, 0.0, 0)]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "7e4dd76c-c726-43a2-a67d-e83b459479c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "3397de4a-2b68-452e-a0dc-c30077416a5f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "strptime() argument 1 must be str, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[205], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m relevance_scores\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# 시간적 관련성 평가 실행\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m temporal_relevance_scores \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_temporal_relevance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_date\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# 결과 출력 (점수가 높은 순서로 정렬)\u001b[39;00m\n\u001b[1;32m     29\u001b[0m temporal_relevance_scores\u001b[38;5;241m.\u001b[39msort(key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m1\u001b[39m], reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[205], line 15\u001b[0m, in \u001b[0;36mevaluate_temporal_relevance\u001b[0;34m(dataset, current_date)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# 각 문서에 대해 순회\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m dataset:\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# 문서의 날짜 파싱\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     doc_date \u001b[38;5;241m=\u001b[39m \u001b[43mdatetime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mY/\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mm/\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mH:\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mM\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# 시간 차이 계산 (일수 기준)\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     time_difference \u001b[38;5;241m=\u001b[39m (current_date \u001b[38;5;241m-\u001b[39m doc_date)\u001b[38;5;241m.\u001b[39mdays\n",
      "\u001b[0;31mTypeError\u001b[0m: strptime() argument 1 must be str, not list"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "# 쿼리 및 현재 날짜\n",
    "query = \"총선\"\n",
    "current_date = datetime.strptime(\"2024-04-10\", \"%Y-%m-%d\")\n",
    "\n",
    "# 데이터셋의 'date' 컬럼으로부터 날짜 객체 리스트 생성\n",
    "# 이 부분은 예시 코드로, 실제 데이터셋 구조에 따라 수정이 필요할 수 있습니다.\n",
    "dates = [datetime.strptime(date_string, \"%Y/%m/%d %H:%M\") for date_string in dataset['date']]\n",
    "\n",
    "def evaluate_temporal_relevance(dataset, current_date):\n",
    "    relevance_scores = []\n",
    "    for i, doc in enumerate(dataset):\n",
    "        # 이미 날짜 객체로 변환된 dates 리스트에서 해당 문서의 날짜를 가져옵니다.\n",
    "        doc_date = dates[i]\n",
    "        time_difference = (current_date - doc_date).days\n",
    "        # 여기서는 단순화를 위해 1/(일수+1) 공식을 사용했습니다.\n",
    "        temporal_score = 1 / (time_difference + 1)\n",
    "        relevance_scores.append((doc, temporal_score))\n",
    "    return relevance_scores\n",
    "\n",
    "# 시간적 관련성 평가 실행\n",
    "temporal_relevance_scores = evaluate_temporal_relevance(dataset, current_date)\n",
    "\n",
    "# 결과 출력 (점수가 높은 순서로 정렬)\n",
    "temporal_relevance_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "for doc, score in temporal_relevance_scores:\n",
    "    print(f\"문서 ID: {doc['id']}, 제목: {doc['title']}, 시간적 관련성 점수: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "c8140a43-0fc0-4959-aa6a-b08bce68e80a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2024/04/01 23:42\n",
       "1       2024/04/01 19:54\n",
       "2       2024/04/01 22:20\n",
       "3       2024/04/01 20:38\n",
       "4       2024/04/01 18:14\n",
       "              ...       \n",
       "2374     2024/04/09 3:58\n",
       "2375     2024/04/09 3:00\n",
       "2376     2024/04/09 4:12\n",
       "2377     2024/04/09 3:00\n",
       "2378     2024/04/09 3:00\n",
       "Name: date, Length: 2379, dtype: object"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7ea0c3-1a96-4e51-9246-ad591ec8b6cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
