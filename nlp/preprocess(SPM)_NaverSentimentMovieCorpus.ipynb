{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Naver Sentiment Movie Corpus 다운로드"
      ],
      "metadata": {
        "id": "9oWXxkUU9HFq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eq1TIOUm7KxX",
        "outputId": "5a22a71c-80c4-4a15-96db-b09733b98f91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-01-20 08:19:41--  https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14628807 (14M) [text/plain]\n",
            "Saving to: ‘ratings_train.txt’\n",
            "\n",
            "ratings_train.txt   100%[===================>]  13.95M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2024-01-20 08:19:41 (113 MB/s) - ‘ratings_train.txt’ saved [14628807/14628807]\n",
            "\n",
            "--2024-01-20 08:19:41--  https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4893335 (4.7M) [text/plain]\n",
            "Saving to: ‘ratings_test.txt’\n",
            "\n",
            "ratings_test.txt    100%[===================>]   4.67M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2024-01-20 08:19:42 (57.9 MB/s) - ‘ratings_test.txt’ saved [4893335/4893335]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "! wget https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\n",
        "! wget https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Vocab 로드\n",
        ": Sentencepiece를 활용해 만들어 놓은 vocab을 로드"
      ],
      "metadata": {
        "id": "lhdY8h6R9MDE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PpI6tFGsCF6P",
        "outputId": "7c90657e-030c-4b9e-f13c-3bba9f17f6ad"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# vocab loading\n",
        "import sentencepiece as spm\n",
        "vocab_file = \"kowiki.model\"\n",
        "vocab = spm.SentencePieceProcessor()\n",
        "vocab.load(vocab_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2COmucr9CfH",
        "outputId": "01ec5645-d6e1-4fa0-9e97-325a4b2053dc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. 전처리\n",
        ": 다운로드한 데이터를 vocab으로 미리 tokenize해서 json형태로 저장\n",
        "(tokenize를 미리하지 않고 training시에 할 경우 처리시간이 매번 소요 되므로 이를 효과적으로 줄이기 위함)"
      ],
      "metadata": {
        "id": "1zSGcUTk9d8E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "def prepare_train(vocab, infile, outfile):\n",
        "    df = pd.read_csv(infile, sep=\"\\t\", engine=\"python\")\n",
        "    with open(outfile, \"w\") as f:\n",
        "        for index, row in df.iterrows(): # 각 행을 순회\n",
        "            document = row[\"document\"]\n",
        "            if type(document) != str:\n",
        "                continue\n",
        "            instance = { \"id\": row[\"id\"], \"doc\": vocab.encode_as_pieces(document), \"label\": row[\"label\"] }\n",
        "                                                 # vocab.encode_as_pieces(document)를 사용하여 단어 사전에 따라 문서를 부분으로 나눔\n",
        "            # instance라는 딕셔너리를 생성하여 \"id\", \"doc\", \"label\" 키를 가지고 있음\n",
        "            f.write(json.dumps(instance))\n",
        "            f.write(\"\\n\")\n",
        "            #  JSON 형식으로 변환하여 출력 파일에 기록. 마지막에 줄 바꿈 문자(\"\\n\")을 추가하여 각 인스턴스를 새로운 줄에 저장"
      ],
      "metadata": {
        "id": "-f0E8bI39oCJ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prepare_train(vocab, \"ratings_train.txt\", \"ratings_train.json\")\n",
        "prepare_train(vocab, \"ratings_test.txt\", \"ratings_test.json\")"
      ],
      "metadata": {
        "id": "t4ECgWTr_HAD"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}